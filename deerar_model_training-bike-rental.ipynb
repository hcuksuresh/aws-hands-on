{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_categories = False\n",
    "if with_categories:\n",
    "    base_job_name = 'deepar-bikerental-with-categories'\n",
    "else:\n",
    "    base_job_name = 'deepar-bikerental-no-categories'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify your bucket name\n",
    "bucket = 'your-bucket-name'\n",
    "prefix = 'deepar/deepar-bikerental' # change to your desired S3 prefix\n",
    "\n",
    "# This structure allows multiple training and test files for model development and testing\n",
    "if with_categories:\n",
    "    s3_data_path = \"{}/{}/data_with_categories\".format(bucket, prefix)\n",
    "else:\n",
    "    s3_data_path = \"{}/{}/data\".format(bucket, prefix)\n",
    "    \n",
    "\n",
    "s3_output_path = \"{}/{}/output\".format(bucket, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sagemaker-eu-west-1-304527814092/deepar/deepar-bikerental/data',\n",
       " 'sagemaker-eu-west-1-304527814092/deepar/deepar-bikerental/output')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_data_path,s3_output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_s3(filename, bucket, key):\n",
    "    with open(filename,'rb') as f: # Read in binary mode\n",
    "        return boto3.Session().resource('s3').Bucket(bucket).Object(key).upload_fileobj(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload one or more training files and test files to S3\n",
    "if with_categories:\n",
    "    write_to_s3('train_with_categories.json',bucket,'deepar/deepar-bikerental/data_with_categories/train/train_with_categories.json')\n",
    "    write_to_s3('test_with_categories.json',bucket,'deepar/deepar-bikerental/data_with_categories/test/test_with_categories.json')\n",
    "else:\n",
    "    write_to_s3('train_bike.json',bucket,'deepar/deepar-bikerental/data/train/train_bike.json')\n",
    "    write_to_s3('test_bike.json',bucket,'deepar/deepar-bikerental/data/test/test_bike.json')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DeepAR Container 224300973850.dkr.ecr.eu-west-1.amazonaws.com/forecasting-deepar:1\n"
     ]
    }
   ],
   "source": [
    "container = sagemaker.image_uris.retrieve(\"forecasting-deepar\",sess.boto_region_name)\n",
    "\n",
    "print (f'Using DeepAR Container {container}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'224300973850.dkr.ecr.eu-west-1.amazonaws.com/forecasting-deepar:1'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq='H' \n",
    "\n",
    "prediction_length = 288\n",
    "\n",
    "context_length = 288"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    output_path=\"s3://\" + s3_output_path,\n",
    "    sagemaker_session=sess,\n",
    "    base_job_name=base_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('H', 288, 288)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq, context_length, prediction_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/deepar_hyperparameters.html\n",
    "hyperparameters = {\n",
    "    \"time_freq\": freq,\n",
    "    \"epochs\": \"400\",\n",
    "    \"early_stopping_patience\": \"288\",\n",
    "    \"mini_batch_size\": \"64\",\n",
    "    \"learning_rate\": \"5E-4\",\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length),\n",
    "    \"cardinality\" : \"auto\" if with_categories else ''\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time_freq': 'H',\n",
       " 'epochs': '400',\n",
       " 'early_stopping_patience': '288',\n",
       " 'mini_batch_size': '64',\n",
       " 'learning_rate': '5E-4',\n",
       " 'context_length': '288',\n",
       " 'prediction_length': '288',\n",
       " 'cardinality': ''}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_channels = {\n",
    "    \"train\": \"s3://{}/train/\".format(s3_data_path),\n",
    "    \"test\": \"s3://{}/test/\".format(s3_data_path)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 's3://sagemaker-eu-west-1-304527814092/deepar/deepar-bikerental/data/train/',\n",
       " 'test': 's3://sagemaker-eu-west-1-304527814092/deepar/deepar-bikerental/data/test/'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-04 08:15:24 Starting - Starting the training job...\n",
      "2021-04-04 08:15:49 Starting - Launching requested ML instancesProfilerReport-1617524124: InProgress\n",
      "......\n",
      "2021-04-04 08:16:50 Starting - Preparing the instances for training......\n",
      "2021-04-04 08:17:52 Downloading - Downloading input data\n",
      "2021-04-04 08:17:52 Training - Downloading the training image...\n",
      "2021-04-04 08:18:10 Training - Training image download completed. Training in progress.\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:10 INFO 139780359198336] Reading default configuration from /opt/amazon/lib/python3.6/site-packages/algorithm/resources/default-input.json: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'student-t', 'mini_batch_size': '128', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]'}\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:10 INFO 139780359198336] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'prediction_length': '288', 'time_freq': 'H', 'context_length': '288', 'epochs': '400', 'learning_rate': '5E-4', 'early_stopping_patience': '288', 'mini_batch_size': '64'}\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:10 INFO 139780359198336] Final configuration: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '288', 'embedding_dimension': '10', 'learning_rate': '5E-4', 'likelihood': 'student-t', 'mini_batch_size': '64', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', 'prediction_length': '288', 'time_freq': 'H', 'context_length': '288', 'epochs': '400'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:10 INFO 139780359198336] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:10 INFO 139780359198336] Using early stopping with patience 288\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:10 INFO 139780359198336] random_seed is None\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:10 INFO 139780359198336] [cardinality=auto] `cat` field was NOT found in the file `/opt/ml/input/data/train/train_bike.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:10 INFO 139780359198336] [num_dynamic_feat=auto] `dynamic_feat` field was NOT found in the file `/opt/ml/input/data/train/train_bike.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:10 INFO 139780359198336] Training set statistics:\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:10 INFO 139780359198336] Integer time series\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:10 INFO 139780359198336] number of time series: 3\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:10 INFO 139780359198336] number of observations: 50904\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:10 INFO 139780359198336] mean target length: 16968.0\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:10 INFO 139780359198336] min/mean/max target: 0.0/79.57296086751532/977.0\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:10 INFO 139780359198336] mean abs(target): 79.57296086751532\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:10 INFO 139780359198336] contains missing values: yes (37.5%)\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:10 INFO 139780359198336] Small number of time series. Doing 214 passes over dataset with prob 0.9968847352024922 per epoch.\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:10 INFO 139780359198336] Test set statistics:\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:10 INFO 139780359198336] Integer time series\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:10 INFO 139780359198336] number of time series: 3\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:10 INFO 139780359198336] number of observations: 51768\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:10 INFO 139780359198336] mean target length: 17256.0\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:10 INFO 139780359198336] min/mean/max target: 0.0/80.57008190387884/977.0\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:10 INFO 139780359198336] mean abs(target): 80.57008190387884\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:10 INFO 139780359198336] contains missing values: yes (36.9%)\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:10 INFO 139780359198336] #memory_usage::<batchbuffer> = 213.4899139404297 mb\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:10 INFO 139780359198336] nvidia-smi took: 0.025228261947631836 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:10 INFO 139780359198336] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:10 INFO 139780359198336] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524290.7127345, \"EndTime\": 1617524304.7437572, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 14028.78737449646, \"count\": 1, \"min\": 14028.78737449646, \"max\": 14028.78737449646}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:24 INFO 139780359198336] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:27 INFO 139780359198336] #memory_usage::<model> = 259 mb\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524304.7438586, \"EndTime\": 1617524307.903397, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 17190.51504135132, \"count\": 1, \"min\": 17190.51504135132, \"max\": 17190.51504135132}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:32 INFO 139780359198336] Epoch[0] Batch[0] avg_epoch_loss=4.188398\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:32 INFO 139780359198336] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=4.1883978843688965\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:38 INFO 139780359198336] Epoch[0] Batch[5] avg_epoch_loss=3.887810\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:38 INFO 139780359198336] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=3.8878103494644165\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:38 INFO 139780359198336] Epoch[0] Batch [5]#011Speed: 56.60 samples/sec#011loss=3.887810\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:43 INFO 139780359198336] Epoch[0] Batch[10] avg_epoch_loss=3.765633\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:43 INFO 139780359198336] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=3.619019365310669\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:43 INFO 139780359198336] Epoch[0] Batch [10]#011Speed: 60.85 samples/sec#011loss=3.619019\u001b[0m\n",
      "\u001b[34m/opt/amazon/python3.6/lib/python3.6/contextlib.py:99: DeprecationWarning: generator 'local_timer' raised StopIteration\n",
      "  self.gen.throw(type, value, traceback)\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:43 INFO 139780359198336] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524307.903473, \"EndTime\": 1617524323.5109253, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 400.0, \"count\": 1, \"min\": 400, \"max\": 400}, \"update.time\": {\"sum\": 15607.372045516968, \"count\": 1, \"min\": 15607.372045516968, \"max\": 15607.372045516968}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:43 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=41.96700091501097 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:43 INFO 139780359198336] #progress_metric: host=algo-1, completed 0.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:43 INFO 139780359198336] #quality_metric: host=algo-1, epoch=0, train loss <loss>=3.7656326293945312\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:43 INFO 139780359198336] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:43 INFO 139780359198336] Saved checkpoint to \"/opt/ml/model/state_5832d8d2-c637-4d99-9eff-e73b0fb14dab-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524323.5110161, \"EndTime\": 1617524323.7003455, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 188.78436088562012, \"count\": 1, \"min\": 188.78436088562012, \"max\": 188.78436088562012}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:47 INFO 139780359198336] Epoch[1] Batch[0] avg_epoch_loss=3.262001\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:47 INFO 139780359198336] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=3.262000560760498\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:52 INFO 139780359198336] Epoch[1] Batch[5] avg_epoch_loss=3.628506\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:52 INFO 139780359198336] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=3.6285057862599692\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:52 INFO 139780359198336] Epoch[1] Batch [5]#011Speed: 61.61 samples/sec#011loss=3.628506\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:58 INFO 139780359198336] Epoch[1] Batch[10] avg_epoch_loss=3.517688\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:58 INFO 139780359198336] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=3.384706974029541\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:58 INFO 139780359198336] Epoch[1] Batch [10]#011Speed: 59.43 samples/sec#011loss=3.384707\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:58 INFO 139780359198336] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524323.7004175, \"EndTime\": 1617524338.3816874, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14681.204080581665, \"count\": 1, \"min\": 14681.204080581665, \"max\": 14681.204080581665}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:58 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.09134421766441 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:58 INFO 139780359198336] #progress_metric: host=algo-1, completed 0.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:58 INFO 139780359198336] #quality_metric: host=algo-1, epoch=1, train loss <loss>=3.5176881443370474\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:58 INFO 139780359198336] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:18:58 INFO 139780359198336] Saved checkpoint to \"/opt/ml/model/state_a1ace3a0-d459-4202-b947-f5bc8c5c7c26-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524338.3817585, \"EndTime\": 1617524338.5786436, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 196.43306732177734, \"count\": 1, \"min\": 196.43306732177734, \"max\": 196.43306732177734}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:02 INFO 139780359198336] Epoch[2] Batch[0] avg_epoch_loss=3.655308\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:02 INFO 139780359198336] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=3.655308246612549\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 08:19:08 INFO 139780359198336] Epoch[2] Batch[5] avg_epoch_loss=3.460503\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:08 INFO 139780359198336] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=3.4605026245117188\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:08 INFO 139780359198336] Epoch[2] Batch [5]#011Speed: 54.27 samples/sec#011loss=3.460503\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:14 INFO 139780359198336] Epoch[2] Batch[10] avg_epoch_loss=3.526406\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:14 INFO 139780359198336] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=3.605489206314087\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:14 INFO 139780359198336] Epoch[2] Batch [10]#011Speed: 61.57 samples/sec#011loss=3.605489\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:14 INFO 139780359198336] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524338.5787141, \"EndTime\": 1617524354.0546103, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 15475.832223892212, \"count\": 1, \"min\": 15475.832223892212, \"max\": 15475.832223892212}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:14 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=42.000699853087546 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:14 INFO 139780359198336] #progress_metric: host=algo-1, completed 0.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:14 INFO 139780359198336] #quality_metric: host=algo-1, epoch=2, train loss <loss>=3.526405616240068\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:14 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:18 INFO 139780359198336] Epoch[3] Batch[0] avg_epoch_loss=3.467620\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:18 INFO 139780359198336] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=3.4676198959350586\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:23 INFO 139780359198336] Epoch[3] Batch[5] avg_epoch_loss=3.359813\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:23 INFO 139780359198336] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=3.359812617301941\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:23 INFO 139780359198336] Epoch[3] Batch [5]#011Speed: 62.08 samples/sec#011loss=3.359813\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:27 INFO 139780359198336] processed a total of 597 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524354.0546758, \"EndTime\": 1617524367.594848, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13539.597034454346, \"count\": 1, \"min\": 13539.597034454346, \"max\": 13539.597034454346}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:27 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.09254181194112 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:27 INFO 139780359198336] #progress_metric: host=algo-1, completed 1.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:27 INFO 139780359198336] #quality_metric: host=algo-1, epoch=3, train loss <loss>=3.276546764373779\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:27 INFO 139780359198336] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:27 INFO 139780359198336] Saved checkpoint to \"/opt/ml/model/state_4a5a6c91-28c5-40e2-8926-ab6ad6ed2897-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524367.594919, \"EndTime\": 1617524367.7827945, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 187.33477592468262, \"count\": 1, \"min\": 187.33477592468262, \"max\": 187.33477592468262}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:31 INFO 139780359198336] Epoch[4] Batch[0] avg_epoch_loss=3.338426\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:31 INFO 139780359198336] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=3.338426113128662\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:37 INFO 139780359198336] Epoch[4] Batch[5] avg_epoch_loss=3.312602\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:37 INFO 139780359198336] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=3.3126019636789956\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:37 INFO 139780359198336] Epoch[4] Batch [5]#011Speed: 61.32 samples/sec#011loss=3.312602\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:42 INFO 139780359198336] Epoch[4] Batch[10] avg_epoch_loss=3.326049\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:42 INFO 139780359198336] #quality_metric: host=algo-1, epoch=4, batch=10 train loss <loss>=3.3421859741210938\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:42 INFO 139780359198336] Epoch[4] Batch [10]#011Speed: 60.60 samples/sec#011loss=3.342186\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:42 INFO 139780359198336] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524367.7828667, \"EndTime\": 1617524382.3915482, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14608.614921569824, \"count\": 1, \"min\": 14608.614921569824, \"max\": 14608.614921569824}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:42 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.5892318529238 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:42 INFO 139780359198336] #progress_metric: host=algo-1, completed 1.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:42 INFO 139780359198336] #quality_metric: host=algo-1, epoch=4, train loss <loss>=3.3260492411526767\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:42 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:46 INFO 139780359198336] Epoch[5] Batch[0] avg_epoch_loss=3.233704\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:46 INFO 139780359198336] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=3.23370361328125\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:51 INFO 139780359198336] Epoch[5] Batch[5] avg_epoch_loss=3.158466\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:51 INFO 139780359198336] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=3.158466100692749\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:51 INFO 139780359198336] Epoch[5] Batch [5]#011Speed: 62.01 samples/sec#011loss=3.158466\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:55 INFO 139780359198336] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524382.3916135, \"EndTime\": 1617524395.9408221, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13548.893928527832, \"count\": 1, \"min\": 13548.893928527832, \"max\": 13548.893928527832}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:55 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=47.23596992367102 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:55 INFO 139780359198336] #progress_metric: host=algo-1, completed 1.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:55 INFO 139780359198336] #quality_metric: host=algo-1, epoch=5, train loss <loss>=3.192919611930847\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:55 INFO 139780359198336] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:19:56 INFO 139780359198336] Saved checkpoint to \"/opt/ml/model/state_80718a55-0e52-48bc-8012-f7150577b754-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524395.9408925, \"EndTime\": 1617524396.1266634, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 185.28008460998535, \"count\": 1, \"min\": 185.28008460998535, \"max\": 185.28008460998535}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:00 INFO 139780359198336] Epoch[6] Batch[0] avg_epoch_loss=3.192229\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:00 INFO 139780359198336] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=3.1922285556793213\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:06 INFO 139780359198336] Epoch[6] Batch[5] avg_epoch_loss=3.129636\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:06 INFO 139780359198336] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=3.1296356121699014\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:06 INFO 139780359198336] Epoch[6] Batch [5]#011Speed: 53.55 samples/sec#011loss=3.129636\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:10 INFO 139780359198336] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524396.1267393, \"EndTime\": 1617524410.657613, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14530.805110931396, \"count\": 1, \"min\": 14530.805110931396, \"max\": 14530.805110931396}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:10 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.699950755614104 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:10 INFO 139780359198336] #progress_metric: host=algo-1, completed 1.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:10 INFO 139780359198336] #quality_metric: host=algo-1, epoch=6, train loss <loss>=3.136123609542847\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:10 INFO 139780359198336] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:10 INFO 139780359198336] Saved checkpoint to \"/opt/ml/model/state_509166f4-1e39-4b4c-b6c6-f70734258609-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524410.657683, \"EndTime\": 1617524410.837269, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 178.9853572845459, \"count\": 1, \"min\": 178.9853572845459, \"max\": 178.9853572845459}}}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 08:20:14 INFO 139780359198336] Epoch[7] Batch[0] avg_epoch_loss=3.083492\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:14 INFO 139780359198336] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=3.083491563796997\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:20 INFO 139780359198336] Epoch[7] Batch[5] avg_epoch_loss=3.007710\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:20 INFO 139780359198336] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=3.007709503173828\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:20 INFO 139780359198336] Epoch[7] Batch [5]#011Speed: 62.84 samples/sec#011loss=3.007710\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:25 INFO 139780359198336] Epoch[7] Batch[10] avg_epoch_loss=3.046127\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:25 INFO 139780359198336] #quality_metric: host=algo-1, epoch=7, batch=10 train loss <loss>=3.0922286033630373\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:25 INFO 139780359198336] Epoch[7] Batch [10]#011Speed: 59.66 samples/sec#011loss=3.092229\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:25 INFO 139780359198336] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524410.837335, \"EndTime\": 1617524425.389329, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14551.930904388428, \"count\": 1, \"min\": 14551.930904388428, \"max\": 14551.930904388428}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:25 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.90420677291237 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:25 INFO 139780359198336] #progress_metric: host=algo-1, completed 2.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:25 INFO 139780359198336] #quality_metric: host=algo-1, epoch=7, train loss <loss>=3.046127275987105\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:25 INFO 139780359198336] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:25 INFO 139780359198336] Saved checkpoint to \"/opt/ml/model/state_1698bf54-952d-4843-9771-38d288e2d964-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524425.3894057, \"EndTime\": 1617524425.5798085, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 189.78548049926758, \"count\": 1, \"min\": 189.78548049926758, \"max\": 189.78548049926758}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:29 INFO 139780359198336] Epoch[8] Batch[0] avg_epoch_loss=3.137933\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:29 INFO 139780359198336] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=3.137932538986206\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:34 INFO 139780359198336] Epoch[8] Batch[5] avg_epoch_loss=3.077047\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:34 INFO 139780359198336] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=3.077047069867452\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:34 INFO 139780359198336] Epoch[8] Batch [5]#011Speed: 62.55 samples/sec#011loss=3.077047\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:39 INFO 139780359198336] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524425.5798805, \"EndTime\": 1617524439.247509, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13667.567491531372, \"count\": 1, \"min\": 13667.567491531372, \"max\": 13667.567491531372}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:39 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.2893643072196 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:39 INFO 139780359198336] #progress_metric: host=algo-1, completed 2.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:39 INFO 139780359198336] #quality_metric: host=algo-1, epoch=8, train loss <loss>=3.0523115158081056\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:39 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:43 INFO 139780359198336] Epoch[9] Batch[0] avg_epoch_loss=2.942095\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:43 INFO 139780359198336] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=2.9420948028564453\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:48 INFO 139780359198336] Epoch[9] Batch[5] avg_epoch_loss=2.949333\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:48 INFO 139780359198336] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=2.949333349863688\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:48 INFO 139780359198336] Epoch[9] Batch [5]#011Speed: 62.36 samples/sec#011loss=2.949333\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:52 INFO 139780359198336] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524439.2475789, \"EndTime\": 1617524452.731695, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13483.556747436523, \"count\": 1, \"min\": 13483.556747436523, \"max\": 13483.556747436523}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:52 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=47.09402999887949 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:52 INFO 139780359198336] #progress_metric: host=algo-1, completed 2.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:52 INFO 139780359198336] #quality_metric: host=algo-1, epoch=9, train loss <loss>=2.9746022701263426\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:52 INFO 139780359198336] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:52 INFO 139780359198336] Saved checkpoint to \"/opt/ml/model/state_a0425e49-5591-4b93-8134-5969005589d7-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524452.7317677, \"EndTime\": 1617524452.9174843, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 184.92960929870605, \"count\": 1, \"min\": 184.92960929870605, \"max\": 184.92960929870605}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:56 INFO 139780359198336] Epoch[10] Batch[0] avg_epoch_loss=3.065210\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:20:56 INFO 139780359198336] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=3.0652101039886475\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:02 INFO 139780359198336] Epoch[10] Batch[5] avg_epoch_loss=2.988921\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:02 INFO 139780359198336] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=2.9889208873113\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:02 INFO 139780359198336] Epoch[10] Batch [5]#011Speed: 60.02 samples/sec#011loss=2.988921\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:08 INFO 139780359198336] Epoch[10] Batch[10] avg_epoch_loss=2.950973\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:08 INFO 139780359198336] #quality_metric: host=algo-1, epoch=10, batch=10 train loss <loss>=2.9054352283477782\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:08 INFO 139780359198336] Epoch[10] Batch [10]#011Speed: 51.19 samples/sec#011loss=2.905435\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:08 INFO 139780359198336] processed a total of 690 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524452.9175522, \"EndTime\": 1617524468.4875531, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 15569.942712783813, \"count\": 1, \"min\": 15569.942712783813, \"max\": 15569.942712783813}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:08 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.315878478867646 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:08 INFO 139780359198336] #progress_metric: host=algo-1, completed 2.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:08 INFO 139780359198336] #quality_metric: host=algo-1, epoch=10, train loss <loss>=2.950972860509699\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:08 INFO 139780359198336] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:08 INFO 139780359198336] Saved checkpoint to \"/opt/ml/model/state_c85f2561-8c7f-44f9-9d84-6f5b8e4afdcd-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524468.4876194, \"EndTime\": 1617524468.6895962, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 201.6277313232422, \"count\": 1, \"min\": 201.6277313232422, \"max\": 201.6277313232422}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:12 INFO 139780359198336] Epoch[11] Batch[0] avg_epoch_loss=2.843486\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:12 INFO 139780359198336] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=2.8434860706329346\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:18 INFO 139780359198336] Epoch[11] Batch[5] avg_epoch_loss=2.881361\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:18 INFO 139780359198336] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=2.8813607692718506\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:18 INFO 139780359198336] Epoch[11] Batch [5]#011Speed: 62.08 samples/sec#011loss=2.881361\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:22 INFO 139780359198336] processed a total of 600 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524468.689668, \"EndTime\": 1617524482.2493362, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13559.558391571045, \"count\": 1, \"min\": 13559.558391571045, \"max\": 13559.558391571045}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:22 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.24879142247549 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:22 INFO 139780359198336] #progress_metric: host=algo-1, completed 3.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:22 INFO 139780359198336] #quality_metric: host=algo-1, epoch=11, train loss <loss>=2.8470580339431764\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:22 INFO 139780359198336] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:22 INFO 139780359198336] Saved checkpoint to \"/opt/ml/model/state_7e78c019-9f0b-4225-a2e7-9330c0947d98-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524482.2494333, \"EndTime\": 1617524482.436356, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 186.4035129547119, \"count\": 1, \"min\": 186.4035129547119, \"max\": 186.4035129547119}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:26 INFO 139780359198336] Epoch[12] Batch[0] avg_epoch_loss=3.051197\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:26 INFO 139780359198336] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=3.051197052001953\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 08:21:31 INFO 139780359198336] Epoch[12] Batch[5] avg_epoch_loss=2.874444\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:31 INFO 139780359198336] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=2.8744444449742637\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:31 INFO 139780359198336] Epoch[12] Batch [5]#011Speed: 62.67 samples/sec#011loss=2.874444\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:37 INFO 139780359198336] Epoch[12] Batch[10] avg_epoch_loss=2.804211\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:37 INFO 139780359198336] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=2.71993145942688\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:37 INFO 139780359198336] Epoch[12] Batch [10]#011Speed: 59.74 samples/sec#011loss=2.719931\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:37 INFO 139780359198336] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524482.4364154, \"EndTime\": 1617524497.0563815, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14619.868278503418, \"count\": 1, \"min\": 14619.868278503418, \"max\": 14619.868278503418}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:37 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.254421773455576 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:37 INFO 139780359198336] #progress_metric: host=algo-1, completed 3.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:37 INFO 139780359198336] #quality_metric: host=algo-1, epoch=12, train loss <loss>=2.8042112697254526\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:37 INFO 139780359198336] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:37 INFO 139780359198336] Saved checkpoint to \"/opt/ml/model/state_dcaf04c9-14e8-4729-825c-6112cbf7bf15-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524497.05645, \"EndTime\": 1617524497.2541952, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 197.01051712036133, \"count\": 1, \"min\": 197.01051712036133, \"max\": 197.01051712036133}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:41 INFO 139780359198336] Epoch[13] Batch[0] avg_epoch_loss=2.881682\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:41 INFO 139780359198336] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=2.8816823959350586\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:46 INFO 139780359198336] Epoch[13] Batch[5] avg_epoch_loss=2.861934\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:46 INFO 139780359198336] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=2.861934026082357\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:46 INFO 139780359198336] Epoch[13] Batch [5]#011Speed: 62.26 samples/sec#011loss=2.861934\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:51 INFO 139780359198336] Epoch[13] Batch[10] avg_epoch_loss=2.783694\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:51 INFO 139780359198336] #quality_metric: host=algo-1, epoch=13, batch=10 train loss <loss>=2.6898053646087647\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:51 INFO 139780359198336] Epoch[13] Batch [10]#011Speed: 59.60 samples/sec#011loss=2.689805\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:51 INFO 139780359198336] processed a total of 669 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524497.2542663, \"EndTime\": 1617524511.8557854, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14601.44829750061, \"count\": 1, \"min\": 14601.44829750061, \"max\": 14601.44829750061}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:51 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.8170698067012 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:51 INFO 139780359198336] #progress_metric: host=algo-1, completed 3.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:51 INFO 139780359198336] #quality_metric: host=algo-1, epoch=13, train loss <loss>=2.783693725412542\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:51 INFO 139780359198336] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:52 INFO 139780359198336] Saved checkpoint to \"/opt/ml/model/state_82dd82a3-79e0-4ec6-8ad3-075444906d3c-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524511.8558471, \"EndTime\": 1617524512.0466678, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 190.19389152526855, \"count\": 1, \"min\": 190.19389152526855, \"max\": 190.19389152526855}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:56 INFO 139780359198336] Epoch[14] Batch[0] avg_epoch_loss=2.937720\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:21:56 INFO 139780359198336] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=2.9377198219299316\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:01 INFO 139780359198336] Epoch[14] Batch[5] avg_epoch_loss=2.822860\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:01 INFO 139780359198336] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=2.822859843571981\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:01 INFO 139780359198336] Epoch[14] Batch [5]#011Speed: 61.50 samples/sec#011loss=2.822860\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:06 INFO 139780359198336] processed a total of 614 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524512.0467384, \"EndTime\": 1617524526.2708454, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14224.041223526001, \"count\": 1, \"min\": 14224.041223526001, \"max\": 14224.041223526001}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:06 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.165965549394585 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:06 INFO 139780359198336] #progress_metric: host=algo-1, completed 3.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:06 INFO 139780359198336] #quality_metric: host=algo-1, epoch=14, train loss <loss>=2.863657069206238\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:06 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:10 INFO 139780359198336] Epoch[15] Batch[0] avg_epoch_loss=3.027567\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:10 INFO 139780359198336] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=3.02756667137146\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:15 INFO 139780359198336] Epoch[15] Batch[5] avg_epoch_loss=2.893088\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:15 INFO 139780359198336] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=2.89308754603068\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:15 INFO 139780359198336] Epoch[15] Batch [5]#011Speed: 62.44 samples/sec#011loss=2.893088\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:21 INFO 139780359198336] Epoch[15] Batch[10] avg_epoch_loss=2.928214\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:21 INFO 139780359198336] #quality_metric: host=algo-1, epoch=15, batch=10 train loss <loss>=2.9703650951385496\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:21 INFO 139780359198336] Epoch[15] Batch [10]#011Speed: 60.40 samples/sec#011loss=2.970365\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:21 INFO 139780359198336] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524526.270939, \"EndTime\": 1617524541.1571543, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14885.189771652222, \"count\": 1, \"min\": 14885.189771652222, \"max\": 14885.189771652222}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:21 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.801602454478186 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:21 INFO 139780359198336] #progress_metric: host=algo-1, completed 4.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:21 INFO 139780359198336] #quality_metric: host=algo-1, epoch=15, train loss <loss>=2.9282137047160757\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:21 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:25 INFO 139780359198336] Epoch[16] Batch[0] avg_epoch_loss=2.736115\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:25 INFO 139780359198336] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=2.736114501953125\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:30 INFO 139780359198336] Epoch[16] Batch[5] avg_epoch_loss=2.794964\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:30 INFO 139780359198336] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=2.794963796933492\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:30 INFO 139780359198336] Epoch[16] Batch [5]#011Speed: 62.91 samples/sec#011loss=2.794964\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:34 INFO 139780359198336] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524541.157233, \"EndTime\": 1617524554.6944737, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13536.917686462402, \"count\": 1, \"min\": 13536.917686462402, \"max\": 13536.917686462402}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:34 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.87414871742523 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:34 INFO 139780359198336] #progress_metric: host=algo-1, completed 4.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:34 INFO 139780359198336] #quality_metric: host=algo-1, epoch=16, train loss <loss>=2.83234703540802\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:34 INFO 139780359198336] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 08:22:38 INFO 139780359198336] Epoch[17] Batch[0] avg_epoch_loss=2.806967\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:38 INFO 139780359198336] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=2.80696702003479\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:44 INFO 139780359198336] Epoch[17] Batch[5] avg_epoch_loss=2.802652\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:44 INFO 139780359198336] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=2.802651802698771\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:44 INFO 139780359198336] Epoch[17] Batch [5]#011Speed: 62.80 samples/sec#011loss=2.802652\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:48 INFO 139780359198336] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524554.6945581, \"EndTime\": 1617524568.192489, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13497.579574584961, \"count\": 1, \"min\": 13497.579574584961, \"max\": 13497.579574584961}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:48 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=47.04512699271181 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:48 INFO 139780359198336] #progress_metric: host=algo-1, completed 4.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:48 INFO 139780359198336] #quality_metric: host=algo-1, epoch=17, train loss <loss>=2.7885918378829957\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:48 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:52 INFO 139780359198336] Epoch[18] Batch[0] avg_epoch_loss=2.729851\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:52 INFO 139780359198336] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=2.729851007461548\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:57 INFO 139780359198336] Epoch[18] Batch[5] avg_epoch_loss=2.744912\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:57 INFO 139780359198336] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=2.7449123859405518\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:22:57 INFO 139780359198336] Epoch[18] Batch [5]#011Speed: 63.15 samples/sec#011loss=2.744912\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:02 INFO 139780359198336] Epoch[18] Batch[10] avg_epoch_loss=2.758602\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:02 INFO 139780359198336] #quality_metric: host=algo-1, epoch=18, batch=10 train loss <loss>=2.7750291347503664\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:02 INFO 139780359198336] Epoch[18] Batch [10]#011Speed: 57.72 samples/sec#011loss=2.775029\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:02 INFO 139780359198336] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524568.192557, \"EndTime\": 1617524582.8211343, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14628.111362457275, \"count\": 1, \"min\": 14628.111362457275, \"max\": 14628.111362457275}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:02 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.665207658162345 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:02 INFO 139780359198336] #progress_metric: host=algo-1, completed 4.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:02 INFO 139780359198336] #quality_metric: host=algo-1, epoch=18, train loss <loss>=2.7586018172177402\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:02 INFO 139780359198336] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:03 INFO 139780359198336] Saved checkpoint to \"/opt/ml/model/state_b53ba9ac-b076-4a19-b0a6-d063c2efb094-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524582.821197, \"EndTime\": 1617524583.023051, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 201.44128799438477, \"count\": 1, \"min\": 201.44128799438477, \"max\": 201.44128799438477}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:07 INFO 139780359198336] Epoch[19] Batch[0] avg_epoch_loss=2.695265\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:07 INFO 139780359198336] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=2.695265054702759\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:12 INFO 139780359198336] Epoch[19] Batch[5] avg_epoch_loss=2.746622\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:12 INFO 139780359198336] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=2.7466219663619995\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:12 INFO 139780359198336] Epoch[19] Batch [5]#011Speed: 61.21 samples/sec#011loss=2.746622\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:16 INFO 139780359198336] processed a total of 594 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524583.0231454, \"EndTime\": 1617524596.9503906, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13927.153587341309, \"count\": 1, \"min\": 13927.153587341309, \"max\": 13927.153587341309}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:16 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=42.65001132664054 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:16 INFO 139780359198336] #progress_metric: host=algo-1, completed 5.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:16 INFO 139780359198336] #quality_metric: host=algo-1, epoch=19, train loss <loss>=2.7446237325668337\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:16 INFO 139780359198336] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:17 INFO 139780359198336] Saved checkpoint to \"/opt/ml/model/state_3b41e7fe-3320-4a86-99f2-4292a7de9cfd-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524596.95049, \"EndTime\": 1617524597.1367629, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 185.78100204467773, \"count\": 1, \"min\": 185.78100204467773, \"max\": 185.78100204467773}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:21 INFO 139780359198336] Epoch[20] Batch[0] avg_epoch_loss=2.670014\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:21 INFO 139780359198336] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=2.670013666152954\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:26 INFO 139780359198336] Epoch[20] Batch[5] avg_epoch_loss=2.719972\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:26 INFO 139780359198336] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=2.719971696535746\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:26 INFO 139780359198336] Epoch[20] Batch [5]#011Speed: 62.19 samples/sec#011loss=2.719972\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:30 INFO 139780359198336] processed a total of 616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524597.1368296, \"EndTime\": 1617524610.6245327, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13487.64157295227, \"count\": 1, \"min\": 13487.64157295227, \"max\": 13487.64157295227}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:30 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.67092155806654 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:30 INFO 139780359198336] #progress_metric: host=algo-1, completed 5.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:30 INFO 139780359198336] #quality_metric: host=algo-1, epoch=20, train loss <loss>=2.735333490371704\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:30 INFO 139780359198336] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:30 INFO 139780359198336] Saved checkpoint to \"/opt/ml/model/state_fcd7e325-99e5-488e-b9b8-a78fded63026-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524610.624613, \"EndTime\": 1617524610.8028917, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 177.6578426361084, \"count\": 1, \"min\": 177.6578426361084, \"max\": 177.6578426361084}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:34 INFO 139780359198336] Epoch[21] Batch[0] avg_epoch_loss=2.677210\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:34 INFO 139780359198336] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=2.6772098541259766\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:40 INFO 139780359198336] Epoch[21] Batch[5] avg_epoch_loss=2.760337\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:40 INFO 139780359198336] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=2.7603370348612466\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:40 INFO 139780359198336] Epoch[21] Batch [5]#011Speed: 61.56 samples/sec#011loss=2.760337\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:44 INFO 139780359198336] processed a total of 613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524610.802958, \"EndTime\": 1617524624.2902277, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13487.210273742676, \"count\": 1, \"min\": 13487.210273742676, \"max\": 13487.210273742676}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:44 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.45006487542151 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:44 INFO 139780359198336] #progress_metric: host=algo-1, completed 5.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:44 INFO 139780359198336] #quality_metric: host=algo-1, epoch=21, train loss <loss>=2.7282397508621217\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:44 INFO 139780359198336] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:44 INFO 139780359198336] Saved checkpoint to \"/opt/ml/model/state_0dd66b77-586b-459f-b4a5-7a6c754745cd-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524624.290313, \"EndTime\": 1617524624.480745, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 190.00482559204102, \"count\": 1, \"min\": 190.00482559204102, \"max\": 190.00482559204102}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:48 INFO 139780359198336] Epoch[22] Batch[0] avg_epoch_loss=2.724537\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:48 INFO 139780359198336] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=2.724536657333374\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 08:23:53 INFO 139780359198336] Epoch[22] Batch[5] avg_epoch_loss=2.773840\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:53 INFO 139780359198336] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=2.773839553197225\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:53 INFO 139780359198336] Epoch[22] Batch [5]#011Speed: 62.92 samples/sec#011loss=2.773840\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:57 INFO 139780359198336] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524624.4808135, \"EndTime\": 1617524637.8911138, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13410.211563110352, \"count\": 1, \"min\": 13410.211563110352, \"max\": 13410.211563110352}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:57 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.68038218032405 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:57 INFO 139780359198336] #progress_metric: host=algo-1, completed 5.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:57 INFO 139780359198336] #quality_metric: host=algo-1, epoch=22, train loss <loss>=2.7575501918792726\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:23:57 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:02 INFO 139780359198336] Epoch[23] Batch[0] avg_epoch_loss=2.757384\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:02 INFO 139780359198336] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=2.7573843002319336\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:08 INFO 139780359198336] Epoch[23] Batch[5] avg_epoch_loss=2.711913\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:08 INFO 139780359198336] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=2.7119125525156655\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:08 INFO 139780359198336] Epoch[23] Batch [5]#011Speed: 54.75 samples/sec#011loss=2.711913\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:12 INFO 139780359198336] processed a total of 608 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524637.8911905, \"EndTime\": 1617524652.379221, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14487.497329711914, \"count\": 1, \"min\": 14487.497329711914, \"max\": 14487.497329711914}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:12 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=41.9669204201608 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:12 INFO 139780359198336] #progress_metric: host=algo-1, completed 6.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:12 INFO 139780359198336] #quality_metric: host=algo-1, epoch=23, train loss <loss>=2.6856690883636474\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:12 INFO 139780359198336] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:12 INFO 139780359198336] Saved checkpoint to \"/opt/ml/model/state_aed16cf9-9d70-4d9b-a8ec-64a1189217fb-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524652.379293, \"EndTime\": 1617524652.5598922, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 180.100679397583, \"count\": 1, \"min\": 180.100679397583, \"max\": 180.100679397583}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:16 INFO 139780359198336] Epoch[24] Batch[0] avg_epoch_loss=2.796047\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:16 INFO 139780359198336] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=2.796046733856201\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:21 INFO 139780359198336] Epoch[24] Batch[5] avg_epoch_loss=2.674112\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:21 INFO 139780359198336] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=2.6741124788920083\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:21 INFO 139780359198336] Epoch[24] Batch [5]#011Speed: 62.82 samples/sec#011loss=2.674112\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:25 INFO 139780359198336] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524652.5599563, \"EndTime\": 1617524665.9724364, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13412.418842315674, \"count\": 1, \"min\": 13412.418842315674, \"max\": 13412.418842315674}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:25 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.67279963226808 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:25 INFO 139780359198336] #progress_metric: host=algo-1, completed 6.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:25 INFO 139780359198336] #quality_metric: host=algo-1, epoch=24, train loss <loss>=2.666618084907532\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:25 INFO 139780359198336] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:26 INFO 139780359198336] Saved checkpoint to \"/opt/ml/model/state_e2bb9e8d-c624-4de6-9315-292ec46f292d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524665.972509, \"EndTime\": 1617524666.2086082, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 235.6588840484619, \"count\": 1, \"min\": 235.6588840484619, \"max\": 235.6588840484619}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:30 INFO 139780359198336] Epoch[25] Batch[0] avg_epoch_loss=2.857439\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:30 INFO 139780359198336] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=2.8574390411376953\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:35 INFO 139780359198336] Epoch[25] Batch[5] avg_epoch_loss=2.791257\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:35 INFO 139780359198336] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=2.7912572622299194\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:35 INFO 139780359198336] Epoch[25] Batch [5]#011Speed: 62.82 samples/sec#011loss=2.791257\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:40 INFO 139780359198336] Epoch[25] Batch[10] avg_epoch_loss=2.750684\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:40 INFO 139780359198336] #quality_metric: host=algo-1, epoch=25, batch=10 train loss <loss>=2.701996994018555\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:40 INFO 139780359198336] Epoch[25] Batch [10]#011Speed: 57.58 samples/sec#011loss=2.701997\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:40 INFO 139780359198336] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524666.2086713, \"EndTime\": 1617524680.9150982, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14706.343173980713, \"count\": 1, \"min\": 14706.343173980713, \"max\": 14706.343173980713}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:40 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.69418957795523 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:40 INFO 139780359198336] #progress_metric: host=algo-1, completed 6.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:40 INFO 139780359198336] #quality_metric: host=algo-1, epoch=25, train loss <loss>=2.7506844130429355\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:40 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:45 INFO 139780359198336] Epoch[26] Batch[0] avg_epoch_loss=2.922192\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:45 INFO 139780359198336] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=2.922191858291626\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:50 INFO 139780359198336] Epoch[26] Batch[5] avg_epoch_loss=2.763714\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:50 INFO 139780359198336] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=2.7637139161427817\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:50 INFO 139780359198336] Epoch[26] Batch [5]#011Speed: 62.54 samples/sec#011loss=2.763714\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:55 INFO 139780359198336] Epoch[26] Batch[10] avg_epoch_loss=2.842013\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:55 INFO 139780359198336] #quality_metric: host=algo-1, epoch=26, batch=10 train loss <loss>=2.935972309112549\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:55 INFO 139780359198336] Epoch[26] Batch [10]#011Speed: 60.61 samples/sec#011loss=2.935972\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:55 INFO 139780359198336] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524680.915166, \"EndTime\": 1617524695.4546864, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14539.089441299438, \"count\": 1, \"min\": 14539.089441299438, \"max\": 14539.089441299438}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:55 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.98183681985809 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:55 INFO 139780359198336] #progress_metric: host=algo-1, completed 6.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:55 INFO 139780359198336] #quality_metric: host=algo-1, epoch=26, train loss <loss>=2.842013185674494\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:55 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:59 INFO 139780359198336] Epoch[27] Batch[0] avg_epoch_loss=2.656644\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:24:59 INFO 139780359198336] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=2.656644105911255\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:05 INFO 139780359198336] Epoch[27] Batch[5] avg_epoch_loss=2.701566\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:05 INFO 139780359198336] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=2.7015655438105264\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:05 INFO 139780359198336] Epoch[27] Batch [5]#011Speed: 58.80 samples/sec#011loss=2.701566\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 08:25:09 INFO 139780359198336] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524695.4547644, \"EndTime\": 1617524709.7612092, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14305.98521232605, \"count\": 1, \"min\": 14305.98521232605, \"max\": 14305.98521232605}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:09 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.316588973428665 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:09 INFO 139780359198336] #progress_metric: host=algo-1, completed 7.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:09 INFO 139780359198336] #quality_metric: host=algo-1, epoch=27, train loss <loss>=2.7013954401016234\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:09 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:14 INFO 139780359198336] Epoch[28] Batch[0] avg_epoch_loss=2.672944\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:14 INFO 139780359198336] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=2.6729443073272705\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:19 INFO 139780359198336] Epoch[28] Batch[5] avg_epoch_loss=2.651798\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:19 INFO 139780359198336] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=2.6517980496088662\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:19 INFO 139780359198336] Epoch[28] Batch [5]#011Speed: 62.65 samples/sec#011loss=2.651798\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:23 INFO 139780359198336] processed a total of 614 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524709.761342, \"EndTime\": 1617524723.2831073, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13521.332025527954, \"count\": 1, \"min\": 13521.332025527954, \"max\": 13521.332025527954}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:23 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.409145198100255 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:23 INFO 139780359198336] #progress_metric: host=algo-1, completed 7.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:23 INFO 139780359198336] #quality_metric: host=algo-1, epoch=28, train loss <loss>=2.684542727470398\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:23 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:27 INFO 139780359198336] Epoch[29] Batch[0] avg_epoch_loss=2.752709\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:27 INFO 139780359198336] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=2.752708911895752\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:32 INFO 139780359198336] Epoch[29] Batch[5] avg_epoch_loss=2.720976\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:32 INFO 139780359198336] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=2.7209759950637817\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:32 INFO 139780359198336] Epoch[29] Batch [5]#011Speed: 63.02 samples/sec#011loss=2.720976\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:36 INFO 139780359198336] processed a total of 602 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524723.2832286, \"EndTime\": 1617524736.6997964, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13416.183710098267, \"count\": 1, \"min\": 13416.183710098267, \"max\": 13416.183710098267}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:36 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.87084472991831 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:36 INFO 139780359198336] #progress_metric: host=algo-1, completed 7.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:36 INFO 139780359198336] #quality_metric: host=algo-1, epoch=29, train loss <loss>=2.6718294858932494\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:36 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:40 INFO 139780359198336] Epoch[30] Batch[0] avg_epoch_loss=2.679895\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:40 INFO 139780359198336] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=2.6798946857452393\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:46 INFO 139780359198336] Epoch[30] Batch[5] avg_epoch_loss=2.646000\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:46 INFO 139780359198336] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=2.6460002660751343\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:46 INFO 139780359198336] Epoch[30] Batch [5]#011Speed: 60.57 samples/sec#011loss=2.646000\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:50 INFO 139780359198336] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524736.699869, \"EndTime\": 1617524750.3128169, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13612.475395202637, \"count\": 1, \"min\": 13612.475395202637, \"max\": 13612.475395202637}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:50 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.133656025583676 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:50 INFO 139780359198336] #progress_metric: host=algo-1, completed 7.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:50 INFO 139780359198336] #quality_metric: host=algo-1, epoch=30, train loss <loss>=2.6249887943267822\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:50 INFO 139780359198336] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:50 INFO 139780359198336] Saved checkpoint to \"/opt/ml/model/state_49b6691a-d15b-482e-a51a-754e24b96d56-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524750.3129284, \"EndTime\": 1617524750.5005286, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 187.2103214263916, \"count\": 1, \"min\": 187.2103214263916, \"max\": 187.2103214263916}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:54 INFO 139780359198336] Epoch[31] Batch[0] avg_epoch_loss=2.686963\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:54 INFO 139780359198336] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=2.686962604522705\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:59 INFO 139780359198336] Epoch[31] Batch[5] avg_epoch_loss=2.693060\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:59 INFO 139780359198336] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=2.6930601596832275\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:25:59 INFO 139780359198336] Epoch[31] Batch [5]#011Speed: 62.88 samples/sec#011loss=2.693060\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:05 INFO 139780359198336] Epoch[31] Batch[10] avg_epoch_loss=2.702204\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:05 INFO 139780359198336] #quality_metric: host=algo-1, epoch=31, batch=10 train loss <loss>=2.7131762981414793\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:05 INFO 139780359198336] Epoch[31] Batch [10]#011Speed: 55.67 samples/sec#011loss=2.713176\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:05 INFO 139780359198336] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524750.5005968, \"EndTime\": 1617524765.4138074, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14913.144588470459, \"count\": 1, \"min\": 14913.144588470459, \"max\": 14913.144588470459}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:05 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.65827306023169 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:05 INFO 139780359198336] #progress_metric: host=algo-1, completed 8.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:05 INFO 139780359198336] #quality_metric: host=algo-1, epoch=31, train loss <loss>=2.702203858982433\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:05 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:09 INFO 139780359198336] Epoch[32] Batch[0] avg_epoch_loss=2.737191\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:09 INFO 139780359198336] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=2.7371909618377686\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:14 INFO 139780359198336] Epoch[32] Batch[5] avg_epoch_loss=2.683565\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:14 INFO 139780359198336] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=2.6835652589797974\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:14 INFO 139780359198336] Epoch[32] Batch [5]#011Speed: 61.98 samples/sec#011loss=2.683565\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:20 INFO 139780359198336] Epoch[32] Batch[10] avg_epoch_loss=2.657440\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:20 INFO 139780359198336] #quality_metric: host=algo-1, epoch=32, batch=10 train loss <loss>=2.6260895252227785\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:20 INFO 139780359198336] Epoch[32] Batch [10]#011Speed: 60.38 samples/sec#011loss=2.626090\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:20 INFO 139780359198336] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524765.4138777, \"EndTime\": 1617524780.2728343, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14858.489990234375, \"count\": 1, \"min\": 14858.489990234375, \"max\": 14858.489990234375}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:20 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.67845150649959 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:20 INFO 139780359198336] #progress_metric: host=algo-1, completed 8.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:20 INFO 139780359198336] #quality_metric: host=algo-1, epoch=32, train loss <loss>=2.6574399254538794\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:20 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:24 INFO 139780359198336] Epoch[33] Batch[0] avg_epoch_loss=2.697135\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:24 INFO 139780359198336] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=2.6971354484558105\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 08:26:29 INFO 139780359198336] Epoch[33] Batch[5] avg_epoch_loss=2.667426\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:29 INFO 139780359198336] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=2.667426029841105\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:29 INFO 139780359198336] Epoch[33] Batch [5]#011Speed: 63.15 samples/sec#011loss=2.667426\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:33 INFO 139780359198336] processed a total of 613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524780.272899, \"EndTime\": 1617524793.6532664, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13379.93049621582, \"count\": 1, \"min\": 13379.93049621582, \"max\": 13379.93049621582}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:33 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.81403688279034 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:33 INFO 139780359198336] #progress_metric: host=algo-1, completed 8.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:33 INFO 139780359198336] #quality_metric: host=algo-1, epoch=33, train loss <loss>=2.70826678276062\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:33 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:37 INFO 139780359198336] Epoch[34] Batch[0] avg_epoch_loss=2.677197\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:37 INFO 139780359198336] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=2.6771974563598633\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:43 INFO 139780359198336] Epoch[34] Batch[5] avg_epoch_loss=2.691972\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:43 INFO 139780359198336] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=2.6919716596603394\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:43 INFO 139780359198336] Epoch[34] Batch [5]#011Speed: 57.70 samples/sec#011loss=2.691972\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:47 INFO 139780359198336] processed a total of 598 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524793.6534607, \"EndTime\": 1617524807.7325017, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14078.609228134155, \"count\": 1, \"min\": 14078.609228134155, \"max\": 14078.609228134155}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:47 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=42.475411752736065 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:47 INFO 139780359198336] #progress_metric: host=algo-1, completed 8.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:47 INFO 139780359198336] #quality_metric: host=algo-1, epoch=34, train loss <loss>=2.576260030269623\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:47 INFO 139780359198336] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:47 INFO 139780359198336] Saved checkpoint to \"/opt/ml/model/state_c72c4f2a-87e4-48ae-8fe7-9274cb121caa-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524807.732574, \"EndTime\": 1617524807.914097, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 180.72199821472168, \"count\": 1, \"min\": 180.72199821472168, \"max\": 180.72199821472168}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:52 INFO 139780359198336] Epoch[35] Batch[0] avg_epoch_loss=2.742382\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:52 INFO 139780359198336] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=2.7423818111419678\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:57 INFO 139780359198336] Epoch[35] Batch[5] avg_epoch_loss=2.660543\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:57 INFO 139780359198336] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=2.660542925198873\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:26:57 INFO 139780359198336] Epoch[35] Batch [5]#011Speed: 62.67 samples/sec#011loss=2.660543\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:01 INFO 139780359198336] processed a total of 594 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524807.9141667, \"EndTime\": 1617524821.511206, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13596.970558166504, \"count\": 1, \"min\": 13596.970558166504, \"max\": 13596.970558166504}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:01 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.68582034758139 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:01 INFO 139780359198336] #progress_metric: host=algo-1, completed 9.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:01 INFO 139780359198336] #quality_metric: host=algo-1, epoch=35, train loss <loss>=2.6093111276626586\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:01 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:06 INFO 139780359198336] Epoch[36] Batch[0] avg_epoch_loss=2.559037\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:06 INFO 139780359198336] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=2.55903697013855\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:11 INFO 139780359198336] Epoch[36] Batch[5] avg_epoch_loss=2.618712\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:11 INFO 139780359198336] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=2.6187124252319336\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:11 INFO 139780359198336] Epoch[36] Batch [5]#011Speed: 62.79 samples/sec#011loss=2.618712\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:15 INFO 139780359198336] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524821.5112875, \"EndTime\": 1617524835.404325, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13892.55142211914, \"count\": 1, \"min\": 13892.55142211914, \"max\": 13892.55142211914}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:15 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.63552632312825 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:15 INFO 139780359198336] #progress_metric: host=algo-1, completed 9.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:15 INFO 139780359198336] #quality_metric: host=algo-1, epoch=36, train loss <loss>=2.6435168266296385\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:15 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:19 INFO 139780359198336] Epoch[37] Batch[0] avg_epoch_loss=2.581519\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:19 INFO 139780359198336] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=2.58151912689209\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:24 INFO 139780359198336] Epoch[37] Batch[5] avg_epoch_loss=2.651758\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:24 INFO 139780359198336] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=2.6517579158147178\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:24 INFO 139780359198336] Epoch[37] Batch [5]#011Speed: 62.98 samples/sec#011loss=2.651758\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:29 INFO 139780359198336] Epoch[37] Batch[10] avg_epoch_loss=2.632265\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:29 INFO 139780359198336] #quality_metric: host=algo-1, epoch=37, batch=10 train loss <loss>=2.6088725566864013\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:29 INFO 139780359198336] Epoch[37] Batch [10]#011Speed: 58.85 samples/sec#011loss=2.608873\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:29 INFO 139780359198336] processed a total of 698 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524835.4044232, \"EndTime\": 1617524849.9320817, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14527.115821838379, \"count\": 1, \"min\": 14527.115821838379, \"max\": 14527.115821838379}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:29 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=48.04776298120809 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:29 INFO 139780359198336] #progress_metric: host=algo-1, completed 9.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:29 INFO 139780359198336] #quality_metric: host=algo-1, epoch=37, train loss <loss>=2.632264570756392\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:29 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:34 INFO 139780359198336] Epoch[38] Batch[0] avg_epoch_loss=2.597550\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:34 INFO 139780359198336] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=2.5975499153137207\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:39 INFO 139780359198336] Epoch[38] Batch[5] avg_epoch_loss=2.584715\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:39 INFO 139780359198336] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=2.584714968999227\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:39 INFO 139780359198336] Epoch[38] Batch [5]#011Speed: 63.60 samples/sec#011loss=2.584715\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:43 INFO 139780359198336] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524849.9321475, \"EndTime\": 1617524863.2791793, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13346.712827682495, \"count\": 1, \"min\": 13346.712827682495, \"max\": 13346.712827682495}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:43 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.30301671828585 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:43 INFO 139780359198336] #progress_metric: host=algo-1, completed 9.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:43 INFO 139780359198336] #quality_metric: host=algo-1, epoch=38, train loss <loss>=2.55722496509552\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:43 INFO 139780359198336] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:43 INFO 139780359198336] Saved checkpoint to \"/opt/ml/model/state_f9f51917-f29f-408e-9183-5a7f66a1a452-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524863.2792518, \"EndTime\": 1617524863.4619536, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 182.0821762084961, \"count\": 1, \"min\": 182.0821762084961, \"max\": 182.0821762084961}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:47 INFO 139780359198336] Epoch[39] Batch[0] avg_epoch_loss=2.648503\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:47 INFO 139780359198336] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=2.648502826690674\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 08:27:52 INFO 139780359198336] Epoch[39] Batch[5] avg_epoch_loss=2.636568\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:52 INFO 139780359198336] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=2.636567751566569\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:52 INFO 139780359198336] Epoch[39] Batch [5]#011Speed: 62.94 samples/sec#011loss=2.636568\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:57 INFO 139780359198336] Epoch[39] Batch[10] avg_epoch_loss=2.574645\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:57 INFO 139780359198336] #quality_metric: host=algo-1, epoch=39, batch=10 train loss <loss>=2.5003381729125977\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:57 INFO 139780359198336] Epoch[39] Batch [10]#011Speed: 61.42 samples/sec#011loss=2.500338\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:57 INFO 139780359198336] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524863.46202, \"EndTime\": 1617524877.9291794, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14467.100858688354, \"count\": 1, \"min\": 14467.100858688354, \"max\": 14467.100858688354}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:57 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.9292294385641 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:57 INFO 139780359198336] #progress_metric: host=algo-1, completed 10.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:57 INFO 139780359198336] #quality_metric: host=algo-1, epoch=39, train loss <loss>=2.5746452158147637\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:27:57 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:02 INFO 139780359198336] Epoch[40] Batch[0] avg_epoch_loss=2.557553\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:02 INFO 139780359198336] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=2.5575528144836426\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:07 INFO 139780359198336] Epoch[40] Batch[5] avg_epoch_loss=2.628108\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:07 INFO 139780359198336] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=2.6281079053878784\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:07 INFO 139780359198336] Epoch[40] Batch [5]#011Speed: 54.94 samples/sec#011loss=2.628108\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:13 INFO 139780359198336] Epoch[40] Batch[10] avg_epoch_loss=2.637918\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:13 INFO 139780359198336] #quality_metric: host=algo-1, epoch=40, batch=10 train loss <loss>=2.6496910572052004\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:13 INFO 139780359198336] Epoch[40] Batch [10]#011Speed: 59.44 samples/sec#011loss=2.649691\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:13 INFO 139780359198336] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524877.9292448, \"EndTime\": 1617524893.3215988, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 15392.004013061523, \"count\": 1, \"min\": 15392.004013061523, \"max\": 15392.004013061523}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:13 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=42.68419947403623 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:13 INFO 139780359198336] #progress_metric: host=algo-1, completed 10.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:13 INFO 139780359198336] #quality_metric: host=algo-1, epoch=40, train loss <loss>=2.6379184289412065\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:13 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:17 INFO 139780359198336] Epoch[41] Batch[0] avg_epoch_loss=2.512137\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:17 INFO 139780359198336] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=2.512136697769165\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:22 INFO 139780359198336] Epoch[41] Batch[5] avg_epoch_loss=2.641776\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:22 INFO 139780359198336] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=2.6417758067448935\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:22 INFO 139780359198336] Epoch[41] Batch [5]#011Speed: 62.50 samples/sec#011loss=2.641776\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:27 INFO 139780359198336] Epoch[41] Batch[10] avg_epoch_loss=2.623573\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:27 INFO 139780359198336] #quality_metric: host=algo-1, epoch=41, batch=10 train loss <loss>=2.601729917526245\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:27 INFO 139780359198336] Epoch[41] Batch [10]#011Speed: 60.63 samples/sec#011loss=2.601730\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:27 INFO 139780359198336] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524893.3216727, \"EndTime\": 1617524907.9212918, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14599.1849899292, \"count\": 1, \"min\": 14599.1849899292, \"max\": 14599.1849899292}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:27 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.6871842012663 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:27 INFO 139780359198336] #progress_metric: host=algo-1, completed 10.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:27 INFO 139780359198336] #quality_metric: host=algo-1, epoch=41, train loss <loss>=2.623573129827326\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:27 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:32 INFO 139780359198336] Epoch[42] Batch[0] avg_epoch_loss=2.542852\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:32 INFO 139780359198336] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=2.5428519248962402\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:37 INFO 139780359198336] Epoch[42] Batch[5] avg_epoch_loss=2.606165\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:37 INFO 139780359198336] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=2.6061652501424155\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:37 INFO 139780359198336] Epoch[42] Batch [5]#011Speed: 62.54 samples/sec#011loss=2.606165\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:42 INFO 139780359198336] Epoch[42] Batch[10] avg_epoch_loss=2.706617\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:42 INFO 139780359198336] #quality_metric: host=algo-1, epoch=42, batch=10 train loss <loss>=2.827159881591797\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:42 INFO 139780359198336] Epoch[42] Batch [10]#011Speed: 62.09 samples/sec#011loss=2.827160\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:42 INFO 139780359198336] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524907.921357, \"EndTime\": 1617524922.4391751, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14517.448663711548, \"count\": 1, \"min\": 14517.448663711548, \"max\": 14517.448663711548}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:42 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.153465097184714 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:42 INFO 139780359198336] #progress_metric: host=algo-1, completed 10.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:42 INFO 139780359198336] #quality_metric: host=algo-1, epoch=42, train loss <loss>=2.7066173553466797\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:42 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:46 INFO 139780359198336] Epoch[43] Batch[0] avg_epoch_loss=2.712090\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:46 INFO 139780359198336] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=2.712089776992798\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:51 INFO 139780359198336] Epoch[43] Batch[5] avg_epoch_loss=2.659821\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:51 INFO 139780359198336] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=2.659821112950643\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:51 INFO 139780359198336] Epoch[43] Batch [5]#011Speed: 62.59 samples/sec#011loss=2.659821\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:55 INFO 139780359198336] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524922.4392414, \"EndTime\": 1617524935.9937289, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13554.121255874634, \"count\": 1, \"min\": 13554.121255874634, \"max\": 13554.121255874634}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:55 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.627509645375184 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:55 INFO 139780359198336] #progress_metric: host=algo-1, completed 11.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:55 INFO 139780359198336] #quality_metric: host=algo-1, epoch=43, train loss <loss>=2.629703187942505\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:28:55 INFO 139780359198336] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 08:29:00 INFO 139780359198336] Epoch[44] Batch[0] avg_epoch_loss=2.689332\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:00 INFO 139780359198336] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=2.689331531524658\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:06 INFO 139780359198336] Epoch[44] Batch[5] avg_epoch_loss=2.650306\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:06 INFO 139780359198336] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=2.65030566851298\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:06 INFO 139780359198336] Epoch[44] Batch [5]#011Speed: 53.83 samples/sec#011loss=2.650306\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:10 INFO 139780359198336] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524935.9937985, \"EndTime\": 1617524950.2850718, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14290.777921676636, \"count\": 1, \"min\": 14290.777921676636, \"max\": 14290.777921676636}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:10 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.43393354059958 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:10 INFO 139780359198336] #progress_metric: host=algo-1, completed 11.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:10 INFO 139780359198336] #quality_metric: host=algo-1, epoch=44, train loss <loss>=2.6368289947509767\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:10 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:14 INFO 139780359198336] Epoch[45] Batch[0] avg_epoch_loss=2.621010\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:14 INFO 139780359198336] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=2.621009588241577\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:19 INFO 139780359198336] Epoch[45] Batch[5] avg_epoch_loss=2.598886\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:19 INFO 139780359198336] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=2.5988858143488565\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:19 INFO 139780359198336] Epoch[45] Batch [5]#011Speed: 61.10 samples/sec#011loss=2.598886\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:23 INFO 139780359198336] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524950.285143, \"EndTime\": 1617524963.9093242, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13623.713254928589, \"count\": 1, \"min\": 13623.713254928589, \"max\": 13623.713254928589}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:23 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.46268563391222 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:23 INFO 139780359198336] #progress_metric: host=algo-1, completed 11.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:23 INFO 139780359198336] #quality_metric: host=algo-1, epoch=45, train loss <loss>=2.6163866758346557\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:23 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:28 INFO 139780359198336] Epoch[46] Batch[0] avg_epoch_loss=2.411791\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:28 INFO 139780359198336] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=2.4117908477783203\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:33 INFO 139780359198336] Epoch[46] Batch[5] avg_epoch_loss=2.594095\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:33 INFO 139780359198336] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=2.59409507115682\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:33 INFO 139780359198336] Epoch[46] Batch [5]#011Speed: 63.29 samples/sec#011loss=2.594095\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:37 INFO 139780359198336] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524963.9094079, \"EndTime\": 1617524977.2846894, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13374.810934066772, \"count\": 1, \"min\": 13374.810934066772, \"max\": 13374.810934066772}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:37 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=47.40218011022337 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:37 INFO 139780359198336] #progress_metric: host=algo-1, completed 11.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:37 INFO 139780359198336] #quality_metric: host=algo-1, epoch=46, train loss <loss>=2.635989856719971\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:37 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:41 INFO 139780359198336] Epoch[47] Batch[0] avg_epoch_loss=2.606836\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:41 INFO 139780359198336] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=2.6068356037139893\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:46 INFO 139780359198336] Epoch[47] Batch[5] avg_epoch_loss=2.631918\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:46 INFO 139780359198336] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=2.6319181521733603\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:46 INFO 139780359198336] Epoch[47] Batch [5]#011Speed: 61.60 samples/sec#011loss=2.631918\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:50 INFO 139780359198336] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524977.284762, \"EndTime\": 1617524990.843897, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13558.569192886353, \"count\": 1, \"min\": 13558.569192886353, \"max\": 13558.569192886353}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:50 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.83343113073194 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:50 INFO 139780359198336] #progress_metric: host=algo-1, completed 12.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:50 INFO 139780359198336] #quality_metric: host=algo-1, epoch=47, train loss <loss>=2.5899305820465086\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:50 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:55 INFO 139780359198336] Epoch[48] Batch[0] avg_epoch_loss=2.627285\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:29:55 INFO 139780359198336] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=2.6272850036621094\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:00 INFO 139780359198336] Epoch[48] Batch[5] avg_epoch_loss=2.649338\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:00 INFO 139780359198336] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=2.6493376890818277\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:00 INFO 139780359198336] Epoch[48] Batch [5]#011Speed: 62.75 samples/sec#011loss=2.649338\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:04 INFO 139780359198336] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617524990.8439786, \"EndTime\": 1617525004.9073813, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14062.829494476318, \"count\": 1, \"min\": 14062.829494476318, \"max\": 14062.829494476318}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:04 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.367429006275536 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:04 INFO 139780359198336] #progress_metric: host=algo-1, completed 12.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:04 INFO 139780359198336] #quality_metric: host=algo-1, epoch=48, train loss <loss>=2.64111533164978\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:04 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:09 INFO 139780359198336] Epoch[49] Batch[0] avg_epoch_loss=2.559858\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:09 INFO 139780359198336] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=2.5598580837249756\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:14 INFO 139780359198336] Epoch[49] Batch[5] avg_epoch_loss=2.599863\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:14 INFO 139780359198336] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=2.5998632113138833\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:14 INFO 139780359198336] Epoch[49] Batch [5]#011Speed: 62.73 samples/sec#011loss=2.599863\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:18 INFO 139780359198336] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525004.9074547, \"EndTime\": 1617525018.7102687, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13802.123308181763, \"count\": 1, \"min\": 13802.123308181763, \"max\": 13802.123308181763}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:18 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.29680773923024 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:18 INFO 139780359198336] #progress_metric: host=algo-1, completed 12.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:18 INFO 139780359198336] #quality_metric: host=algo-1, epoch=49, train loss <loss>=2.6082953453063964\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:18 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:22 INFO 139780359198336] Epoch[50] Batch[0] avg_epoch_loss=2.424529\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:22 INFO 139780359198336] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=2.4245293140411377\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 08:30:28 INFO 139780359198336] Epoch[50] Batch[5] avg_epoch_loss=2.632103\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:28 INFO 139780359198336] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=2.6321029663085938\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:28 INFO 139780359198336] Epoch[50] Batch [5]#011Speed: 62.38 samples/sec#011loss=2.632103\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:32 INFO 139780359198336] processed a total of 605 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525018.7103422, \"EndTime\": 1617525032.205429, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13494.580268859863, \"count\": 1, \"min\": 13494.580268859863, \"max\": 13494.580268859863}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:32 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.83246890808465 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:32 INFO 139780359198336] #progress_metric: host=algo-1, completed 12.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:32 INFO 139780359198336] #quality_metric: host=algo-1, epoch=50, train loss <loss>=2.61899471282959\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:32 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:36 INFO 139780359198336] Epoch[51] Batch[0] avg_epoch_loss=2.586956\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:36 INFO 139780359198336] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=2.5869555473327637\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:41 INFO 139780359198336] Epoch[51] Batch[5] avg_epoch_loss=2.645830\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:41 INFO 139780359198336] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=2.645829955736796\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:41 INFO 139780359198336] Epoch[51] Batch [5]#011Speed: 61.76 samples/sec#011loss=2.645830\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:46 INFO 139780359198336] Epoch[51] Batch[10] avg_epoch_loss=2.615496\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:46 INFO 139780359198336] #quality_metric: host=algo-1, epoch=51, batch=10 train loss <loss>=2.5790950298309325\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:46 INFO 139780359198336] Epoch[51] Batch [10]#011Speed: 56.79 samples/sec#011loss=2.579095\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:46 INFO 139780359198336] processed a total of 701 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525032.205501, \"EndTime\": 1617525046.9650717, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14759.093523025513, \"count\": 1, \"min\": 14759.093523025513, \"max\": 14759.093523025513}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:46 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=47.4953623641694 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:46 INFO 139780359198336] #progress_metric: host=algo-1, completed 13.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:46 INFO 139780359198336] #quality_metric: host=algo-1, epoch=51, train loss <loss>=2.615495898506858\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:46 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:51 INFO 139780359198336] Epoch[52] Batch[0] avg_epoch_loss=2.500354\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:51 INFO 139780359198336] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=2.5003538131713867\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:56 INFO 139780359198336] Epoch[52] Batch[5] avg_epoch_loss=2.629824\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:56 INFO 139780359198336] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=2.629824082056681\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:30:56 INFO 139780359198336] Epoch[52] Batch [5]#011Speed: 62.66 samples/sec#011loss=2.629824\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:00 INFO 139780359198336] processed a total of 590 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525046.965144, \"EndTime\": 1617525060.5118842, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13545.9463596344, \"count\": 1, \"min\": 13545.9463596344, \"max\": 13545.9463596344}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:00 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.555137443525176 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:00 INFO 139780359198336] #progress_metric: host=algo-1, completed 13.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:00 INFO 139780359198336] #quality_metric: host=algo-1, epoch=52, train loss <loss>=2.680808591842651\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:00 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:05 INFO 139780359198336] Epoch[53] Batch[0] avg_epoch_loss=2.640856\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:05 INFO 139780359198336] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=2.6408562660217285\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:10 INFO 139780359198336] Epoch[53] Batch[5] avg_epoch_loss=2.608845\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:10 INFO 139780359198336] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=2.608845353126526\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:10 INFO 139780359198336] Epoch[53] Batch [5]#011Speed: 61.62 samples/sec#011loss=2.608845\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:15 INFO 139780359198336] Epoch[53] Batch[10] avg_epoch_loss=2.659596\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:15 INFO 139780359198336] #quality_metric: host=algo-1, epoch=53, batch=10 train loss <loss>=2.7204973220825197\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:15 INFO 139780359198336] Epoch[53] Batch [10]#011Speed: 61.02 samples/sec#011loss=2.720497\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:15 INFO 139780359198336] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525060.511956, \"EndTime\": 1617525075.6896348, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 15177.204847335815, \"count\": 1, \"min\": 15177.204847335815, \"max\": 15177.204847335815}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:15 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=42.36589645032162 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:15 INFO 139780359198336] #progress_metric: host=algo-1, completed 13.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:15 INFO 139780359198336] #quality_metric: host=algo-1, epoch=53, train loss <loss>=2.659596248106523\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:15 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:19 INFO 139780359198336] Epoch[54] Batch[0] avg_epoch_loss=2.576063\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:19 INFO 139780359198336] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=2.5760629177093506\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:24 INFO 139780359198336] Epoch[54] Batch[5] avg_epoch_loss=2.638234\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:24 INFO 139780359198336] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=2.6382339795430503\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:24 INFO 139780359198336] Epoch[54] Batch [5]#011Speed: 62.82 samples/sec#011loss=2.638234\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:30 INFO 139780359198336] Epoch[54] Batch[10] avg_epoch_loss=2.605291\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:30 INFO 139780359198336] #quality_metric: host=algo-1, epoch=54, batch=10 train loss <loss>=2.5657586097717284\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:30 INFO 139780359198336] Epoch[54] Batch [10]#011Speed: 60.97 samples/sec#011loss=2.565759\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:30 INFO 139780359198336] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525075.6897016, \"EndTime\": 1617525090.198477, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14508.41212272644, \"count\": 1, \"min\": 14508.41212272644, \"max\": 14508.41212272644}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:30 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.1459345220642 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:30 INFO 139780359198336] #progress_metric: host=algo-1, completed 13.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:30 INFO 139780359198336] #quality_metric: host=algo-1, epoch=54, train loss <loss>=2.6052906296469946\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:30 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:34 INFO 139780359198336] Epoch[55] Batch[0] avg_epoch_loss=2.537492\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:34 INFO 139780359198336] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=2.5374915599823\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:39 INFO 139780359198336] Epoch[55] Batch[5] avg_epoch_loss=2.588471\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:39 INFO 139780359198336] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=2.588470697402954\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:39 INFO 139780359198336] Epoch[55] Batch [5]#011Speed: 62.41 samples/sec#011loss=2.588471\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:43 INFO 139780359198336] processed a total of 613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525090.1985426, \"EndTime\": 1617525103.760131, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13561.286449432373, \"count\": 1, \"min\": 13561.286449432373, \"max\": 13561.286449432373}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:43 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.201737206592696 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:43 INFO 139780359198336] #progress_metric: host=algo-1, completed 14.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:43 INFO 139780359198336] #quality_metric: host=algo-1, epoch=55, train loss <loss>=2.6423947334289553\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:43 INFO 139780359198336] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 08:31:48 INFO 139780359198336] Epoch[56] Batch[0] avg_epoch_loss=2.610163\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:48 INFO 139780359198336] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=2.6101632118225098\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:53 INFO 139780359198336] Epoch[56] Batch[5] avg_epoch_loss=2.630957\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:53 INFO 139780359198336] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=2.630956768989563\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:53 INFO 139780359198336] Epoch[56] Batch [5]#011Speed: 62.19 samples/sec#011loss=2.630957\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:57 INFO 139780359198336] processed a total of 602 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525103.7602363, \"EndTime\": 1617525117.474796, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13714.138269424438, \"count\": 1, \"min\": 13714.138269424438, \"max\": 13714.138269424438}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:57 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.895984757748316 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:57 INFO 139780359198336] #progress_metric: host=algo-1, completed 14.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:57 INFO 139780359198336] #quality_metric: host=algo-1, epoch=56, train loss <loss>=2.6210184574127195\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:31:57 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:01 INFO 139780359198336] Epoch[57] Batch[0] avg_epoch_loss=2.696003\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:01 INFO 139780359198336] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=2.696002960205078\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:07 INFO 139780359198336] Epoch[57] Batch[5] avg_epoch_loss=2.611609\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:07 INFO 139780359198336] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=2.611608862876892\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:07 INFO 139780359198336] Epoch[57] Batch [5]#011Speed: 54.30 samples/sec#011loss=2.611609\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:12 INFO 139780359198336] Epoch[57] Batch[10] avg_epoch_loss=2.693981\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:12 INFO 139780359198336] #quality_metric: host=algo-1, epoch=57, batch=10 train loss <loss>=2.792828369140625\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:12 INFO 139780359198336] Epoch[57] Batch [10]#011Speed: 61.32 samples/sec#011loss=2.792828\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:12 INFO 139780359198336] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525117.4748664, \"EndTime\": 1617525132.6805222, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 15205.003499984741, \"count\": 1, \"min\": 15205.003499984741, \"max\": 15205.003499984741}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:12 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.406468023864335 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:12 INFO 139780359198336] #progress_metric: host=algo-1, completed 14.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:12 INFO 139780359198336] #quality_metric: host=algo-1, epoch=57, train loss <loss>=2.6939813657240435\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:12 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:16 INFO 139780359198336] Epoch[58] Batch[0] avg_epoch_loss=2.658084\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:16 INFO 139780359198336] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=2.6580843925476074\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:22 INFO 139780359198336] Epoch[58] Batch[5] avg_epoch_loss=2.645327\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:22 INFO 139780359198336] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=2.645326852798462\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:22 INFO 139780359198336] Epoch[58] Batch [5]#011Speed: 61.83 samples/sec#011loss=2.645327\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:26 INFO 139780359198336] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525132.6805913, \"EndTime\": 1617525146.1405418, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13459.526300430298, \"count\": 1, \"min\": 13459.526300430298, \"max\": 13459.526300430298}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:26 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.286550590381935 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:26 INFO 139780359198336] #progress_metric: host=algo-1, completed 14.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:26 INFO 139780359198336] #quality_metric: host=algo-1, epoch=58, train loss <loss>=2.586869311332703\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:26 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:30 INFO 139780359198336] Epoch[59] Batch[0] avg_epoch_loss=2.605058\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:30 INFO 139780359198336] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=2.605057716369629\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:35 INFO 139780359198336] Epoch[59] Batch[5] avg_epoch_loss=2.570229\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:35 INFO 139780359198336] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=2.5702289740244546\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:35 INFO 139780359198336] Epoch[59] Batch [5]#011Speed: 63.11 samples/sec#011loss=2.570229\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:40 INFO 139780359198336] Epoch[59] Batch[10] avg_epoch_loss=2.560699\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:40 INFO 139780359198336] #quality_metric: host=algo-1, epoch=59, batch=10 train loss <loss>=2.5492625713348387\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:40 INFO 139780359198336] Epoch[59] Batch [10]#011Speed: 60.55 samples/sec#011loss=2.549263\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:40 INFO 139780359198336] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525146.1406174, \"EndTime\": 1617525160.7381976, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14597.206592559814, \"count\": 1, \"min\": 14597.206592559814, \"max\": 14597.206592559814}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:40 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.80279193322825 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:40 INFO 139780359198336] #progress_metric: host=algo-1, completed 15.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:40 INFO 139780359198336] #quality_metric: host=algo-1, epoch=59, train loss <loss>=2.56069879098372\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:40 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:44 INFO 139780359198336] Epoch[60] Batch[0] avg_epoch_loss=2.674657\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:44 INFO 139780359198336] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=2.674656629562378\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:50 INFO 139780359198336] Epoch[60] Batch[5] avg_epoch_loss=2.626754\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:50 INFO 139780359198336] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=2.6267540057500205\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:50 INFO 139780359198336] Epoch[60] Batch [5]#011Speed: 62.18 samples/sec#011loss=2.626754\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:55 INFO 139780359198336] Epoch[60] Batch[10] avg_epoch_loss=2.524774\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:55 INFO 139780359198336] #quality_metric: host=algo-1, epoch=60, batch=10 train loss <loss>=2.402397108078003\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:55 INFO 139780359198336] Epoch[60] Batch [10]#011Speed: 61.48 samples/sec#011loss=2.402397\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:55 INFO 139780359198336] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525160.7382638, \"EndTime\": 1617525175.269799, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14531.176805496216, \"count\": 1, \"min\": 14531.176805496216, \"max\": 14531.176805496216}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:55 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.59344083337595 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:55 INFO 139780359198336] #progress_metric: host=algo-1, completed 15.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:55 INFO 139780359198336] #quality_metric: host=algo-1, epoch=60, train loss <loss>=2.524773597717285\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:55 INFO 139780359198336] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:55 INFO 139780359198336] Saved checkpoint to \"/opt/ml/model/state_73ce3fa1-5742-47a8-b80d-8995a536984b-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525175.2698736, \"EndTime\": 1617525175.4552367, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 184.86714363098145, \"count\": 1, \"min\": 184.86714363098145, \"max\": 184.86714363098145}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:59 INFO 139780359198336] Epoch[61] Batch[0] avg_epoch_loss=2.763661\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:32:59 INFO 139780359198336] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=2.7636613845825195\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 08:33:05 INFO 139780359198336] Epoch[61] Batch[5] avg_epoch_loss=2.598991\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:05 INFO 139780359198336] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=2.5989911953608194\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:05 INFO 139780359198336] Epoch[61] Batch [5]#011Speed: 56.16 samples/sec#011loss=2.598991\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:09 INFO 139780359198336] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525175.4553022, \"EndTime\": 1617525189.6863444, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14230.979442596436, \"count\": 1, \"min\": 14230.979442596436, \"max\": 14230.979442596436}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:09 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.62060815759843 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:09 INFO 139780359198336] #progress_metric: host=algo-1, completed 15.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:09 INFO 139780359198336] #quality_metric: host=algo-1, epoch=61, train loss <loss>=2.607951283454895\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:09 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:13 INFO 139780359198336] Epoch[62] Batch[0] avg_epoch_loss=2.677726\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:13 INFO 139780359198336] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=2.6777262687683105\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:19 INFO 139780359198336] Epoch[62] Batch[5] avg_epoch_loss=2.599376\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:19 INFO 139780359198336] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=2.5993759632110596\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:19 INFO 139780359198336] Epoch[62] Batch [5]#011Speed: 62.78 samples/sec#011loss=2.599376\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:23 INFO 139780359198336] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525189.6864233, \"EndTime\": 1617525203.2768543, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13589.978694915771, \"count\": 1, \"min\": 13589.978694915771, \"max\": 13589.978694915771}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:23 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.65142072879189 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:23 INFO 139780359198336] #progress_metric: host=algo-1, completed 15.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:23 INFO 139780359198336] #quality_metric: host=algo-1, epoch=62, train loss <loss>=2.5838126659393312\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:23 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:27 INFO 139780359198336] Epoch[63] Batch[0] avg_epoch_loss=2.596024\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:27 INFO 139780359198336] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=2.5960237979888916\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:32 INFO 139780359198336] Epoch[63] Batch[5] avg_epoch_loss=2.619181\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:32 INFO 139780359198336] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=2.619180599848429\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:32 INFO 139780359198336] Epoch[63] Batch [5]#011Speed: 62.51 samples/sec#011loss=2.619181\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:37 INFO 139780359198336] Epoch[63] Batch[10] avg_epoch_loss=2.551021\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:37 INFO 139780359198336] #quality_metric: host=algo-1, epoch=63, batch=10 train loss <loss>=2.4692291498184202\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:37 INFO 139780359198336] Epoch[63] Batch [10]#011Speed: 59.36 samples/sec#011loss=2.469229\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:37 INFO 139780359198336] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525203.276931, \"EndTime\": 1617525217.9514987, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14674.073219299316, \"count\": 1, \"min\": 14674.073219299316, \"max\": 14674.073219299316}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:37 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.45401733400239 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:37 INFO 139780359198336] #progress_metric: host=algo-1, completed 16.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:37 INFO 139780359198336] #quality_metric: host=algo-1, epoch=63, train loss <loss>=2.551020849834789\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:37 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:42 INFO 139780359198336] Epoch[64] Batch[0] avg_epoch_loss=2.540708\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:42 INFO 139780359198336] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=2.540708303451538\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:47 INFO 139780359198336] Epoch[64] Batch[5] avg_epoch_loss=2.570306\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:47 INFO 139780359198336] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=2.5703062613805137\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:47 INFO 139780359198336] Epoch[64] Batch [5]#011Speed: 61.91 samples/sec#011loss=2.570306\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:51 INFO 139780359198336] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525217.951565, \"EndTime\": 1617525231.8145075, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13862.6229763031, \"count\": 1, \"min\": 13862.6229763031, \"max\": 13862.6229763031}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:51 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.734157867923415 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:51 INFO 139780359198336] #progress_metric: host=algo-1, completed 16.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:51 INFO 139780359198336] #quality_metric: host=algo-1, epoch=64, train loss <loss>=2.5529802322387694\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:51 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:56 INFO 139780359198336] Epoch[65] Batch[0] avg_epoch_loss=2.518534\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:33:56 INFO 139780359198336] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=2.5185341835021973\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:01 INFO 139780359198336] Epoch[65] Batch[5] avg_epoch_loss=2.542730\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:01 INFO 139780359198336] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=2.5427298545837402\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:01 INFO 139780359198336] Epoch[65] Batch [5]#011Speed: 61.38 samples/sec#011loss=2.542730\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:06 INFO 139780359198336] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525231.8145761, \"EndTime\": 1617525246.2683709, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14453.315734863281, \"count\": 1, \"min\": 14453.315734863281, \"max\": 14453.315734863281}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:06 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.2423622862545 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:06 INFO 139780359198336] #progress_metric: host=algo-1, completed 16.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:06 INFO 139780359198336] #quality_metric: host=algo-1, epoch=65, train loss <loss>=2.522268223762512\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:06 INFO 139780359198336] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:06 INFO 139780359198336] Saved checkpoint to \"/opt/ml/model/state_891a6292-55d1-4326-81e3-986cede15b81-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525246.2684433, \"EndTime\": 1617525246.4852836, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 216.4616584777832, \"count\": 1, \"min\": 216.4616584777832, \"max\": 216.4616584777832}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:10 INFO 139780359198336] Epoch[66] Batch[0] avg_epoch_loss=2.499452\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:10 INFO 139780359198336] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=2.4994521141052246\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:15 INFO 139780359198336] Epoch[66] Batch[5] avg_epoch_loss=2.571765\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:15 INFO 139780359198336] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=2.5717652638753257\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:15 INFO 139780359198336] Epoch[66] Batch [5]#011Speed: 62.74 samples/sec#011loss=2.571765\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:21 INFO 139780359198336] Epoch[66] Batch[10] avg_epoch_loss=2.492606\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:21 INFO 139780359198336] #quality_metric: host=algo-1, epoch=66, batch=10 train loss <loss>=2.397614765167236\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:21 INFO 139780359198336] Epoch[66] Batch [10]#011Speed: 58.06 samples/sec#011loss=2.397615\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:21 INFO 139780359198336] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525246.4853616, \"EndTime\": 1617525261.256014, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14770.585298538208, \"count\": 1, \"min\": 14770.585298538208, \"max\": 14770.585298538208}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:21 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.20908961103698 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:21 INFO 139780359198336] #progress_metric: host=algo-1, completed 16.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:21 INFO 139780359198336] #quality_metric: host=algo-1, epoch=66, train loss <loss>=2.4926059462807397\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:21 INFO 139780359198336] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:21 INFO 139780359198336] Saved checkpoint to \"/opt/ml/model/state_31736411-9206-494c-9e73-861d2f9c565d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525261.256113, \"EndTime\": 1617525261.4976518, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 241.1367893218994, \"count\": 1, \"min\": 241.1367893218994, \"max\": 241.1367893218994}}}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 08:34:25 INFO 139780359198336] Epoch[67] Batch[0] avg_epoch_loss=2.511882\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:25 INFO 139780359198336] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=2.5118818283081055\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:30 INFO 139780359198336] Epoch[67] Batch[5] avg_epoch_loss=2.560475\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:30 INFO 139780359198336] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=2.5604745546976724\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:30 INFO 139780359198336] Epoch[67] Batch [5]#011Speed: 61.87 samples/sec#011loss=2.560475\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:35 INFO 139780359198336] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525261.4977088, \"EndTime\": 1617525275.1497197, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13651.951789855957, \"count\": 1, \"min\": 13651.951789855957, \"max\": 13651.951789855957}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:35 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.63415296923875 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:35 INFO 139780359198336] #progress_metric: host=algo-1, completed 17.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:35 INFO 139780359198336] #quality_metric: host=algo-1, epoch=67, train loss <loss>=2.5681352615356445\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:35 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:39 INFO 139780359198336] Epoch[68] Batch[0] avg_epoch_loss=2.529862\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:39 INFO 139780359198336] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=2.5298619270324707\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:44 INFO 139780359198336] Epoch[68] Batch[5] avg_epoch_loss=2.563014\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:44 INFO 139780359198336] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=2.5630136330922446\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:44 INFO 139780359198336] Epoch[68] Batch [5]#011Speed: 62.70 samples/sec#011loss=2.563014\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:49 INFO 139780359198336] Epoch[68] Batch[10] avg_epoch_loss=2.631375\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:49 INFO 139780359198336] #quality_metric: host=algo-1, epoch=68, batch=10 train loss <loss>=2.7134094715118406\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:49 INFO 139780359198336] Epoch[68] Batch [10]#011Speed: 60.25 samples/sec#011loss=2.713409\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:49 INFO 139780359198336] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525275.149793, \"EndTime\": 1617525289.7316873, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14581.411123275757, \"count\": 1, \"min\": 14581.411123275757, \"max\": 14581.411123275757}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:49 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.19419888224063 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:49 INFO 139780359198336] #progress_metric: host=algo-1, completed 17.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:49 INFO 139780359198336] #quality_metric: host=algo-1, epoch=68, train loss <loss>=2.631375377828425\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:49 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:54 INFO 139780359198336] Epoch[69] Batch[0] avg_epoch_loss=2.652872\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:54 INFO 139780359198336] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=2.65287184715271\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:59 INFO 139780359198336] Epoch[69] Batch[5] avg_epoch_loss=2.550863\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:59 INFO 139780359198336] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=2.5508632262547812\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:34:59 INFO 139780359198336] Epoch[69] Batch [5]#011Speed: 61.56 samples/sec#011loss=2.550863\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:05 INFO 139780359198336] Epoch[69] Batch[10] avg_epoch_loss=2.459261\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:05 INFO 139780359198336] #quality_metric: host=algo-1, epoch=69, batch=10 train loss <loss>=2.349338245391846\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:05 INFO 139780359198336] Epoch[69] Batch [10]#011Speed: 55.08 samples/sec#011loss=2.349338\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:05 INFO 139780359198336] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525289.731759, \"EndTime\": 1617525305.102565, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 15370.362758636475, \"count\": 1, \"min\": 15370.362758636475, \"max\": 15370.362758636475}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:05 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=42.22385334751021 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:05 INFO 139780359198336] #progress_metric: host=algo-1, completed 17.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:05 INFO 139780359198336] #quality_metric: host=algo-1, epoch=69, train loss <loss>=2.4592609622261743\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:05 INFO 139780359198336] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:05 INFO 139780359198336] Saved checkpoint to \"/opt/ml/model/state_5cbc498f-da36-4946-a2e5-11fec7e9e7f7-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525305.1026301, \"EndTime\": 1617525305.384976, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 281.9995880126953, \"count\": 1, \"min\": 281.9995880126953, \"max\": 281.9995880126953}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:09 INFO 139780359198336] Epoch[70] Batch[0] avg_epoch_loss=2.501024\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:09 INFO 139780359198336] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=2.5010244846343994\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:14 INFO 139780359198336] Epoch[70] Batch[5] avg_epoch_loss=2.566802\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:14 INFO 139780359198336] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=2.566802461942037\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:14 INFO 139780359198336] Epoch[70] Batch [5]#011Speed: 62.04 samples/sec#011loss=2.566802\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:20 INFO 139780359198336] Epoch[70] Batch[10] avg_epoch_loss=2.605103\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:20 INFO 139780359198336] #quality_metric: host=algo-1, epoch=70, batch=10 train loss <loss>=2.6510634899139403\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:20 INFO 139780359198336] Epoch[70] Batch [10]#011Speed: 60.53 samples/sec#011loss=2.651063\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:20 INFO 139780359198336] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525305.3850472, \"EndTime\": 1617525320.1575954, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14772.477865219116, \"count\": 1, \"min\": 14772.477865219116, \"max\": 14772.477865219116}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:20 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.27121014077764 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:20 INFO 139780359198336] #progress_metric: host=algo-1, completed 17.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:20 INFO 139780359198336] #quality_metric: host=algo-1, epoch=70, train loss <loss>=2.605102929201993\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:20 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:24 INFO 139780359198336] Epoch[71] Batch[0] avg_epoch_loss=2.635829\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:24 INFO 139780359198336] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=2.635829210281372\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:29 INFO 139780359198336] Epoch[71] Batch[5] avg_epoch_loss=2.562898\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:29 INFO 139780359198336] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=2.56289803981781\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:29 INFO 139780359198336] Epoch[71] Batch [5]#011Speed: 62.38 samples/sec#011loss=2.562898\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:33 INFO 139780359198336] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525320.1576614, \"EndTime\": 1617525333.7965462, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13638.41462135315, \"count\": 1, \"min\": 13638.41462135315, \"max\": 13638.41462135315}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:33 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.82592086686621 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:33 INFO 139780359198336] #progress_metric: host=algo-1, completed 18.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:33 INFO 139780359198336] #quality_metric: host=algo-1, epoch=71, train loss <loss>=2.5807841777801515\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:33 INFO 139780359198336] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 08:35:37 INFO 139780359198336] Epoch[72] Batch[0] avg_epoch_loss=2.685135\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:37 INFO 139780359198336] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=2.6851346492767334\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:42 INFO 139780359198336] Epoch[72] Batch[5] avg_epoch_loss=2.570396\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:42 INFO 139780359198336] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=2.5703956286112466\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:42 INFO 139780359198336] Epoch[72] Batch [5]#011Speed: 63.29 samples/sec#011loss=2.570396\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:48 INFO 139780359198336] Epoch[72] Batch[10] avg_epoch_loss=2.552522\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:48 INFO 139780359198336] #quality_metric: host=algo-1, epoch=72, batch=10 train loss <loss>=2.5310728549957275\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:48 INFO 139780359198336] Epoch[72] Batch [10]#011Speed: 59.53 samples/sec#011loss=2.531073\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:48 INFO 139780359198336] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525333.7966158, \"EndTime\": 1617525348.3222318, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14525.108575820923, \"count\": 1, \"min\": 14525.108575820923, \"max\": 14525.108575820923}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:48 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.64481149294053 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:48 INFO 139780359198336] #progress_metric: host=algo-1, completed 18.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:48 INFO 139780359198336] #quality_metric: host=algo-1, epoch=72, train loss <loss>=2.5525216406041924\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:48 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:52 INFO 139780359198336] Epoch[73] Batch[0] avg_epoch_loss=2.596069\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:52 INFO 139780359198336] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=2.5960686206817627\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:57 INFO 139780359198336] Epoch[73] Batch[5] avg_epoch_loss=2.583793\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:57 INFO 139780359198336] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=2.5837934017181396\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:35:57 INFO 139780359198336] Epoch[73] Batch [5]#011Speed: 60.99 samples/sec#011loss=2.583793\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:03 INFO 139780359198336] Epoch[73] Batch[10] avg_epoch_loss=2.596898\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:03 INFO 139780359198336] #quality_metric: host=algo-1, epoch=73, batch=10 train loss <loss>=2.6126240730285644\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:03 INFO 139780359198336] Epoch[73] Batch [10]#011Speed: 58.01 samples/sec#011loss=2.612624\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:03 INFO 139780359198336] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525348.3222935, \"EndTime\": 1617525363.1778848, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14855.27229309082, \"count\": 1, \"min\": 14855.27229309082, \"max\": 14855.27229309082}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:03 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.76490806012954 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:03 INFO 139780359198336] #progress_metric: host=algo-1, completed 18.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:03 INFO 139780359198336] #quality_metric: host=algo-1, epoch=73, train loss <loss>=2.596898252313787\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:03 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:07 INFO 139780359198336] Epoch[74] Batch[0] avg_epoch_loss=2.534720\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:07 INFO 139780359198336] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=2.5347204208374023\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:12 INFO 139780359198336] Epoch[74] Batch[5] avg_epoch_loss=2.568624\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:12 INFO 139780359198336] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=2.5686243375142417\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:12 INFO 139780359198336] Epoch[74] Batch [5]#011Speed: 62.71 samples/sec#011loss=2.568624\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:16 INFO 139780359198336] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525363.1779644, \"EndTime\": 1617525376.8963625, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13717.743158340454, \"count\": 1, \"min\": 13717.743158340454, \"max\": 13717.743158340454}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:16 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.071104249303126 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:16 INFO 139780359198336] #progress_metric: host=algo-1, completed 18.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:16 INFO 139780359198336] #quality_metric: host=algo-1, epoch=74, train loss <loss>=2.604329562187195\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:16 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:21 INFO 139780359198336] Epoch[75] Batch[0] avg_epoch_loss=2.629691\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:21 INFO 139780359198336] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=2.6296911239624023\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:26 INFO 139780359198336] Epoch[75] Batch[5] avg_epoch_loss=2.558303\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:26 INFO 139780359198336] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=2.558302879333496\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:26 INFO 139780359198336] Epoch[75] Batch [5]#011Speed: 61.37 samples/sec#011loss=2.558303\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:30 INFO 139780359198336] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525376.896505, \"EndTime\": 1617525390.52031, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13623.062133789062, \"count\": 1, \"min\": 13623.062133789062, \"max\": 13623.062133789062}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:30 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.58412202907492 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:30 INFO 139780359198336] #progress_metric: host=algo-1, completed 19.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:30 INFO 139780359198336] #quality_metric: host=algo-1, epoch=75, train loss <loss>=2.550164985656738\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:30 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:34 INFO 139780359198336] Epoch[76] Batch[0] avg_epoch_loss=2.528613\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:34 INFO 139780359198336] #quality_metric: host=algo-1, epoch=76, batch=0 train loss <loss>=2.5286126136779785\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:39 INFO 139780359198336] Epoch[76] Batch[5] avg_epoch_loss=2.559500\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:39 INFO 139780359198336] #quality_metric: host=algo-1, epoch=76, batch=5 train loss <loss>=2.5595001777013144\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:39 INFO 139780359198336] Epoch[76] Batch [5]#011Speed: 63.03 samples/sec#011loss=2.559500\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:44 INFO 139780359198336] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525390.5203817, \"EndTime\": 1617525404.0185394, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13497.671127319336, \"count\": 1, \"min\": 13497.671127319336, \"max\": 13497.671127319336}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:44 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.52613878976215 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:44 INFO 139780359198336] #progress_metric: host=algo-1, completed 19.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:44 INFO 139780359198336] #quality_metric: host=algo-1, epoch=76, train loss <loss>=2.532335567474365\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:44 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:48 INFO 139780359198336] Epoch[77] Batch[0] avg_epoch_loss=2.385988\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:48 INFO 139780359198336] #quality_metric: host=algo-1, epoch=77, batch=0 train loss <loss>=2.3859875202178955\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:53 INFO 139780359198336] Epoch[77] Batch[5] avg_epoch_loss=2.562069\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:53 INFO 139780359198336] #quality_metric: host=algo-1, epoch=77, batch=5 train loss <loss>=2.5620688597361245\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:53 INFO 139780359198336] Epoch[77] Batch [5]#011Speed: 62.57 samples/sec#011loss=2.562069\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 08:36:58 INFO 139780359198336] Epoch[77] Batch[10] avg_epoch_loss=2.637667\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:58 INFO 139780359198336] #quality_metric: host=algo-1, epoch=77, batch=10 train loss <loss>=2.728384017944336\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:58 INFO 139780359198336] Epoch[77] Batch [10]#011Speed: 59.56 samples/sec#011loss=2.728384\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:58 INFO 139780359198336] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525404.01862, \"EndTime\": 1617525418.6265666, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14607.441425323486, \"count\": 1, \"min\": 14607.441425323486, \"max\": 14607.441425323486}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:58 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.25057941686703 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:58 INFO 139780359198336] #progress_metric: host=algo-1, completed 19.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:58 INFO 139780359198336] #quality_metric: host=algo-1, epoch=77, train loss <loss>=2.6376666589216753\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:36:58 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:02 INFO 139780359198336] Epoch[78] Batch[0] avg_epoch_loss=2.564412\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:02 INFO 139780359198336] #quality_metric: host=algo-1, epoch=78, batch=0 train loss <loss>=2.5644123554229736\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:08 INFO 139780359198336] Epoch[78] Batch[5] avg_epoch_loss=2.547817\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:08 INFO 139780359198336] #quality_metric: host=algo-1, epoch=78, batch=5 train loss <loss>=2.54781707127889\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:08 INFO 139780359198336] Epoch[78] Batch [5]#011Speed: 54.75 samples/sec#011loss=2.547817\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:12 INFO 139780359198336] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525418.6266382, \"EndTime\": 1617525432.8836405, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14256.465196609497, \"count\": 1, \"min\": 14256.465196609497, \"max\": 14256.465196609497}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:12 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.54083473507525 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:12 INFO 139780359198336] #progress_metric: host=algo-1, completed 19.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:12 INFO 139780359198336] #quality_metric: host=algo-1, epoch=78, train loss <loss>=2.534296679496765\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:12 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:17 INFO 139780359198336] Epoch[79] Batch[0] avg_epoch_loss=2.598762\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:17 INFO 139780359198336] #quality_metric: host=algo-1, epoch=79, batch=0 train loss <loss>=2.598762273788452\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:22 INFO 139780359198336] Epoch[79] Batch[5] avg_epoch_loss=2.569339\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:22 INFO 139780359198336] #quality_metric: host=algo-1, epoch=79, batch=5 train loss <loss>=2.569339394569397\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:22 INFO 139780359198336] Epoch[79] Batch [5]#011Speed: 63.21 samples/sec#011loss=2.569339\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:26 INFO 139780359198336] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525432.8837197, \"EndTime\": 1617525446.4006789, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13516.255855560303, \"count\": 1, \"min\": 13516.255855560303, \"max\": 13516.255855560303}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:26 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=47.128028728540805 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:26 INFO 139780359198336] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:26 INFO 139780359198336] #quality_metric: host=algo-1, epoch=79, train loss <loss>=2.5652211904525757\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:26 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:30 INFO 139780359198336] Epoch[80] Batch[0] avg_epoch_loss=2.690646\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:30 INFO 139780359198336] #quality_metric: host=algo-1, epoch=80, batch=0 train loss <loss>=2.690645933151245\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:35 INFO 139780359198336] Epoch[80] Batch[5] avg_epoch_loss=2.545209\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:35 INFO 139780359198336] #quality_metric: host=algo-1, epoch=80, batch=5 train loss <loss>=2.5452088514963784\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:35 INFO 139780359198336] Epoch[80] Batch [5]#011Speed: 63.13 samples/sec#011loss=2.545209\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:40 INFO 139780359198336] Epoch[80] Batch[10] avg_epoch_loss=2.576502\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:40 INFO 139780359198336] #quality_metric: host=algo-1, epoch=80, batch=10 train loss <loss>=2.614054870605469\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:40 INFO 139780359198336] Epoch[80] Batch [10]#011Speed: 60.95 samples/sec#011loss=2.614055\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:40 INFO 139780359198336] processed a total of 670 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525446.4007604, \"EndTime\": 1617525460.7885184, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14387.22825050354, \"count\": 1, \"min\": 14387.22825050354, \"max\": 14387.22825050354}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:40 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.56875549125326 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:40 INFO 139780359198336] #progress_metric: host=algo-1, completed 20.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:40 INFO 139780359198336] #quality_metric: host=algo-1, epoch=80, train loss <loss>=2.576502496545965\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:40 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:44 INFO 139780359198336] Epoch[81] Batch[0] avg_epoch_loss=2.640895\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:44 INFO 139780359198336] #quality_metric: host=algo-1, epoch=81, batch=0 train loss <loss>=2.640894651412964\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:49 INFO 139780359198336] Epoch[81] Batch[5] avg_epoch_loss=2.595955\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:49 INFO 139780359198336] #quality_metric: host=algo-1, epoch=81, batch=5 train loss <loss>=2.595954974492391\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:49 INFO 139780359198336] Epoch[81] Batch [5]#011Speed: 62.99 samples/sec#011loss=2.595955\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:55 INFO 139780359198336] Epoch[81] Batch[10] avg_epoch_loss=2.598397\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:55 INFO 139780359198336] #quality_metric: host=algo-1, epoch=81, batch=10 train loss <loss>=2.6013272285461424\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:55 INFO 139780359198336] Epoch[81] Batch [10]#011Speed: 59.34 samples/sec#011loss=2.601327\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:55 INFO 139780359198336] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525460.788586, \"EndTime\": 1617525475.3342853, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14545.176029205322, \"count\": 1, \"min\": 14545.176029205322, \"max\": 14545.176029205322}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:55 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.58170813414658 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:55 INFO 139780359198336] #progress_metric: host=algo-1, completed 20.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:55 INFO 139780359198336] #quality_metric: host=algo-1, epoch=81, train loss <loss>=2.598396908153187\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:55 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:59 INFO 139780359198336] Epoch[82] Batch[0] avg_epoch_loss=2.445062\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:37:59 INFO 139780359198336] #quality_metric: host=algo-1, epoch=82, batch=0 train loss <loss>=2.4450623989105225\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:05 INFO 139780359198336] Epoch[82] Batch[5] avg_epoch_loss=2.508886\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:05 INFO 139780359198336] #quality_metric: host=algo-1, epoch=82, batch=5 train loss <loss>=2.508885622024536\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:05 INFO 139780359198336] Epoch[82] Batch [5]#011Speed: 57.07 samples/sec#011loss=2.508886\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:10 INFO 139780359198336] Epoch[82] Batch[10] avg_epoch_loss=2.540857\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:10 INFO 139780359198336] #quality_metric: host=algo-1, epoch=82, batch=10 train loss <loss>=2.5792216777801515\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:10 INFO 139780359198336] Epoch[82] Batch [10]#011Speed: 57.26 samples/sec#011loss=2.579222\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:10 INFO 139780359198336] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525475.3343794, \"EndTime\": 1617525490.6451464, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 15310.266971588135, \"count\": 1, \"min\": 15310.266971588135, \"max\": 15310.266971588135}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:10 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.63055762685228 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:10 INFO 139780359198336] #progress_metric: host=algo-1, completed 20.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:10 INFO 139780359198336] #quality_metric: host=algo-1, epoch=82, train loss <loss>=2.5408565564589067\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:10 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:14 INFO 139780359198336] Epoch[83] Batch[0] avg_epoch_loss=2.593477\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:14 INFO 139780359198336] #quality_metric: host=algo-1, epoch=83, batch=0 train loss <loss>=2.5934770107269287\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 08:38:20 INFO 139780359198336] Epoch[83] Batch[5] avg_epoch_loss=2.582181\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:20 INFO 139780359198336] #quality_metric: host=algo-1, epoch=83, batch=5 train loss <loss>=2.582180976867676\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:20 INFO 139780359198336] Epoch[83] Batch [5]#011Speed: 62.16 samples/sec#011loss=2.582181\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:24 INFO 139780359198336] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525490.645216, \"EndTime\": 1617525504.2340872, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13588.485479354858, \"count\": 1, \"min\": 13588.485479354858, \"max\": 13588.485479354858}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:24 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.435968710584625 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:24 INFO 139780359198336] #progress_metric: host=algo-1, completed 21.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:24 INFO 139780359198336] #quality_metric: host=algo-1, epoch=83, train loss <loss>=2.5532036304473875\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:24 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:28 INFO 139780359198336] Epoch[84] Batch[0] avg_epoch_loss=2.489778\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:28 INFO 139780359198336] #quality_metric: host=algo-1, epoch=84, batch=0 train loss <loss>=2.4897780418395996\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:33 INFO 139780359198336] Epoch[84] Batch[5] avg_epoch_loss=2.544408\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:33 INFO 139780359198336] #quality_metric: host=algo-1, epoch=84, batch=5 train loss <loss>=2.544407765070597\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:33 INFO 139780359198336] Epoch[84] Batch [5]#011Speed: 62.76 samples/sec#011loss=2.544408\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:37 INFO 139780359198336] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525504.2341716, \"EndTime\": 1617525517.7553582, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13520.780324935913, \"count\": 1, \"min\": 13520.780324935913, \"max\": 13520.780324935913}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:37 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.85493565463277 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:37 INFO 139780359198336] #progress_metric: host=algo-1, completed 21.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:37 INFO 139780359198336] #quality_metric: host=algo-1, epoch=84, train loss <loss>=2.5146090984344482\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:37 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:41 INFO 139780359198336] Epoch[85] Batch[0] avg_epoch_loss=2.598670\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:41 INFO 139780359198336] #quality_metric: host=algo-1, epoch=85, batch=0 train loss <loss>=2.5986697673797607\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:47 INFO 139780359198336] Epoch[85] Batch[5] avg_epoch_loss=2.514396\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:47 INFO 139780359198336] #quality_metric: host=algo-1, epoch=85, batch=5 train loss <loss>=2.5143959124883017\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:47 INFO 139780359198336] Epoch[85] Batch [5]#011Speed: 63.01 samples/sec#011loss=2.514396\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:51 INFO 139780359198336] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525517.7554405, \"EndTime\": 1617525531.1446848, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13388.71955871582, \"count\": 1, \"min\": 13388.71955871582, \"max\": 13388.71955871582}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:51 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.68064939780851 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:51 INFO 139780359198336] #progress_metric: host=algo-1, completed 21.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:51 INFO 139780359198336] #quality_metric: host=algo-1, epoch=85, train loss <loss>=2.5299612522125243\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:51 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:55 INFO 139780359198336] Epoch[86] Batch[0] avg_epoch_loss=2.433958\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:38:55 INFO 139780359198336] #quality_metric: host=algo-1, epoch=86, batch=0 train loss <loss>=2.433957815170288\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:00 INFO 139780359198336] Epoch[86] Batch[5] avg_epoch_loss=2.527117\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:00 INFO 139780359198336] #quality_metric: host=algo-1, epoch=86, batch=5 train loss <loss>=2.5271170139312744\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:00 INFO 139780359198336] Epoch[86] Batch [5]#011Speed: 60.87 samples/sec#011loss=2.527117\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:06 INFO 139780359198336] Epoch[86] Batch[10] avg_epoch_loss=2.526517\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:06 INFO 139780359198336] #quality_metric: host=algo-1, epoch=86, batch=10 train loss <loss>=2.525796365737915\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:06 INFO 139780359198336] Epoch[86] Batch [10]#011Speed: 51.50 samples/sec#011loss=2.525796\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:06 INFO 139780359198336] processed a total of 677 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525531.1447685, \"EndTime\": 1617525546.6305192, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 15485.204219818115, \"count\": 1, \"min\": 15485.204219818115, \"max\": 15485.204219818115}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:06 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.7188553457851 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:06 INFO 139780359198336] #progress_metric: host=algo-1, completed 21.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:06 INFO 139780359198336] #quality_metric: host=algo-1, epoch=86, train loss <loss>=2.526516719297929\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:06 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:10 INFO 139780359198336] Epoch[87] Batch[0] avg_epoch_loss=2.415258\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:10 INFO 139780359198336] #quality_metric: host=algo-1, epoch=87, batch=0 train loss <loss>=2.4152584075927734\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:15 INFO 139780359198336] Epoch[87] Batch[5] avg_epoch_loss=2.549993\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:15 INFO 139780359198336] #quality_metric: host=algo-1, epoch=87, batch=5 train loss <loss>=2.5499930381774902\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:15 INFO 139780359198336] Epoch[87] Batch [5]#011Speed: 62.67 samples/sec#011loss=2.549993\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:21 INFO 139780359198336] Epoch[87] Batch[10] avg_epoch_loss=2.514564\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:21 INFO 139780359198336] #quality_metric: host=algo-1, epoch=87, batch=10 train loss <loss>=2.4720497608184813\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:21 INFO 139780359198336] Epoch[87] Batch [10]#011Speed: 59.45 samples/sec#011loss=2.472050\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:21 INFO 139780359198336] processed a total of 676 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525546.630591, \"EndTime\": 1617525561.18549, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14554.43811416626, \"count\": 1, \"min\": 14554.43811416626, \"max\": 14554.43811416626}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:21 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.44590752404995 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:21 INFO 139780359198336] #progress_metric: host=algo-1, completed 22.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:21 INFO 139780359198336] #quality_metric: host=algo-1, epoch=87, train loss <loss>=2.514564275741577\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:21 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:25 INFO 139780359198336] Epoch[88] Batch[0] avg_epoch_loss=2.543266\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:25 INFO 139780359198336] #quality_metric: host=algo-1, epoch=88, batch=0 train loss <loss>=2.5432662963867188\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:30 INFO 139780359198336] Epoch[88] Batch[5] avg_epoch_loss=2.591210\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:30 INFO 139780359198336] #quality_metric: host=algo-1, epoch=88, batch=5 train loss <loss>=2.5912102858225503\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:30 INFO 139780359198336] Epoch[88] Batch [5]#011Speed: 60.48 samples/sec#011loss=2.591210\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:34 INFO 139780359198336] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525561.1855586, \"EndTime\": 1617525574.8265994, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13640.522241592407, \"count\": 1, \"min\": 13640.522241592407, \"max\": 13640.522241592407}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:34 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.11226787015253 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:34 INFO 139780359198336] #progress_metric: host=algo-1, completed 22.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:34 INFO 139780359198336] #quality_metric: host=algo-1, epoch=88, train loss <loss>=2.597750210762024\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:34 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:38 INFO 139780359198336] Epoch[89] Batch[0] avg_epoch_loss=2.480310\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:38 INFO 139780359198336] #quality_metric: host=algo-1, epoch=89, batch=0 train loss <loss>=2.4803099632263184\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 08:39:44 INFO 139780359198336] Epoch[89] Batch[5] avg_epoch_loss=2.561644\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:44 INFO 139780359198336] #quality_metric: host=algo-1, epoch=89, batch=5 train loss <loss>=2.5616438388824463\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:44 INFO 139780359198336] Epoch[89] Batch [5]#011Speed: 62.56 samples/sec#011loss=2.561644\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:49 INFO 139780359198336] Epoch[89] Batch[10] avg_epoch_loss=2.670774\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:49 INFO 139780359198336] #quality_metric: host=algo-1, epoch=89, batch=10 train loss <loss>=2.8017295360565186\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:49 INFO 139780359198336] Epoch[89] Batch [10]#011Speed: 60.14 samples/sec#011loss=2.801730\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:49 INFO 139780359198336] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525574.8266702, \"EndTime\": 1617525589.4196775, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14592.443943023682, \"count\": 1, \"min\": 14592.443943023682, \"max\": 14592.443943023682}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:49 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.47478022743951 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:49 INFO 139780359198336] #progress_metric: host=algo-1, completed 22.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:49 INFO 139780359198336] #quality_metric: host=algo-1, epoch=89, train loss <loss>=2.6707737012342974\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:49 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:53 INFO 139780359198336] Epoch[90] Batch[0] avg_epoch_loss=2.604971\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:53 INFO 139780359198336] #quality_metric: host=algo-1, epoch=90, batch=0 train loss <loss>=2.604970932006836\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:58 INFO 139780359198336] Epoch[90] Batch[5] avg_epoch_loss=2.537630\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:58 INFO 139780359198336] #quality_metric: host=algo-1, epoch=90, batch=5 train loss <loss>=2.5376303593317666\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:39:58 INFO 139780359198336] Epoch[90] Batch [5]#011Speed: 61.39 samples/sec#011loss=2.537630\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:04 INFO 139780359198336] Epoch[90] Batch[10] avg_epoch_loss=2.502628\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:04 INFO 139780359198336] #quality_metric: host=algo-1, epoch=90, batch=10 train loss <loss>=2.4606243133544923\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:04 INFO 139780359198336] Epoch[90] Batch [10]#011Speed: 56.14 samples/sec#011loss=2.460624\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:04 INFO 139780359198336] processed a total of 677 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525589.4197419, \"EndTime\": 1617525604.4536178, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 15033.510684967041, \"count\": 1, \"min\": 15033.510684967041, \"max\": 15033.510684967041}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:04 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.03238321571993 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:04 INFO 139780359198336] #progress_metric: host=algo-1, completed 22.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:04 INFO 139780359198336] #quality_metric: host=algo-1, epoch=90, train loss <loss>=2.5026276111602783\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:04 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:08 INFO 139780359198336] Epoch[91] Batch[0] avg_epoch_loss=2.575365\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:08 INFO 139780359198336] #quality_metric: host=algo-1, epoch=91, batch=0 train loss <loss>=2.575364589691162\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:13 INFO 139780359198336] Epoch[91] Batch[5] avg_epoch_loss=2.512549\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:13 INFO 139780359198336] #quality_metric: host=algo-1, epoch=91, batch=5 train loss <loss>=2.5125486850738525\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:13 INFO 139780359198336] Epoch[91] Batch [5]#011Speed: 62.60 samples/sec#011loss=2.512549\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:19 INFO 139780359198336] Epoch[91] Batch[10] avg_epoch_loss=2.587145\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:19 INFO 139780359198336] #quality_metric: host=algo-1, epoch=91, batch=10 train loss <loss>=2.6766607761383057\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:19 INFO 139780359198336] Epoch[91] Batch [10]#011Speed: 60.46 samples/sec#011loss=2.676661\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:19 INFO 139780359198336] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525604.4536972, \"EndTime\": 1617525619.2713532, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14817.062139511108, \"count\": 1, \"min\": 14817.062139511108, \"max\": 14817.062139511108}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:19 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.07050552265821 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:19 INFO 139780359198336] #progress_metric: host=algo-1, completed 23.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:19 INFO 139780359198336] #quality_metric: host=algo-1, epoch=91, train loss <loss>=2.5871450901031494\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:19 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:23 INFO 139780359198336] Epoch[92] Batch[0] avg_epoch_loss=2.581503\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:23 INFO 139780359198336] #quality_metric: host=algo-1, epoch=92, batch=0 train loss <loss>=2.581502676010132\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:28 INFO 139780359198336] Epoch[92] Batch[5] avg_epoch_loss=2.572158\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:28 INFO 139780359198336] #quality_metric: host=algo-1, epoch=92, batch=5 train loss <loss>=2.5721577405929565\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:28 INFO 139780359198336] Epoch[92] Batch [5]#011Speed: 60.75 samples/sec#011loss=2.572158\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:32 INFO 139780359198336] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525619.2714245, \"EndTime\": 1617525632.877926, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13606.074571609497, \"count\": 1, \"min\": 13606.074571609497, \"max\": 13606.074571609497}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:32 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.567497891218224 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:32 INFO 139780359198336] #progress_metric: host=algo-1, completed 23.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:32 INFO 139780359198336] #quality_metric: host=algo-1, epoch=92, train loss <loss>=2.5584200859069823\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:32 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:37 INFO 139780359198336] Epoch[93] Batch[0] avg_epoch_loss=2.642562\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:37 INFO 139780359198336] #quality_metric: host=algo-1, epoch=93, batch=0 train loss <loss>=2.642561674118042\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:42 INFO 139780359198336] Epoch[93] Batch[5] avg_epoch_loss=2.588711\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:42 INFO 139780359198336] #quality_metric: host=algo-1, epoch=93, batch=5 train loss <loss>=2.5887107451756797\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:42 INFO 139780359198336] Epoch[93] Batch [5]#011Speed: 62.57 samples/sec#011loss=2.588711\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:47 INFO 139780359198336] Epoch[93] Batch[10] avg_epoch_loss=2.535005\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:47 INFO 139780359198336] #quality_metric: host=algo-1, epoch=93, batch=10 train loss <loss>=2.4705589771270753\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:47 INFO 139780359198336] Epoch[93] Batch [10]#011Speed: 60.77 samples/sec#011loss=2.470559\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:47 INFO 139780359198336] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525632.8780057, \"EndTime\": 1617525647.4248655, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14546.285390853882, \"count\": 1, \"min\": 14546.285390853882, \"max\": 14546.285390853882}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:47 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.61588485513074 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:47 INFO 139780359198336] #progress_metric: host=algo-1, completed 23.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:47 INFO 139780359198336] #quality_metric: host=algo-1, epoch=93, train loss <loss>=2.5350053960626777\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:47 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:51 INFO 139780359198336] Epoch[94] Batch[0] avg_epoch_loss=2.609316\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:51 INFO 139780359198336] #quality_metric: host=algo-1, epoch=94, batch=0 train loss <loss>=2.609315872192383\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 08:40:56 INFO 139780359198336] Epoch[94] Batch[5] avg_epoch_loss=2.511060\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:56 INFO 139780359198336] #quality_metric: host=algo-1, epoch=94, batch=5 train loss <loss>=2.5110599994659424\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:40:56 INFO 139780359198336] Epoch[94] Batch [5]#011Speed: 63.03 samples/sec#011loss=2.511060\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:02 INFO 139780359198336] Epoch[94] Batch[10] avg_epoch_loss=2.536102\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:02 INFO 139780359198336] #quality_metric: host=algo-1, epoch=94, batch=10 train loss <loss>=2.566151666641235\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:02 INFO 139780359198336] Epoch[94] Batch [10]#011Speed: 57.53 samples/sec#011loss=2.566152\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:02 INFO 139780359198336] processed a total of 694 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525647.424937, \"EndTime\": 1617525662.080635, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14655.315160751343, \"count\": 1, \"min\": 14655.315160751343, \"max\": 14655.315160751343}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:02 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=47.35439990971769 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:02 INFO 139780359198336] #progress_metric: host=algo-1, completed 23.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:02 INFO 139780359198336] #quality_metric: host=algo-1, epoch=94, train loss <loss>=2.5361016663638027\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:02 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:06 INFO 139780359198336] Epoch[95] Batch[0] avg_epoch_loss=2.628575\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:06 INFO 139780359198336] #quality_metric: host=algo-1, epoch=95, batch=0 train loss <loss>=2.6285746097564697\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:11 INFO 139780359198336] Epoch[95] Batch[5] avg_epoch_loss=2.580158\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:11 INFO 139780359198336] #quality_metric: host=algo-1, epoch=95, batch=5 train loss <loss>=2.5801578362782798\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:11 INFO 139780359198336] Epoch[95] Batch [5]#011Speed: 62.43 samples/sec#011loss=2.580158\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:17 INFO 139780359198336] Epoch[95] Batch[10] avg_epoch_loss=2.550630\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:17 INFO 139780359198336] #quality_metric: host=algo-1, epoch=95, batch=10 train loss <loss>=2.515195846557617\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:17 INFO 139780359198336] Epoch[95] Batch [10]#011Speed: 59.03 samples/sec#011loss=2.515196\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:17 INFO 139780359198336] processed a total of 691 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525662.080738, \"EndTime\": 1617525677.1266994, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 15045.428991317749, \"count\": 1, \"min\": 15045.428991317749, \"max\": 15045.428991317749}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:17 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.92726696491844 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:17 INFO 139780359198336] #progress_metric: host=algo-1, completed 24.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:17 INFO 139780359198336] #quality_metric: host=algo-1, epoch=95, train loss <loss>=2.550629659132524\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:17 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:21 INFO 139780359198336] Epoch[96] Batch[0] avg_epoch_loss=2.608315\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:21 INFO 139780359198336] #quality_metric: host=algo-1, epoch=96, batch=0 train loss <loss>=2.6083145141601562\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:26 INFO 139780359198336] Epoch[96] Batch[5] avg_epoch_loss=2.559153\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:26 INFO 139780359198336] #quality_metric: host=algo-1, epoch=96, batch=5 train loss <loss>=2.5591526428858438\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:26 INFO 139780359198336] Epoch[96] Batch [5]#011Speed: 62.67 samples/sec#011loss=2.559153\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:31 INFO 139780359198336] Epoch[96] Batch[10] avg_epoch_loss=2.544022\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:31 INFO 139780359198336] #quality_metric: host=algo-1, epoch=96, batch=10 train loss <loss>=2.5258649826049804\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:31 INFO 139780359198336] Epoch[96] Batch [10]#011Speed: 57.96 samples/sec#011loss=2.525865\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:31 INFO 139780359198336] processed a total of 675 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525677.1267643, \"EndTime\": 1617525691.7649434, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14637.741804122925, \"count\": 1, \"min\": 14637.741804122925, \"max\": 14637.741804122925}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:31 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.113362387231035 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:31 INFO 139780359198336] #progress_metric: host=algo-1, completed 24.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:31 INFO 139780359198336] #quality_metric: host=algo-1, epoch=96, train loss <loss>=2.544021888212724\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:31 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:36 INFO 139780359198336] Epoch[97] Batch[0] avg_epoch_loss=2.515315\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:36 INFO 139780359198336] #quality_metric: host=algo-1, epoch=97, batch=0 train loss <loss>=2.515314817428589\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:41 INFO 139780359198336] Epoch[97] Batch[5] avg_epoch_loss=2.537766\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:41 INFO 139780359198336] #quality_metric: host=algo-1, epoch=97, batch=5 train loss <loss>=2.5377655029296875\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:41 INFO 139780359198336] Epoch[97] Batch [5]#011Speed: 62.79 samples/sec#011loss=2.537766\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:45 INFO 139780359198336] processed a total of 610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525691.7650099, \"EndTime\": 1617525705.3423839, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13577.064990997314, \"count\": 1, \"min\": 13577.064990997314, \"max\": 13577.064990997314}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:45 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.928193659960016 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:45 INFO 139780359198336] #progress_metric: host=algo-1, completed 24.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:45 INFO 139780359198336] #quality_metric: host=algo-1, epoch=97, train loss <loss>=2.548092317581177\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:45 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:49 INFO 139780359198336] Epoch[98] Batch[0] avg_epoch_loss=2.553159\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:49 INFO 139780359198336] #quality_metric: host=algo-1, epoch=98, batch=0 train loss <loss>=2.55315899848938\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:54 INFO 139780359198336] Epoch[98] Batch[5] avg_epoch_loss=2.497222\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:54 INFO 139780359198336] #quality_metric: host=algo-1, epoch=98, batch=5 train loss <loss>=2.497222145398458\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:54 INFO 139780359198336] Epoch[98] Batch [5]#011Speed: 62.64 samples/sec#011loss=2.497222\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:58 INFO 139780359198336] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525705.342508, \"EndTime\": 1617525718.8728874, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13529.858112335205, \"count\": 1, \"min\": 13529.858112335205, \"max\": 13529.858112335205}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:58 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=47.08061574021177 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:58 INFO 139780359198336] #progress_metric: host=algo-1, completed 24.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:58 INFO 139780359198336] #quality_metric: host=algo-1, epoch=98, train loss <loss>=2.510973048210144\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:41:58 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:03 INFO 139780359198336] Epoch[99] Batch[0] avg_epoch_loss=2.508909\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:03 INFO 139780359198336] #quality_metric: host=algo-1, epoch=99, batch=0 train loss <loss>=2.50890851020813\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:08 INFO 139780359198336] Epoch[99] Batch[5] avg_epoch_loss=2.530097\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:08 INFO 139780359198336] #quality_metric: host=algo-1, epoch=99, batch=5 train loss <loss>=2.530097405115763\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:08 INFO 139780359198336] Epoch[99] Batch [5]#011Speed: 54.77 samples/sec#011loss=2.530097\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 08:42:14 INFO 139780359198336] Epoch[99] Batch[10] avg_epoch_loss=2.481069\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:14 INFO 139780359198336] #quality_metric: host=algo-1, epoch=99, batch=10 train loss <loss>=2.4222338676452635\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:14 INFO 139780359198336] Epoch[99] Batch [10]#011Speed: 60.06 samples/sec#011loss=2.422234\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:14 INFO 139780359198336] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525718.8729763, \"EndTime\": 1617525734.308646, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 15435.097455978394, \"count\": 1, \"min\": 15435.097455978394, \"max\": 15435.097455978394}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:14 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=42.69464719427963 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:14 INFO 139780359198336] #progress_metric: host=algo-1, completed 25.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:14 INFO 139780359198336] #quality_metric: host=algo-1, epoch=99, train loss <loss>=2.4810685244473545\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:14 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:18 INFO 139780359198336] Epoch[100] Batch[0] avg_epoch_loss=2.563401\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:18 INFO 139780359198336] #quality_metric: host=algo-1, epoch=100, batch=0 train loss <loss>=2.5634007453918457\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:23 INFO 139780359198336] Epoch[100] Batch[5] avg_epoch_loss=2.570264\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:23 INFO 139780359198336] #quality_metric: host=algo-1, epoch=100, batch=5 train loss <loss>=2.570264299710592\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:23 INFO 139780359198336] Epoch[100] Batch [5]#011Speed: 63.24 samples/sec#011loss=2.570264\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:28 INFO 139780359198336] Epoch[100] Batch[10] avg_epoch_loss=2.615615\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:28 INFO 139780359198336] #quality_metric: host=algo-1, epoch=100, batch=10 train loss <loss>=2.6700350761413576\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:28 INFO 139780359198336] Epoch[100] Batch [10]#011Speed: 60.12 samples/sec#011loss=2.670035\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:28 INFO 139780359198336] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525734.3087094, \"EndTime\": 1617525748.7894619, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14480.430603027344, \"count\": 1, \"min\": 14480.430603027344, \"max\": 14480.430603027344}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:28 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.509341944794635 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:28 INFO 139780359198336] #progress_metric: host=algo-1, completed 25.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:28 INFO 139780359198336] #quality_metric: host=algo-1, epoch=100, train loss <loss>=2.615614652633667\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:28 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:32 INFO 139780359198336] Epoch[101] Batch[0] avg_epoch_loss=2.500040\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:32 INFO 139780359198336] #quality_metric: host=algo-1, epoch=101, batch=0 train loss <loss>=2.500040054321289\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:38 INFO 139780359198336] Epoch[101] Batch[5] avg_epoch_loss=2.536871\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:38 INFO 139780359198336] #quality_metric: host=algo-1, epoch=101, batch=5 train loss <loss>=2.5368707180023193\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:38 INFO 139780359198336] Epoch[101] Batch [5]#011Speed: 63.48 samples/sec#011loss=2.536871\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:42 INFO 139780359198336] processed a total of 591 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525748.7895284, \"EndTime\": 1617525762.0983608, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13308.517217636108, \"count\": 1, \"min\": 13308.517217636108, \"max\": 13308.517217636108}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:42 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.40726527246205 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:42 INFO 139780359198336] #progress_metric: host=algo-1, completed 25.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:42 INFO 139780359198336] #quality_metric: host=algo-1, epoch=101, train loss <loss>=2.530812311172485\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:42 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:46 INFO 139780359198336] Epoch[102] Batch[0] avg_epoch_loss=2.500725\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:46 INFO 139780359198336] #quality_metric: host=algo-1, epoch=102, batch=0 train loss <loss>=2.500725030899048\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:51 INFO 139780359198336] Epoch[102] Batch[5] avg_epoch_loss=2.459030\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:51 INFO 139780359198336] #quality_metric: host=algo-1, epoch=102, batch=5 train loss <loss>=2.4590302308400473\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:51 INFO 139780359198336] Epoch[102] Batch [5]#011Speed: 63.68 samples/sec#011loss=2.459030\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:55 INFO 139780359198336] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525762.0984437, \"EndTime\": 1617525775.416029, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13317.224025726318, \"count\": 1, \"min\": 13317.224025726318, \"max\": 13317.224025726318}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:55 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=47.83242325802592 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:55 INFO 139780359198336] #progress_metric: host=algo-1, completed 25.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:55 INFO 139780359198336] #quality_metric: host=algo-1, epoch=102, train loss <loss>=2.4940624952316286\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:55 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:59 INFO 139780359198336] Epoch[103] Batch[0] avg_epoch_loss=2.466608\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:42:59 INFO 139780359198336] #quality_metric: host=algo-1, epoch=103, batch=0 train loss <loss>=2.4666078090667725\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:05 INFO 139780359198336] Epoch[103] Batch[5] avg_epoch_loss=2.505784\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:05 INFO 139780359198336] #quality_metric: host=algo-1, epoch=103, batch=5 train loss <loss>=2.505784034729004\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:05 INFO 139780359198336] Epoch[103] Batch [5]#011Speed: 56.32 samples/sec#011loss=2.505784\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:10 INFO 139780359198336] Epoch[103] Batch[10] avg_epoch_loss=2.617147\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:10 INFO 139780359198336] #quality_metric: host=algo-1, epoch=103, batch=10 train loss <loss>=2.7507834434509277\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:10 INFO 139780359198336] Epoch[103] Batch [10]#011Speed: 57.10 samples/sec#011loss=2.750783\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:10 INFO 139780359198336] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525775.4160984, \"EndTime\": 1617525790.8397386, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 15423.289060592651, \"count\": 1, \"min\": 15423.289060592651, \"max\": 15423.289060592651}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:10 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=41.75479589408842 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:10 INFO 139780359198336] #progress_metric: host=algo-1, completed 26.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:10 INFO 139780359198336] #quality_metric: host=algo-1, epoch=103, train loss <loss>=2.6171474023298784\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:10 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:15 INFO 139780359198336] Epoch[104] Batch[0] avg_epoch_loss=2.632022\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:15 INFO 139780359198336] #quality_metric: host=algo-1, epoch=104, batch=0 train loss <loss>=2.632021903991699\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:20 INFO 139780359198336] Epoch[104] Batch[5] avg_epoch_loss=2.590924\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:20 INFO 139780359198336] #quality_metric: host=algo-1, epoch=104, batch=5 train loss <loss>=2.5909239451090493\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:20 INFO 139780359198336] Epoch[104] Batch [5]#011Speed: 62.34 samples/sec#011loss=2.590924\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:24 INFO 139780359198336] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525790.8398004, \"EndTime\": 1617525804.2810733, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13440.870761871338, \"count\": 1, \"min\": 13440.870761871338, \"max\": 13440.870761871338}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:24 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=47.16917977713604 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:24 INFO 139780359198336] #progress_metric: host=algo-1, completed 26.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:24 INFO 139780359198336] #quality_metric: host=algo-1, epoch=104, train loss <loss>=2.5643097877502443\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:24 INFO 139780359198336] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 08:43:28 INFO 139780359198336] Epoch[105] Batch[0] avg_epoch_loss=2.543126\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:28 INFO 139780359198336] #quality_metric: host=algo-1, epoch=105, batch=0 train loss <loss>=2.543125629425049\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:33 INFO 139780359198336] Epoch[105] Batch[5] avg_epoch_loss=2.564661\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:33 INFO 139780359198336] #quality_metric: host=algo-1, epoch=105, batch=5 train loss <loss>=2.564661383628845\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:33 INFO 139780359198336] Epoch[105] Batch [5]#011Speed: 61.25 samples/sec#011loss=2.564661\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:38 INFO 139780359198336] Epoch[105] Batch[10] avg_epoch_loss=2.554935\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:38 INFO 139780359198336] #quality_metric: host=algo-1, epoch=105, batch=10 train loss <loss>=2.5432623386383058\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:38 INFO 139780359198336] Epoch[105] Batch [10]#011Speed: 58.94 samples/sec#011loss=2.543262\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:38 INFO 139780359198336] processed a total of 692 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525804.281149, \"EndTime\": 1617525818.96077, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14679.211378097534, \"count\": 1, \"min\": 14679.211378097534, \"max\": 14679.211378097534}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:38 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=47.141199980906116 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:38 INFO 139780359198336] #progress_metric: host=algo-1, completed 26.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:38 INFO 139780359198336] #quality_metric: host=algo-1, epoch=105, train loss <loss>=2.5549345449967817\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:38 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:43 INFO 139780359198336] Epoch[106] Batch[0] avg_epoch_loss=2.620317\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:43 INFO 139780359198336] #quality_metric: host=algo-1, epoch=106, batch=0 train loss <loss>=2.620316982269287\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:48 INFO 139780359198336] Epoch[106] Batch[5] avg_epoch_loss=2.557047\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:48 INFO 139780359198336] #quality_metric: host=algo-1, epoch=106, batch=5 train loss <loss>=2.557047486305237\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:48 INFO 139780359198336] Epoch[106] Batch [5]#011Speed: 62.15 samples/sec#011loss=2.557047\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:52 INFO 139780359198336] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525818.9608328, \"EndTime\": 1617525832.4742084, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13513.055324554443, \"count\": 1, \"min\": 13513.055324554443, \"max\": 13513.055324554443}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:52 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.95512762685421 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:52 INFO 139780359198336] #progress_metric: host=algo-1, completed 26.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:52 INFO 139780359198336] #quality_metric: host=algo-1, epoch=106, train loss <loss>=2.551270294189453\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:52 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:56 INFO 139780359198336] Epoch[107] Batch[0] avg_epoch_loss=2.502819\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:43:56 INFO 139780359198336] #quality_metric: host=algo-1, epoch=107, batch=0 train loss <loss>=2.5028188228607178\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:01 INFO 139780359198336] Epoch[107] Batch[5] avg_epoch_loss=2.510449\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:01 INFO 139780359198336] #quality_metric: host=algo-1, epoch=107, batch=5 train loss <loss>=2.5104488134384155\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:01 INFO 139780359198336] Epoch[107] Batch [5]#011Speed: 61.87 samples/sec#011loss=2.510449\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:07 INFO 139780359198336] Epoch[107] Batch[10] avg_epoch_loss=2.591001\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:07 INFO 139780359198336] #quality_metric: host=algo-1, epoch=107, batch=10 train loss <loss>=2.6876642227172853\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:07 INFO 139780359198336] Epoch[107] Batch [10]#011Speed: 51.97 samples/sec#011loss=2.687664\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:07 INFO 139780359198336] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525832.4742897, \"EndTime\": 1617525847.9746516, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 15499.858379364014, \"count\": 1, \"min\": 15499.858379364014, \"max\": 15499.858379364014}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:07 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=42.064648123529146 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:07 INFO 139780359198336] #progress_metric: host=algo-1, completed 27.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:07 INFO 139780359198336] #quality_metric: host=algo-1, epoch=107, train loss <loss>=2.591001272201538\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:07 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:12 INFO 139780359198336] Epoch[108] Batch[0] avg_epoch_loss=2.553141\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:12 INFO 139780359198336] #quality_metric: host=algo-1, epoch=108, batch=0 train loss <loss>=2.553140878677368\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:17 INFO 139780359198336] Epoch[108] Batch[5] avg_epoch_loss=2.526030\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:17 INFO 139780359198336] #quality_metric: host=algo-1, epoch=108, batch=5 train loss <loss>=2.5260300238927207\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:17 INFO 139780359198336] Epoch[108] Batch [5]#011Speed: 62.10 samples/sec#011loss=2.526030\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:22 INFO 139780359198336] Epoch[108] Batch[10] avg_epoch_loss=2.552843\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:22 INFO 139780359198336] #quality_metric: host=algo-1, epoch=108, batch=10 train loss <loss>=2.585018539428711\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:22 INFO 139780359198336] Epoch[108] Batch [10]#011Speed: 61.22 samples/sec#011loss=2.585019\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:22 INFO 139780359198336] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525847.974716, \"EndTime\": 1617525862.6062706, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14631.243705749512, \"count\": 1, \"min\": 14631.243705749512, \"max\": 14631.243705749512}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:22 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.810058616418274 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:22 INFO 139780359198336] #progress_metric: host=algo-1, completed 27.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:22 INFO 139780359198336] #quality_metric: host=algo-1, epoch=108, train loss <loss>=2.552842985499989\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:22 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:26 INFO 139780359198336] Epoch[109] Batch[0] avg_epoch_loss=2.583120\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:26 INFO 139780359198336] #quality_metric: host=algo-1, epoch=109, batch=0 train loss <loss>=2.5831198692321777\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:31 INFO 139780359198336] Epoch[109] Batch[5] avg_epoch_loss=2.529967\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:31 INFO 139780359198336] #quality_metric: host=algo-1, epoch=109, batch=5 train loss <loss>=2.5299665133158364\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:31 INFO 139780359198336] Epoch[109] Batch [5]#011Speed: 62.43 samples/sec#011loss=2.529967\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:37 INFO 139780359198336] Epoch[109] Batch[10] avg_epoch_loss=2.577079\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:37 INFO 139780359198336] #quality_metric: host=algo-1, epoch=109, batch=10 train loss <loss>=2.633613443374634\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:37 INFO 139780359198336] Epoch[109] Batch [10]#011Speed: 58.67 samples/sec#011loss=2.633613\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:37 INFO 139780359198336] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525862.606341, \"EndTime\": 1617525877.3520176, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14745.269060134888, \"count\": 1, \"min\": 14745.269060134888, \"max\": 14745.269060134888}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:37 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.03110062321674 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:37 INFO 139780359198336] #progress_metric: host=algo-1, completed 27.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:37 INFO 139780359198336] #quality_metric: host=algo-1, epoch=109, train loss <loss>=2.5770787542516533\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:37 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:41 INFO 139780359198336] Epoch[110] Batch[0] avg_epoch_loss=2.558242\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:41 INFO 139780359198336] #quality_metric: host=algo-1, epoch=110, batch=0 train loss <loss>=2.558241605758667\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 08:44:46 INFO 139780359198336] Epoch[110] Batch[5] avg_epoch_loss=2.523965\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:46 INFO 139780359198336] #quality_metric: host=algo-1, epoch=110, batch=5 train loss <loss>=2.523964842160543\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:46 INFO 139780359198336] Epoch[110] Batch [5]#011Speed: 63.08 samples/sec#011loss=2.523965\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:51 INFO 139780359198336] Epoch[110] Batch[10] avg_epoch_loss=2.494382\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:51 INFO 139780359198336] #quality_metric: host=algo-1, epoch=110, batch=10 train loss <loss>=2.4588815212249755\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:51 INFO 139780359198336] Epoch[110] Batch [10]#011Speed: 60.91 samples/sec#011loss=2.458882\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:51 INFO 139780359198336] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525877.3520823, \"EndTime\": 1617525891.8044336, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14451.676368713379, \"count\": 1, \"min\": 14451.676368713379, \"max\": 14451.676368713379}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:51 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.461529918359034 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:51 INFO 139780359198336] #progress_metric: host=algo-1, completed 27.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:51 INFO 139780359198336] #quality_metric: host=algo-1, epoch=110, train loss <loss>=2.4943815144625576\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:51 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:55 INFO 139780359198336] Epoch[111] Batch[0] avg_epoch_loss=2.494928\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:44:55 INFO 139780359198336] #quality_metric: host=algo-1, epoch=111, batch=0 train loss <loss>=2.4949283599853516\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:01 INFO 139780359198336] Epoch[111] Batch[5] avg_epoch_loss=2.562337\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:01 INFO 139780359198336] #quality_metric: host=algo-1, epoch=111, batch=5 train loss <loss>=2.5623366038004556\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:01 INFO 139780359198336] Epoch[111] Batch [5]#011Speed: 62.88 samples/sec#011loss=2.562337\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:05 INFO 139780359198336] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525891.8045018, \"EndTime\": 1617525905.964496, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14159.509658813477, \"count\": 1, \"min\": 14159.509658813477, \"max\": 14159.509658813477}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:05 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.91611384826266 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:05 INFO 139780359198336] #progress_metric: host=algo-1, completed 28.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:05 INFO 139780359198336] #quality_metric: host=algo-1, epoch=111, train loss <loss>=2.5500858068466186\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:05 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:10 INFO 139780359198336] Epoch[112] Batch[0] avg_epoch_loss=2.611571\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:10 INFO 139780359198336] #quality_metric: host=algo-1, epoch=112, batch=0 train loss <loss>=2.6115705966949463\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:15 INFO 139780359198336] Epoch[112] Batch[5] avg_epoch_loss=2.547301\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:15 INFO 139780359198336] #quality_metric: host=algo-1, epoch=112, batch=5 train loss <loss>=2.547300616900126\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:15 INFO 139780359198336] Epoch[112] Batch [5]#011Speed: 62.80 samples/sec#011loss=2.547301\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:19 INFO 139780359198336] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525905.9646568, \"EndTime\": 1617525919.6191936, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13653.76591682434, \"count\": 1, \"min\": 13653.76591682434, \"max\": 13653.76591682434}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:19 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.36043348196292 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:19 INFO 139780359198336] #progress_metric: host=algo-1, completed 28.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:19 INFO 139780359198336] #quality_metric: host=algo-1, epoch=112, train loss <loss>=2.5391979217529297\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:19 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:23 INFO 139780359198336] Epoch[113] Batch[0] avg_epoch_loss=2.473667\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:23 INFO 139780359198336] #quality_metric: host=algo-1, epoch=113, batch=0 train loss <loss>=2.4736673831939697\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:28 INFO 139780359198336] Epoch[113] Batch[5] avg_epoch_loss=2.507433\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:28 INFO 139780359198336] #quality_metric: host=algo-1, epoch=113, batch=5 train loss <loss>=2.5074331363042197\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:28 INFO 139780359198336] Epoch[113] Batch [5]#011Speed: 63.19 samples/sec#011loss=2.507433\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:34 INFO 139780359198336] Epoch[113] Batch[10] avg_epoch_loss=2.518011\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:34 INFO 139780359198336] #quality_metric: host=algo-1, epoch=113, batch=10 train loss <loss>=2.5307052612304686\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:34 INFO 139780359198336] Epoch[113] Batch [10]#011Speed: 58.00 samples/sec#011loss=2.530705\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:34 INFO 139780359198336] processed a total of 687 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525919.6192636, \"EndTime\": 1617525934.2395737, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14619.827508926392, \"count\": 1, \"min\": 14619.827508926392, \"max\": 14619.827508926392}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:34 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.990669663559295 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:34 INFO 139780359198336] #progress_metric: host=algo-1, completed 28.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:34 INFO 139780359198336] #quality_metric: host=algo-1, epoch=113, train loss <loss>=2.51801137490706\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:34 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:38 INFO 139780359198336] Epoch[114] Batch[0] avg_epoch_loss=2.485500\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:38 INFO 139780359198336] #quality_metric: host=algo-1, epoch=114, batch=0 train loss <loss>=2.485499858856201\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:43 INFO 139780359198336] Epoch[114] Batch[5] avg_epoch_loss=2.498083\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:43 INFO 139780359198336] #quality_metric: host=algo-1, epoch=114, batch=5 train loss <loss>=2.498083472251892\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:43 INFO 139780359198336] Epoch[114] Batch [5]#011Speed: 62.45 samples/sec#011loss=2.498083\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:47 INFO 139780359198336] processed a total of 603 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525934.2396395, \"EndTime\": 1617525947.6814475, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13441.34497642517, \"count\": 1, \"min\": 13441.34497642517, \"max\": 13441.34497642517}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:47 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.86102977341375 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:47 INFO 139780359198336] #progress_metric: host=algo-1, completed 28.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:47 INFO 139780359198336] #quality_metric: host=algo-1, epoch=114, train loss <loss>=2.4800618171691893\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:47 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:51 INFO 139780359198336] Epoch[115] Batch[0] avg_epoch_loss=2.446050\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:51 INFO 139780359198336] #quality_metric: host=algo-1, epoch=115, batch=0 train loss <loss>=2.4460504055023193\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:56 INFO 139780359198336] Epoch[115] Batch[5] avg_epoch_loss=2.521624\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:56 INFO 139780359198336] #quality_metric: host=algo-1, epoch=115, batch=5 train loss <loss>=2.521624286969503\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:45:56 INFO 139780359198336] Epoch[115] Batch [5]#011Speed: 62.98 samples/sec#011loss=2.521624\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:02 INFO 139780359198336] Epoch[115] Batch[10] avg_epoch_loss=2.524512\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:02 INFO 139780359198336] #quality_metric: host=algo-1, epoch=115, batch=10 train loss <loss>=2.5279776573181154\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:02 INFO 139780359198336] Epoch[115] Batch [10]#011Speed: 57.48 samples/sec#011loss=2.527978\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:02 INFO 139780359198336] processed a total of 685 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525947.6815796, \"EndTime\": 1617525962.3667145, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14684.756755828857, \"count\": 1, \"min\": 14684.756755828857, \"max\": 14684.756755828857}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:02 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.64668920979314 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:02 INFO 139780359198336] #progress_metric: host=algo-1, completed 29.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:02 INFO 139780359198336] #quality_metric: host=algo-1, epoch=115, train loss <loss>=2.5245121825825083\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:02 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:07 INFO 139780359198336] Epoch[116] Batch[0] avg_epoch_loss=2.431298\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:07 INFO 139780359198336] #quality_metric: host=algo-1, epoch=116, batch=0 train loss <loss>=2.431297779083252\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 08:46:12 INFO 139780359198336] Epoch[116] Batch[5] avg_epoch_loss=2.550803\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:12 INFO 139780359198336] #quality_metric: host=algo-1, epoch=116, batch=5 train loss <loss>=2.5508033831914267\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:12 INFO 139780359198336] Epoch[116] Batch [5]#011Speed: 62.59 samples/sec#011loss=2.550803\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:16 INFO 139780359198336] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525962.3667843, \"EndTime\": 1617525976.3251667, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13957.747220993042, \"count\": 1, \"min\": 13957.747220993042, \"max\": 13957.747220993042}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:16 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.8522486882634 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:16 INFO 139780359198336] #progress_metric: host=algo-1, completed 29.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:16 INFO 139780359198336] #quality_metric: host=algo-1, epoch=116, train loss <loss>=2.5197388410568236\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:16 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:20 INFO 139780359198336] Epoch[117] Batch[0] avg_epoch_loss=2.515895\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:20 INFO 139780359198336] #quality_metric: host=algo-1, epoch=117, batch=0 train loss <loss>=2.515894889831543\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:25 INFO 139780359198336] Epoch[117] Batch[5] avg_epoch_loss=2.537964\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:25 INFO 139780359198336] #quality_metric: host=algo-1, epoch=117, batch=5 train loss <loss>=2.5379640658696494\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:25 INFO 139780359198336] Epoch[117] Batch [5]#011Speed: 62.78 samples/sec#011loss=2.537964\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:30 INFO 139780359198336] Epoch[117] Batch[10] avg_epoch_loss=2.458461\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:30 INFO 139780359198336] #quality_metric: host=algo-1, epoch=117, batch=10 train loss <loss>=2.3630563735961916\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:30 INFO 139780359198336] Epoch[117] Batch [10]#011Speed: 59.00 samples/sec#011loss=2.363056\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:30 INFO 139780359198336] processed a total of 675 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525976.325239, \"EndTime\": 1617525990.8884263, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14562.828779220581, \"count\": 1, \"min\": 14562.828779220581, \"max\": 14562.828779220581}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:30 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.35057297857012 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:30 INFO 139780359198336] #progress_metric: host=algo-1, completed 29.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:30 INFO 139780359198336] #quality_metric: host=algo-1, epoch=117, train loss <loss>=2.458460569381714\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:30 INFO 139780359198336] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:31 INFO 139780359198336] Saved checkpoint to \"/opt/ml/model/state_ebc059f7-dff7-4732-a3a3-7c18b1b30e24-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525990.8884938, \"EndTime\": 1617525991.0825636, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 193.63832473754883, \"count\": 1, \"min\": 193.63832473754883, \"max\": 193.63832473754883}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:35 INFO 139780359198336] Epoch[118] Batch[0] avg_epoch_loss=2.424309\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:35 INFO 139780359198336] #quality_metric: host=algo-1, epoch=118, batch=0 train loss <loss>=2.424309253692627\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:40 INFO 139780359198336] Epoch[118] Batch[5] avg_epoch_loss=2.485785\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:40 INFO 139780359198336] #quality_metric: host=algo-1, epoch=118, batch=5 train loss <loss>=2.485785484313965\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:40 INFO 139780359198336] Epoch[118] Batch [5]#011Speed: 62.74 samples/sec#011loss=2.485785\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:44 INFO 139780359198336] processed a total of 599 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617525991.0826428, \"EndTime\": 1617526004.5957608, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13513.055086135864, \"count\": 1, \"min\": 13513.055086135864, \"max\": 13513.055086135864}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:44 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.32717214361726 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:44 INFO 139780359198336] #progress_metric: host=algo-1, completed 29.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:44 INFO 139780359198336] #quality_metric: host=algo-1, epoch=118, train loss <loss>=2.5004332065582275\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:44 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:48 INFO 139780359198336] Epoch[119] Batch[0] avg_epoch_loss=2.474196\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:48 INFO 139780359198336] #quality_metric: host=algo-1, epoch=119, batch=0 train loss <loss>=2.474196195602417\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:53 INFO 139780359198336] Epoch[119] Batch[5] avg_epoch_loss=2.478106\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:53 INFO 139780359198336] #quality_metric: host=algo-1, epoch=119, batch=5 train loss <loss>=2.478106458981832\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:53 INFO 139780359198336] Epoch[119] Batch [5]#011Speed: 62.78 samples/sec#011loss=2.478106\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:57 INFO 139780359198336] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526004.5958326, \"EndTime\": 1617526017.9807734, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13384.515285491943, \"count\": 1, \"min\": 13384.515285491943, \"max\": 13384.515285491943}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:57 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.24706864449265 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:57 INFO 139780359198336] #progress_metric: host=algo-1, completed 30.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:57 INFO 139780359198336] #quality_metric: host=algo-1, epoch=119, train loss <loss>=2.495258021354675\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:46:57 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:02 INFO 139780359198336] Epoch[120] Batch[0] avg_epoch_loss=2.573373\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:02 INFO 139780359198336] #quality_metric: host=algo-1, epoch=120, batch=0 train loss <loss>=2.5733728408813477\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:08 INFO 139780359198336] Epoch[120] Batch[5] avg_epoch_loss=2.549325\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:08 INFO 139780359198336] #quality_metric: host=algo-1, epoch=120, batch=5 train loss <loss>=2.549325148264567\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:08 INFO 139780359198336] Epoch[120] Batch [5]#011Speed: 54.29 samples/sec#011loss=2.549325\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:12 INFO 139780359198336] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526017.9808567, \"EndTime\": 1617526032.4618056, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14480.587244033813, \"count\": 1, \"min\": 14480.587244033813, \"max\": 14480.587244033813}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:12 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.368030617234 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:12 INFO 139780359198336] #progress_metric: host=algo-1, completed 30.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:12 INFO 139780359198336] #quality_metric: host=algo-1, epoch=120, train loss <loss>=2.5232845067977907\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:12 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:16 INFO 139780359198336] Epoch[121] Batch[0] avg_epoch_loss=2.609406\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:16 INFO 139780359198336] #quality_metric: host=algo-1, epoch=121, batch=0 train loss <loss>=2.609405994415283\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:21 INFO 139780359198336] Epoch[121] Batch[5] avg_epoch_loss=2.545847\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:21 INFO 139780359198336] #quality_metric: host=algo-1, epoch=121, batch=5 train loss <loss>=2.545846700668335\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:21 INFO 139780359198336] Epoch[121] Batch [5]#011Speed: 63.21 samples/sec#011loss=2.545847\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:26 INFO 139780359198336] Epoch[121] Batch[10] avg_epoch_loss=2.621240\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:26 INFO 139780359198336] #quality_metric: host=algo-1, epoch=121, batch=10 train loss <loss>=2.711710977554321\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:26 INFO 139780359198336] Epoch[121] Batch [10]#011Speed: 61.23 samples/sec#011loss=2.711711\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:26 INFO 139780359198336] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526032.4618902, \"EndTime\": 1617526046.9724216, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14510.030508041382, \"count\": 1, \"min\": 14510.030508041382, \"max\": 14510.030508041382}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:26 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.07196325619506 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:26 INFO 139780359198336] #progress_metric: host=algo-1, completed 30.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:26 INFO 139780359198336] #quality_metric: host=algo-1, epoch=121, train loss <loss>=2.6212395537983286\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:26 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:31 INFO 139780359198336] Epoch[122] Batch[0] avg_epoch_loss=2.651118\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:31 INFO 139780359198336] #quality_metric: host=algo-1, epoch=122, batch=0 train loss <loss>=2.6511178016662598\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 08:47:36 INFO 139780359198336] Epoch[122] Batch[5] avg_epoch_loss=2.579458\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:36 INFO 139780359198336] #quality_metric: host=algo-1, epoch=122, batch=5 train loss <loss>=2.5794584353764853\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:36 INFO 139780359198336] Epoch[122] Batch [5]#011Speed: 62.48 samples/sec#011loss=2.579458\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:41 INFO 139780359198336] Epoch[122] Batch[10] avg_epoch_loss=2.515592\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:41 INFO 139780359198336] #quality_metric: host=algo-1, epoch=122, batch=10 train loss <loss>=2.4389529705047606\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:41 INFO 139780359198336] Epoch[122] Batch [10]#011Speed: 60.02 samples/sec#011loss=2.438953\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:41 INFO 139780359198336] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526046.9724882, \"EndTime\": 1617526061.5455115, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14572.701454162598, \"count\": 1, \"min\": 14572.701454162598, \"max\": 14572.701454162598}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:41 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.015339677851124 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:41 INFO 139780359198336] #progress_metric: host=algo-1, completed 30.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:41 INFO 139780359198336] #quality_metric: host=algo-1, epoch=122, train loss <loss>=2.5155923149802466\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:41 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:45 INFO 139780359198336] Epoch[123] Batch[0] avg_epoch_loss=2.461634\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:45 INFO 139780359198336] #quality_metric: host=algo-1, epoch=123, batch=0 train loss <loss>=2.461634397506714\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:50 INFO 139780359198336] Epoch[123] Batch[5] avg_epoch_loss=2.546653\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:50 INFO 139780359198336] #quality_metric: host=algo-1, epoch=123, batch=5 train loss <loss>=2.546653429667155\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:50 INFO 139780359198336] Epoch[123] Batch [5]#011Speed: 62.80 samples/sec#011loss=2.546653\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:54 INFO 139780359198336] processed a total of 595 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526061.5455863, \"EndTime\": 1617526074.9621522, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13416.14317893982, \"count\": 1, \"min\": 13416.14317893982, \"max\": 13416.14317893982}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:54 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.349160076134645 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:54 INFO 139780359198336] #progress_metric: host=algo-1, completed 31.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:54 INFO 139780359198336] #quality_metric: host=algo-1, epoch=123, train loss <loss>=2.5390326499938967\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:54 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:59 INFO 139780359198336] Epoch[124] Batch[0] avg_epoch_loss=2.432220\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:47:59 INFO 139780359198336] #quality_metric: host=algo-1, epoch=124, batch=0 train loss <loss>=2.432220220565796\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:04 INFO 139780359198336] Epoch[124] Batch[5] avg_epoch_loss=2.526643\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:04 INFO 139780359198336] #quality_metric: host=algo-1, epoch=124, batch=5 train loss <loss>=2.526642680168152\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:04 INFO 139780359198336] Epoch[124] Batch [5]#011Speed: 59.24 samples/sec#011loss=2.526643\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:09 INFO 139780359198336] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526074.9622376, \"EndTime\": 1617526089.2868443, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14324.25856590271, \"count\": 1, \"min\": 14324.25856590271, \"max\": 14324.25856590271}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:09 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.46971273838602 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:09 INFO 139780359198336] #progress_metric: host=algo-1, completed 31.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:09 INFO 139780359198336] #quality_metric: host=algo-1, epoch=124, train loss <loss>=2.535660219192505\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:09 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:13 INFO 139780359198336] Epoch[125] Batch[0] avg_epoch_loss=2.629743\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:13 INFO 139780359198336] #quality_metric: host=algo-1, epoch=125, batch=0 train loss <loss>=2.6297433376312256\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:18 INFO 139780359198336] Epoch[125] Batch[5] avg_epoch_loss=2.524776\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:18 INFO 139780359198336] #quality_metric: host=algo-1, epoch=125, batch=5 train loss <loss>=2.524776061375936\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:18 INFO 139780359198336] Epoch[125] Batch [5]#011Speed: 62.42 samples/sec#011loss=2.524776\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:22 INFO 139780359198336] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526089.286911, \"EndTime\": 1617526102.8104637, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13523.082494735718, \"count\": 1, \"min\": 13523.082494735718, \"max\": 13523.082494735718}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:22 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=47.10421563050044 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:22 INFO 139780359198336] #progress_metric: host=algo-1, completed 31.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:22 INFO 139780359198336] #quality_metric: host=algo-1, epoch=125, train loss <loss>=2.528793287277222\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:22 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:27 INFO 139780359198336] Epoch[126] Batch[0] avg_epoch_loss=2.364133\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:27 INFO 139780359198336] #quality_metric: host=algo-1, epoch=126, batch=0 train loss <loss>=2.364133358001709\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:32 INFO 139780359198336] Epoch[126] Batch[5] avg_epoch_loss=2.476229\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:32 INFO 139780359198336] #quality_metric: host=algo-1, epoch=126, batch=5 train loss <loss>=2.476228674252828\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:32 INFO 139780359198336] Epoch[126] Batch [5]#011Speed: 62.74 samples/sec#011loss=2.476229\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:36 INFO 139780359198336] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526102.810548, \"EndTime\": 1617526116.2176027, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13406.358480453491, \"count\": 1, \"min\": 13406.358480453491, \"max\": 13406.358480453491}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:36 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.842823172832794 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:36 INFO 139780359198336] #progress_metric: host=algo-1, completed 31.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:36 INFO 139780359198336] #quality_metric: host=algo-1, epoch=126, train loss <loss>=2.4625836610794067\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:36 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:40 INFO 139780359198336] Epoch[127] Batch[0] avg_epoch_loss=2.597773\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:40 INFO 139780359198336] #quality_metric: host=algo-1, epoch=127, batch=0 train loss <loss>=2.5977725982666016\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:45 INFO 139780359198336] Epoch[127] Batch[5] avg_epoch_loss=2.563044\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:45 INFO 139780359198336] #quality_metric: host=algo-1, epoch=127, batch=5 train loss <loss>=2.5630438725153604\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:45 INFO 139780359198336] Epoch[127] Batch [5]#011Speed: 62.29 samples/sec#011loss=2.563044\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:49 INFO 139780359198336] processed a total of 607 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526116.2177262, \"EndTime\": 1617526129.7264256, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13508.333206176758, \"count\": 1, \"min\": 13508.333206176758, \"max\": 13508.333206176758}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:49 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.93483935864712 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:49 INFO 139780359198336] #progress_metric: host=algo-1, completed 32.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:49 INFO 139780359198336] #quality_metric: host=algo-1, epoch=127, train loss <loss>=2.4685781478881834\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:49 INFO 139780359198336] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 08:48:53 INFO 139780359198336] Epoch[128] Batch[0] avg_epoch_loss=2.474997\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:53 INFO 139780359198336] #quality_metric: host=algo-1, epoch=128, batch=0 train loss <loss>=2.474996566772461\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:59 INFO 139780359198336] Epoch[128] Batch[5] avg_epoch_loss=2.491120\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:59 INFO 139780359198336] #quality_metric: host=algo-1, epoch=128, batch=5 train loss <loss>=2.491119901339213\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:48:59 INFO 139780359198336] Epoch[128] Batch [5]#011Speed: 62.73 samples/sec#011loss=2.491120\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:03 INFO 139780359198336] processed a total of 594 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526129.72651, \"EndTime\": 1617526143.3440852, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13617.218494415283, \"count\": 1, \"min\": 13617.218494415283, \"max\": 13617.218494415283}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:03 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.620923981459775 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:03 INFO 139780359198336] #progress_metric: host=algo-1, completed 32.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:03 INFO 139780359198336] #quality_metric: host=algo-1, epoch=128, train loss <loss>=2.50401086807251\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:03 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:08 INFO 139780359198336] Epoch[129] Batch[0] avg_epoch_loss=2.573504\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:08 INFO 139780359198336] #quality_metric: host=algo-1, epoch=129, batch=0 train loss <loss>=2.5735037326812744\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:13 INFO 139780359198336] Epoch[129] Batch[5] avg_epoch_loss=2.530906\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:13 INFO 139780359198336] #quality_metric: host=algo-1, epoch=129, batch=5 train loss <loss>=2.530906319618225\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:13 INFO 139780359198336] Epoch[129] Batch [5]#011Speed: 62.36 samples/sec#011loss=2.530906\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:17 INFO 139780359198336] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526143.3441556, \"EndTime\": 1617526157.275249, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13930.613040924072, \"count\": 1, \"min\": 13930.613040924072, \"max\": 13930.613040924072}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:17 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.58271654764979 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:17 INFO 139780359198336] #progress_metric: host=algo-1, completed 32.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:17 INFO 139780359198336] #quality_metric: host=algo-1, epoch=129, train loss <loss>=2.552776837348938\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:17 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:21 INFO 139780359198336] Epoch[130] Batch[0] avg_epoch_loss=2.520883\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:21 INFO 139780359198336] #quality_metric: host=algo-1, epoch=130, batch=0 train loss <loss>=2.520883321762085\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:26 INFO 139780359198336] Epoch[130] Batch[5] avg_epoch_loss=2.487195\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:26 INFO 139780359198336] #quality_metric: host=algo-1, epoch=130, batch=5 train loss <loss>=2.487195134162903\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:26 INFO 139780359198336] Epoch[130] Batch [5]#011Speed: 62.05 samples/sec#011loss=2.487195\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:30 INFO 139780359198336] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526157.2753212, \"EndTime\": 1617526170.8131225, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13537.318706512451, \"count\": 1, \"min\": 13537.318706512451, \"max\": 13537.318706512451}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:30 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.759207329914744 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:30 INFO 139780359198336] #progress_metric: host=algo-1, completed 32.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:30 INFO 139780359198336] #quality_metric: host=algo-1, epoch=130, train loss <loss>=2.4787620067596436\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:30 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:35 INFO 139780359198336] Epoch[131] Batch[0] avg_epoch_loss=2.474433\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:35 INFO 139780359198336] #quality_metric: host=algo-1, epoch=131, batch=0 train loss <loss>=2.474432945251465\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:40 INFO 139780359198336] Epoch[131] Batch[5] avg_epoch_loss=2.488847\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:40 INFO 139780359198336] #quality_metric: host=algo-1, epoch=131, batch=5 train loss <loss>=2.488847295443217\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:40 INFO 139780359198336] Epoch[131] Batch [5]#011Speed: 61.11 samples/sec#011loss=2.488847\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:44 INFO 139780359198336] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526170.8132048, \"EndTime\": 1617526184.4556005, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13641.90649986267, \"count\": 1, \"min\": 13641.90649986267, \"max\": 13641.90649986267}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:44 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.40080085678254 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:44 INFO 139780359198336] #progress_metric: host=algo-1, completed 33.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:44 INFO 139780359198336] #quality_metric: host=algo-1, epoch=131, train loss <loss>=2.516227149963379\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:44 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:48 INFO 139780359198336] Epoch[132] Batch[0] avg_epoch_loss=2.562251\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:48 INFO 139780359198336] #quality_metric: host=algo-1, epoch=132, batch=0 train loss <loss>=2.562251091003418\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:53 INFO 139780359198336] Epoch[132] Batch[5] avg_epoch_loss=2.466453\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:53 INFO 139780359198336] #quality_metric: host=algo-1, epoch=132, batch=5 train loss <loss>=2.4664529959360757\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:53 INFO 139780359198336] Epoch[132] Batch [5]#011Speed: 62.91 samples/sec#011loss=2.466453\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:57 INFO 139780359198336] processed a total of 593 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526184.455667, \"EndTime\": 1617526197.890854, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13434.814453125, \"count\": 1, \"min\": 13434.814453125, \"max\": 13434.814453125}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:57 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.138650554476186 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:57 INFO 139780359198336] #progress_metric: host=algo-1, completed 33.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:57 INFO 139780359198336] #quality_metric: host=algo-1, epoch=132, train loss <loss>=2.5455724477767943\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:49:57 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:02 INFO 139780359198336] Epoch[133] Batch[0] avg_epoch_loss=2.558002\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:02 INFO 139780359198336] #quality_metric: host=algo-1, epoch=133, batch=0 train loss <loss>=2.5580015182495117\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:07 INFO 139780359198336] Epoch[133] Batch[5] avg_epoch_loss=2.535990\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:07 INFO 139780359198336] #quality_metric: host=algo-1, epoch=133, batch=5 train loss <loss>=2.5359904766082764\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:07 INFO 139780359198336] Epoch[133] Batch [5]#011Speed: 55.42 samples/sec#011loss=2.535990\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:13 INFO 139780359198336] Epoch[133] Batch[10] avg_epoch_loss=2.608618\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:13 INFO 139780359198336] #quality_metric: host=algo-1, epoch=133, batch=10 train loss <loss>=2.695769929885864\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:13 INFO 139780359198336] Epoch[133] Batch [10]#011Speed: 59.60 samples/sec#011loss=2.695770\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:13 INFO 139780359198336] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526197.8909245, \"EndTime\": 1617526213.3043218, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 15412.88447380066, \"count\": 1, \"min\": 15412.88447380066, \"max\": 15412.88447380066}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:13 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=42.43176110904905 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:13 INFO 139780359198336] #progress_metric: host=algo-1, completed 33.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:13 INFO 139780359198336] #quality_metric: host=algo-1, epoch=133, train loss <loss>=2.608617500825362\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:13 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:17 INFO 139780359198336] Epoch[134] Batch[0] avg_epoch_loss=2.688631\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:17 INFO 139780359198336] #quality_metric: host=algo-1, epoch=134, batch=0 train loss <loss>=2.688631057739258\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 08:50:22 INFO 139780359198336] Epoch[134] Batch[5] avg_epoch_loss=2.552199\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:22 INFO 139780359198336] #quality_metric: host=algo-1, epoch=134, batch=5 train loss <loss>=2.552199125289917\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:22 INFO 139780359198336] Epoch[134] Batch [5]#011Speed: 62.22 samples/sec#011loss=2.552199\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:27 INFO 139780359198336] Epoch[134] Batch[10] avg_epoch_loss=2.553253\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:27 INFO 139780359198336] #quality_metric: host=algo-1, epoch=134, batch=10 train loss <loss>=2.554517984390259\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:27 INFO 139780359198336] Epoch[134] Batch [10]#011Speed: 60.50 samples/sec#011loss=2.554518\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:27 INFO 139780359198336] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526213.30439, \"EndTime\": 1617526227.9505498, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14645.715236663818, \"count\": 1, \"min\": 14645.715236663818, \"max\": 14645.715236663818}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:27 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.79092848490713 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:27 INFO 139780359198336] #progress_metric: host=algo-1, completed 33.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:27 INFO 139780359198336] #quality_metric: host=algo-1, epoch=134, train loss <loss>=2.5532531521537085\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:27 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:32 INFO 139780359198336] Epoch[135] Batch[0] avg_epoch_loss=2.463813\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:32 INFO 139780359198336] #quality_metric: host=algo-1, epoch=135, batch=0 train loss <loss>=2.4638125896453857\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:37 INFO 139780359198336] Epoch[135] Batch[5] avg_epoch_loss=2.496068\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:37 INFO 139780359198336] #quality_metric: host=algo-1, epoch=135, batch=5 train loss <loss>=2.496068318684896\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:37 INFO 139780359198336] Epoch[135] Batch [5]#011Speed: 60.32 samples/sec#011loss=2.496068\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:42 INFO 139780359198336] Epoch[135] Batch[10] avg_epoch_loss=2.462734\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:42 INFO 139780359198336] #quality_metric: host=algo-1, epoch=135, batch=10 train loss <loss>=2.422731876373291\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:42 INFO 139780359198336] Epoch[135] Batch [10]#011Speed: 59.35 samples/sec#011loss=2.422732\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:42 INFO 139780359198336] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526227.9506245, \"EndTime\": 1617526242.8478675, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14896.703958511353, \"count\": 1, \"min\": 14896.703958511353, \"max\": 14896.703958511353}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:42 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.49923868981924 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:42 INFO 139780359198336] #progress_metric: host=algo-1, completed 34.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:42 INFO 139780359198336] #quality_metric: host=algo-1, epoch=135, train loss <loss>=2.462733572179621\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:42 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:47 INFO 139780359198336] Epoch[136] Batch[0] avg_epoch_loss=2.629444\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:47 INFO 139780359198336] #quality_metric: host=algo-1, epoch=136, batch=0 train loss <loss>=2.6294443607330322\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:52 INFO 139780359198336] Epoch[136] Batch[5] avg_epoch_loss=2.540277\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:52 INFO 139780359198336] #quality_metric: host=algo-1, epoch=136, batch=5 train loss <loss>=2.5402767260869346\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:52 INFO 139780359198336] Epoch[136] Batch [5]#011Speed: 62.59 samples/sec#011loss=2.540277\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:56 INFO 139780359198336] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526242.847939, \"EndTime\": 1617526256.3152196, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13466.811895370483, \"count\": 1, \"min\": 13466.811895370483, \"max\": 13466.811895370483}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:56 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.89019529889973 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:56 INFO 139780359198336] #progress_metric: host=algo-1, completed 34.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:56 INFO 139780359198336] #quality_metric: host=algo-1, epoch=136, train loss <loss>=2.5484039545059205\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:50:56 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:00 INFO 139780359198336] Epoch[137] Batch[0] avg_epoch_loss=2.454458\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:00 INFO 139780359198336] #quality_metric: host=algo-1, epoch=137, batch=0 train loss <loss>=2.454458236694336\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:06 INFO 139780359198336] Epoch[137] Batch[5] avg_epoch_loss=2.507909\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:06 INFO 139780359198336] #quality_metric: host=algo-1, epoch=137, batch=5 train loss <loss>=2.5079090197881064\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:06 INFO 139780359198336] Epoch[137] Batch [5]#011Speed: 56.20 samples/sec#011loss=2.507909\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:11 INFO 139780359198336] Epoch[137] Batch[10] avg_epoch_loss=2.495992\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:11 INFO 139780359198336] #quality_metric: host=algo-1, epoch=137, batch=10 train loss <loss>=2.481691074371338\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:11 INFO 139780359198336] Epoch[137] Batch [10]#011Speed: 54.85 samples/sec#011loss=2.481691\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:11 INFO 139780359198336] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526256.3152983, \"EndTime\": 1617526271.9587517, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 15642.967700958252, \"count\": 1, \"min\": 15642.967700958252, \"max\": 15642.967700958252}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:11 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=42.51080212726833 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:11 INFO 139780359198336] #progress_metric: host=algo-1, completed 34.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:11 INFO 139780359198336] #quality_metric: host=algo-1, epoch=137, train loss <loss>=2.4959917718713935\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:11 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:15 INFO 139780359198336] Epoch[138] Batch[0] avg_epoch_loss=2.505319\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:15 INFO 139780359198336] #quality_metric: host=algo-1, epoch=138, batch=0 train loss <loss>=2.505319356918335\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:21 INFO 139780359198336] Epoch[138] Batch[5] avg_epoch_loss=2.516071\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:21 INFO 139780359198336] #quality_metric: host=algo-1, epoch=138, batch=5 train loss <loss>=2.5160706440607705\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:21 INFO 139780359198336] Epoch[138] Batch [5]#011Speed: 62.28 samples/sec#011loss=2.516071\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:26 INFO 139780359198336] Epoch[138] Batch[10] avg_epoch_loss=2.539086\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:26 INFO 139780359198336] #quality_metric: host=algo-1, epoch=138, batch=10 train loss <loss>=2.5667052268981934\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:26 INFO 139780359198336] Epoch[138] Batch [10]#011Speed: 58.97 samples/sec#011loss=2.566705\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:26 INFO 139780359198336] processed a total of 677 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526271.9588292, \"EndTime\": 1617526286.5628295, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14603.478908538818, \"count\": 1, \"min\": 14603.478908538818, \"max\": 14603.478908538818}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:26 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.358513827260346 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:26 INFO 139780359198336] #progress_metric: host=algo-1, completed 34.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:26 INFO 139780359198336] #quality_metric: host=algo-1, epoch=138, train loss <loss>=2.5390863635323266\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:26 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:30 INFO 139780359198336] Epoch[139] Batch[0] avg_epoch_loss=2.461163\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:30 INFO 139780359198336] #quality_metric: host=algo-1, epoch=139, batch=0 train loss <loss>=2.46116304397583\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 08:51:35 INFO 139780359198336] Epoch[139] Batch[5] avg_epoch_loss=2.487516\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:35 INFO 139780359198336] #quality_metric: host=algo-1, epoch=139, batch=5 train loss <loss>=2.487516164779663\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:35 INFO 139780359198336] Epoch[139] Batch [5]#011Speed: 62.41 samples/sec#011loss=2.487516\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:40 INFO 139780359198336] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526286.562895, \"EndTime\": 1617526300.0435069, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13480.240106582642, \"count\": 1, \"min\": 13480.240106582642, \"max\": 13480.240106582642}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:40 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.844544242866725 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:40 INFO 139780359198336] #progress_metric: host=algo-1, completed 35.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:40 INFO 139780359198336] #quality_metric: host=algo-1, epoch=139, train loss <loss>=2.5103676319122314\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:40 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:44 INFO 139780359198336] Epoch[140] Batch[0] avg_epoch_loss=2.572047\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:44 INFO 139780359198336] #quality_metric: host=algo-1, epoch=140, batch=0 train loss <loss>=2.5720467567443848\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:49 INFO 139780359198336] Epoch[140] Batch[5] avg_epoch_loss=2.523150\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:49 INFO 139780359198336] #quality_metric: host=algo-1, epoch=140, batch=5 train loss <loss>=2.523150404294332\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:49 INFO 139780359198336] Epoch[140] Batch [5]#011Speed: 62.19 samples/sec#011loss=2.523150\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:54 INFO 139780359198336] Epoch[140] Batch[10] avg_epoch_loss=2.468866\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:54 INFO 139780359198336] #quality_metric: host=algo-1, epoch=140, batch=10 train loss <loss>=2.403725004196167\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:54 INFO 139780359198336] Epoch[140] Batch [10]#011Speed: 59.28 samples/sec#011loss=2.403725\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:54 INFO 139780359198336] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526300.043574, \"EndTime\": 1617526314.7615206, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14717.45228767395, \"count\": 1, \"min\": 14717.45228767395, \"max\": 14717.45228767395}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:54 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.09701759794646 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:54 INFO 139780359198336] #progress_metric: host=algo-1, completed 35.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:54 INFO 139780359198336] #quality_metric: host=algo-1, epoch=140, train loss <loss>=2.468866131522439\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:54 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:59 INFO 139780359198336] Epoch[141] Batch[0] avg_epoch_loss=2.377019\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:51:59 INFO 139780359198336] #quality_metric: host=algo-1, epoch=141, batch=0 train loss <loss>=2.377019166946411\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:04 INFO 139780359198336] Epoch[141] Batch[5] avg_epoch_loss=2.497355\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:04 INFO 139780359198336] #quality_metric: host=algo-1, epoch=141, batch=5 train loss <loss>=2.497354507446289\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:04 INFO 139780359198336] Epoch[141] Batch [5]#011Speed: 60.38 samples/sec#011loss=2.497355\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:09 INFO 139780359198336] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526314.761584, \"EndTime\": 1617526329.0771945, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14315.294981002808, \"count\": 1, \"min\": 14315.294981002808, \"max\": 14315.294981002808}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:09 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.35777677686887 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:09 INFO 139780359198336] #progress_metric: host=algo-1, completed 35.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:09 INFO 139780359198336] #quality_metric: host=algo-1, epoch=141, train loss <loss>=2.4832869291305544\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:09 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:13 INFO 139780359198336] Epoch[142] Batch[0] avg_epoch_loss=2.559630\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:13 INFO 139780359198336] #quality_metric: host=algo-1, epoch=142, batch=0 train loss <loss>=2.5596303939819336\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:18 INFO 139780359198336] Epoch[142] Batch[5] avg_epoch_loss=2.604872\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:18 INFO 139780359198336] #quality_metric: host=algo-1, epoch=142, batch=5 train loss <loss>=2.604872147242228\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:18 INFO 139780359198336] Epoch[142] Batch [5]#011Speed: 62.95 samples/sec#011loss=2.604872\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:22 INFO 139780359198336] processed a total of 613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526329.0772777, \"EndTime\": 1617526342.751016, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13673.256397247314, \"count\": 1, \"min\": 13673.256397247314, \"max\": 13673.256397247314}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:22 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.83156399680177 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:22 INFO 139780359198336] #progress_metric: host=algo-1, completed 35.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:22 INFO 139780359198336] #quality_metric: host=algo-1, epoch=142, train loss <loss>=2.5709328174591066\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:22 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:26 INFO 139780359198336] Epoch[143] Batch[0] avg_epoch_loss=2.586792\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:26 INFO 139780359198336] #quality_metric: host=algo-1, epoch=143, batch=0 train loss <loss>=2.586791515350342\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:31 INFO 139780359198336] Epoch[143] Batch[5] avg_epoch_loss=2.523195\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:31 INFO 139780359198336] #quality_metric: host=algo-1, epoch=143, batch=5 train loss <loss>=2.523195226987203\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:31 INFO 139780359198336] Epoch[143] Batch [5]#011Speed: 63.17 samples/sec#011loss=2.523195\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:37 INFO 139780359198336] Epoch[143] Batch[10] avg_epoch_loss=2.509602\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:37 INFO 139780359198336] #quality_metric: host=algo-1, epoch=143, batch=10 train loss <loss>=2.4932908058166503\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:37 INFO 139780359198336] Epoch[143] Batch [10]#011Speed: 60.56 samples/sec#011loss=2.493291\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:37 INFO 139780359198336] processed a total of 678 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526342.7511237, \"EndTime\": 1617526357.2419739, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14490.484952926636, \"count\": 1, \"min\": 14490.484952926636, \"max\": 14490.484952926636}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:37 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.78900252537447 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:37 INFO 139780359198336] #progress_metric: host=algo-1, completed 36.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:37 INFO 139780359198336] #quality_metric: host=algo-1, epoch=143, train loss <loss>=2.5096023082733154\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:37 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:41 INFO 139780359198336] Epoch[144] Batch[0] avg_epoch_loss=2.471653\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:41 INFO 139780359198336] #quality_metric: host=algo-1, epoch=144, batch=0 train loss <loss>=2.471653461456299\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:46 INFO 139780359198336] Epoch[144] Batch[5] avg_epoch_loss=2.546506\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:46 INFO 139780359198336] #quality_metric: host=algo-1, epoch=144, batch=5 train loss <loss>=2.5465057690938315\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:46 INFO 139780359198336] Epoch[144] Batch [5]#011Speed: 62.11 samples/sec#011loss=2.546506\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:51 INFO 139780359198336] Epoch[144] Batch[10] avg_epoch_loss=2.544713\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:51 INFO 139780359198336] #quality_metric: host=algo-1, epoch=144, batch=10 train loss <loss>=2.5425609588623046\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:51 INFO 139780359198336] Epoch[144] Batch [10]#011Speed: 59.49 samples/sec#011loss=2.542561\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:51 INFO 139780359198336] processed a total of 687 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526357.242041, \"EndTime\": 1617526371.7355883, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14493.076086044312, \"count\": 1, \"min\": 14493.076086044312, \"max\": 14493.076086044312}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:51 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=47.40157023538265 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:51 INFO 139780359198336] #progress_metric: host=algo-1, completed 36.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:51 INFO 139780359198336] #quality_metric: host=algo-1, epoch=144, train loss <loss>=2.5447126735340464\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:51 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:55 INFO 139780359198336] Epoch[145] Batch[0] avg_epoch_loss=2.421810\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:52:55 INFO 139780359198336] #quality_metric: host=algo-1, epoch=145, batch=0 train loss <loss>=2.4218099117279053\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 08:53:00 INFO 139780359198336] Epoch[145] Batch[5] avg_epoch_loss=2.480693\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:00 INFO 139780359198336] #quality_metric: host=algo-1, epoch=145, batch=5 train loss <loss>=2.480693260828654\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:00 INFO 139780359198336] Epoch[145] Batch [5]#011Speed: 63.51 samples/sec#011loss=2.480693\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:05 INFO 139780359198336] processed a total of 604 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526371.7356682, \"EndTime\": 1617526385.346531, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13610.45789718628, \"count\": 1, \"min\": 13610.45789718628, \"max\": 13610.45789718628}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:05 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.37725903012965 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:05 INFO 139780359198336] #progress_metric: host=algo-1, completed 36.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:05 INFO 139780359198336] #quality_metric: host=algo-1, epoch=145, train loss <loss>=2.5030354022979737\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:05 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:09 INFO 139780359198336] Epoch[146] Batch[0] avg_epoch_loss=2.408335\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:09 INFO 139780359198336] #quality_metric: host=algo-1, epoch=146, batch=0 train loss <loss>=2.4083352088928223\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:15 INFO 139780359198336] Epoch[146] Batch[5] avg_epoch_loss=2.502220\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:15 INFO 139780359198336] #quality_metric: host=algo-1, epoch=146, batch=5 train loss <loss>=2.502219875653585\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:15 INFO 139780359198336] Epoch[146] Batch [5]#011Speed: 61.62 samples/sec#011loss=2.502220\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:19 INFO 139780359198336] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526385.3466165, \"EndTime\": 1617526399.1558928, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13808.590650558472, \"count\": 1, \"min\": 13808.590650558472, \"max\": 13808.590650558472}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:19 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.62326925764407 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:19 INFO 139780359198336] #progress_metric: host=algo-1, completed 36.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:19 INFO 139780359198336] #quality_metric: host=algo-1, epoch=146, train loss <loss>=2.498506951332092\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:19 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:23 INFO 139780359198336] Epoch[147] Batch[0] avg_epoch_loss=2.510305\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:23 INFO 139780359198336] #quality_metric: host=algo-1, epoch=147, batch=0 train loss <loss>=2.5103046894073486\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:28 INFO 139780359198336] Epoch[147] Batch[5] avg_epoch_loss=2.485845\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:28 INFO 139780359198336] #quality_metric: host=algo-1, epoch=147, batch=5 train loss <loss>=2.485844612121582\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:28 INFO 139780359198336] Epoch[147] Batch [5]#011Speed: 61.22 samples/sec#011loss=2.485845\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:33 INFO 139780359198336] Epoch[147] Batch[10] avg_epoch_loss=2.489430\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:33 INFO 139780359198336] #quality_metric: host=algo-1, epoch=147, batch=10 train loss <loss>=2.4937321186065673\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:33 INFO 139780359198336] Epoch[147] Batch [10]#011Speed: 59.63 samples/sec#011loss=2.493732\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:33 INFO 139780359198336] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526399.156012, \"EndTime\": 1617526413.8503242, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14693.827867507935, \"count\": 1, \"min\": 14693.827867507935, \"max\": 14693.827867507935}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:33 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.12069231897787 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:33 INFO 139780359198336] #progress_metric: host=algo-1, completed 37.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:33 INFO 139780359198336] #quality_metric: host=algo-1, epoch=147, train loss <loss>=2.48942984234203\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:33 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:38 INFO 139780359198336] Epoch[148] Batch[0] avg_epoch_loss=2.389767\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:38 INFO 139780359198336] #quality_metric: host=algo-1, epoch=148, batch=0 train loss <loss>=2.3897674083709717\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:43 INFO 139780359198336] Epoch[148] Batch[5] avg_epoch_loss=2.460696\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:43 INFO 139780359198336] #quality_metric: host=algo-1, epoch=148, batch=5 train loss <loss>=2.4606958627700806\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:43 INFO 139780359198336] Epoch[148] Batch [5]#011Speed: 61.66 samples/sec#011loss=2.460696\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:47 INFO 139780359198336] processed a total of 604 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526413.850389, \"EndTime\": 1617526427.4742692, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13623.514175415039, \"count\": 1, \"min\": 13623.514175415039, \"max\": 13623.514175415039}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:47 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.33473062704228 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:47 INFO 139780359198336] #progress_metric: host=algo-1, completed 37.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:47 INFO 139780359198336] #quality_metric: host=algo-1, epoch=148, train loss <loss>=2.4269371747970583\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:47 INFO 139780359198336] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:47 INFO 139780359198336] Saved checkpoint to \"/opt/ml/model/state_d8b2422a-b25d-4b19-9cb1-c83435f22a06-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526427.4743483, \"EndTime\": 1617526427.679587, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 204.82921600341797, \"count\": 1, \"min\": 204.82921600341797, \"max\": 204.82921600341797}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:51 INFO 139780359198336] Epoch[149] Batch[0] avg_epoch_loss=2.454755\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:51 INFO 139780359198336] #quality_metric: host=algo-1, epoch=149, batch=0 train loss <loss>=2.454754590988159\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:57 INFO 139780359198336] Epoch[149] Batch[5] avg_epoch_loss=2.478849\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:57 INFO 139780359198336] #quality_metric: host=algo-1, epoch=149, batch=5 train loss <loss>=2.4788487752278647\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:53:57 INFO 139780359198336] Epoch[149] Batch [5]#011Speed: 62.05 samples/sec#011loss=2.478849\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:01 INFO 139780359198336] processed a total of 610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526427.6796584, \"EndTime\": 1617526441.2074916, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13527.77099609375, \"count\": 1, \"min\": 13527.77099609375, \"max\": 13527.77099609375}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:01 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.09209367127082 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:01 INFO 139780359198336] #progress_metric: host=algo-1, completed 37.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:01 INFO 139780359198336] #quality_metric: host=algo-1, epoch=149, train loss <loss>=2.517773246765137\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:01 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:05 INFO 139780359198336] Epoch[150] Batch[0] avg_epoch_loss=2.530469\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:05 INFO 139780359198336] #quality_metric: host=algo-1, epoch=150, batch=0 train loss <loss>=2.5304691791534424\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:11 INFO 139780359198336] Epoch[150] Batch[5] avg_epoch_loss=2.544501\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:11 INFO 139780359198336] #quality_metric: host=algo-1, epoch=150, batch=5 train loss <loss>=2.544501225153605\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:11 INFO 139780359198336] Epoch[150] Batch [5]#011Speed: 57.84 samples/sec#011loss=2.544501\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 08:54:15 INFO 139780359198336] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526441.2075613, \"EndTime\": 1617526455.5839162, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14375.876665115356, \"count\": 1, \"min\": 14375.876665115356, \"max\": 14375.876665115356}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:15 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.26659361857249 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:15 INFO 139780359198336] #progress_metric: host=algo-1, completed 37.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:15 INFO 139780359198336] #quality_metric: host=algo-1, epoch=150, train loss <loss>=2.528977966308594\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:15 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:19 INFO 139780359198336] Epoch[151] Batch[0] avg_epoch_loss=2.574970\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:19 INFO 139780359198336] #quality_metric: host=algo-1, epoch=151, batch=0 train loss <loss>=2.574970245361328\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:24 INFO 139780359198336] Epoch[151] Batch[5] avg_epoch_loss=2.517915\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:24 INFO 139780359198336] #quality_metric: host=algo-1, epoch=151, batch=5 train loss <loss>=2.5179149309794107\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:24 INFO 139780359198336] Epoch[151] Batch [5]#011Speed: 62.35 samples/sec#011loss=2.517915\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:30 INFO 139780359198336] Epoch[151] Batch[10] avg_epoch_loss=2.514464\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:30 INFO 139780359198336] #quality_metric: host=algo-1, epoch=151, batch=10 train loss <loss>=2.510322427749634\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:30 INFO 139780359198336] Epoch[151] Batch [10]#011Speed: 59.00 samples/sec#011loss=2.510322\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:30 INFO 139780359198336] processed a total of 681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526455.5839942, \"EndTime\": 1617526470.1949544, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14610.56637763977, \"count\": 1, \"min\": 14610.56637763977, \"max\": 14610.56637763977}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:30 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.609783295883524 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:30 INFO 139780359198336] #progress_metric: host=algo-1, completed 38.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:30 INFO 139780359198336] #quality_metric: host=algo-1, epoch=151, train loss <loss>=2.514463793147694\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:30 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:34 INFO 139780359198336] Epoch[152] Batch[0] avg_epoch_loss=2.392659\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:34 INFO 139780359198336] #quality_metric: host=algo-1, epoch=152, batch=0 train loss <loss>=2.3926591873168945\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:39 INFO 139780359198336] Epoch[152] Batch[5] avg_epoch_loss=2.475753\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:39 INFO 139780359198336] #quality_metric: host=algo-1, epoch=152, batch=5 train loss <loss>=2.475753386815389\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:39 INFO 139780359198336] Epoch[152] Batch [5]#011Speed: 62.87 samples/sec#011loss=2.475753\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:44 INFO 139780359198336] Epoch[152] Batch[10] avg_epoch_loss=2.496992\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:44 INFO 139780359198336] #quality_metric: host=algo-1, epoch=152, batch=10 train loss <loss>=2.5224790573120117\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:44 INFO 139780359198336] Epoch[152] Batch [10]#011Speed: 58.79 samples/sec#011loss=2.522479\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:44 INFO 139780359198336] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526470.1950238, \"EndTime\": 1617526484.8112273, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14615.748643875122, \"count\": 1, \"min\": 14615.748643875122, \"max\": 14615.748643875122}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:44 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.15639359928529 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:44 INFO 139780359198336] #progress_metric: host=algo-1, completed 38.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:44 INFO 139780359198336] #quality_metric: host=algo-1, epoch=152, train loss <loss>=2.4969923279502173\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:44 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:48 INFO 139780359198336] Epoch[153] Batch[0] avg_epoch_loss=2.650761\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:48 INFO 139780359198336] #quality_metric: host=algo-1, epoch=153, batch=0 train loss <loss>=2.6507608890533447\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:54 INFO 139780359198336] Epoch[153] Batch[5] avg_epoch_loss=2.501770\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:54 INFO 139780359198336] #quality_metric: host=algo-1, epoch=153, batch=5 train loss <loss>=2.5017704566319785\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:54 INFO 139780359198336] Epoch[153] Batch [5]#011Speed: 62.42 samples/sec#011loss=2.501770\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:59 INFO 139780359198336] Epoch[153] Batch[10] avg_epoch_loss=2.504833\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:59 INFO 139780359198336] #quality_metric: host=algo-1, epoch=153, batch=10 train loss <loss>=2.508507585525513\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:59 INFO 139780359198336] Epoch[153] Batch [10]#011Speed: 59.77 samples/sec#011loss=2.508508\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:59 INFO 139780359198336] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526484.8113122, \"EndTime\": 1617526499.4335155, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14621.684074401855, \"count\": 1, \"min\": 14621.684074401855, \"max\": 14621.684074401855}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:59 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.248778897172535 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:59 INFO 139780359198336] #progress_metric: host=algo-1, completed 38.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:59 INFO 139780359198336] #quality_metric: host=algo-1, epoch=153, train loss <loss>=2.504832787947221\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:54:59 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:03 INFO 139780359198336] Epoch[154] Batch[0] avg_epoch_loss=2.490833\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:03 INFO 139780359198336] #quality_metric: host=algo-1, epoch=154, batch=0 train loss <loss>=2.490833044052124\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:09 INFO 139780359198336] Epoch[154] Batch[5] avg_epoch_loss=2.544783\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:09 INFO 139780359198336] #quality_metric: host=algo-1, epoch=154, batch=5 train loss <loss>=2.5447829167048135\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:09 INFO 139780359198336] Epoch[154] Batch [5]#011Speed: 55.24 samples/sec#011loss=2.544783\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:13 INFO 139780359198336] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526499.433664, \"EndTime\": 1617526513.5905175, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14156.320571899414, \"count\": 1, \"min\": 14156.320571899414, \"max\": 14156.320571899414}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:13 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.714699359204175 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:13 INFO 139780359198336] #progress_metric: host=algo-1, completed 38.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:13 INFO 139780359198336] #quality_metric: host=algo-1, epoch=154, train loss <loss>=2.53601496219635\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:13 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:17 INFO 139780359198336] Epoch[155] Batch[0] avg_epoch_loss=2.431453\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:17 INFO 139780359198336] #quality_metric: host=algo-1, epoch=155, batch=0 train loss <loss>=2.431453227996826\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:22 INFO 139780359198336] Epoch[155] Batch[5] avg_epoch_loss=2.497353\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:22 INFO 139780359198336] #quality_metric: host=algo-1, epoch=155, batch=5 train loss <loss>=2.497353434562683\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:22 INFO 139780359198336] Epoch[155] Batch [5]#011Speed: 62.66 samples/sec#011loss=2.497353\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:28 INFO 139780359198336] Epoch[155] Batch[10] avg_epoch_loss=2.519288\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:28 INFO 139780359198336] #quality_metric: host=algo-1, epoch=155, batch=10 train loss <loss>=2.545609188079834\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:28 INFO 139780359198336] Epoch[155] Batch [10]#011Speed: 60.82 samples/sec#011loss=2.545609\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:28 INFO 139780359198336] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526513.5905848, \"EndTime\": 1617526528.2513754, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14660.439491271973, \"count\": 1, \"min\": 14660.439491271973, \"max\": 14660.439491271973}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:28 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.92740814086242 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:28 INFO 139780359198336] #progress_metric: host=algo-1, completed 39.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:28 INFO 139780359198336] #quality_metric: host=algo-1, epoch=155, train loss <loss>=2.51928786797957\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:28 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:32 INFO 139780359198336] Epoch[156] Batch[0] avg_epoch_loss=2.446362\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:32 INFO 139780359198336] #quality_metric: host=algo-1, epoch=156, batch=0 train loss <loss>=2.446361780166626\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 08:55:37 INFO 139780359198336] Epoch[156] Batch[5] avg_epoch_loss=2.456902\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:37 INFO 139780359198336] #quality_metric: host=algo-1, epoch=156, batch=5 train loss <loss>=2.456901947657267\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:37 INFO 139780359198336] Epoch[156] Batch [5]#011Speed: 63.10 samples/sec#011loss=2.456902\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:41 INFO 139780359198336] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526528.2514527, \"EndTime\": 1617526541.7255967, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13473.653078079224, \"count\": 1, \"min\": 13473.653078079224, \"max\": 13473.653078079224}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:41 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.86687630769433 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:41 INFO 139780359198336] #progress_metric: host=algo-1, completed 39.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:41 INFO 139780359198336] #quality_metric: host=algo-1, epoch=156, train loss <loss>=2.4931355476379395\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:41 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:46 INFO 139780359198336] Epoch[157] Batch[0] avg_epoch_loss=2.547861\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:46 INFO 139780359198336] #quality_metric: host=algo-1, epoch=157, batch=0 train loss <loss>=2.547861099243164\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:51 INFO 139780359198336] Epoch[157] Batch[5] avg_epoch_loss=2.487636\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:51 INFO 139780359198336] #quality_metric: host=algo-1, epoch=157, batch=5 train loss <loss>=2.4876363277435303\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:51 INFO 139780359198336] Epoch[157] Batch [5]#011Speed: 61.45 samples/sec#011loss=2.487636\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:55 INFO 139780359198336] processed a total of 603 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526541.7256792, \"EndTime\": 1617526555.3708556, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13644.624471664429, \"count\": 1, \"min\": 13644.624471664429, \"max\": 13644.624471664429}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:55 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.192563892827685 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:55 INFO 139780359198336] #progress_metric: host=algo-1, completed 39.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:55 INFO 139780359198336] #quality_metric: host=algo-1, epoch=157, train loss <loss>=2.4551438808441164\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:55 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:59 INFO 139780359198336] Epoch[158] Batch[0] avg_epoch_loss=2.581537\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:55:59 INFO 139780359198336] #quality_metric: host=algo-1, epoch=158, batch=0 train loss <loss>=2.5815367698669434\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:04 INFO 139780359198336] Epoch[158] Batch[5] avg_epoch_loss=2.534667\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:04 INFO 139780359198336] #quality_metric: host=algo-1, epoch=158, batch=5 train loss <loss>=2.534667491912842\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:04 INFO 139780359198336] Epoch[158] Batch [5]#011Speed: 59.71 samples/sec#011loss=2.534667\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:10 INFO 139780359198336] Epoch[158] Batch[10] avg_epoch_loss=2.498634\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:10 INFO 139780359198336] #quality_metric: host=algo-1, epoch=158, batch=10 train loss <loss>=2.455393934249878\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:10 INFO 139780359198336] Epoch[158] Batch [10]#011Speed: 54.49 samples/sec#011loss=2.455394\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:10 INFO 139780359198336] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526555.3710043, \"EndTime\": 1617526570.7284124, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 15356.923580169678, \"count\": 1, \"min\": 15356.923580169678, \"max\": 15356.923580169678}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:10 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.237531986447564 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:10 INFO 139780359198336] #progress_metric: host=algo-1, completed 39.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:10 INFO 139780359198336] #quality_metric: host=algo-1, epoch=158, train loss <loss>=2.4986340566114946\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:10 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:14 INFO 139780359198336] Epoch[159] Batch[0] avg_epoch_loss=2.502948\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:14 INFO 139780359198336] #quality_metric: host=algo-1, epoch=159, batch=0 train loss <loss>=2.502948045730591\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:19 INFO 139780359198336] Epoch[159] Batch[5] avg_epoch_loss=2.504737\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:19 INFO 139780359198336] #quality_metric: host=algo-1, epoch=159, batch=5 train loss <loss>=2.50473682085673\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:19 INFO 139780359198336] Epoch[159] Batch [5]#011Speed: 61.14 samples/sec#011loss=2.504737\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:25 INFO 139780359198336] Epoch[159] Batch[10] avg_epoch_loss=2.489129\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:25 INFO 139780359198336] #quality_metric: host=algo-1, epoch=159, batch=10 train loss <loss>=2.4704001903533936\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:25 INFO 139780359198336] Epoch[159] Batch [10]#011Speed: 57.98 samples/sec#011loss=2.470400\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:25 INFO 139780359198336] processed a total of 693 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526570.7284846, \"EndTime\": 1617526585.4245641, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14695.730686187744, \"count\": 1, \"min\": 14695.730686187744, \"max\": 14695.730686187744}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:25 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=47.15617639484342 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:25 INFO 139780359198336] #progress_metric: host=algo-1, completed 40.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:25 INFO 139780359198336] #quality_metric: host=algo-1, epoch=159, train loss <loss>=2.4891292615370317\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:25 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:29 INFO 139780359198336] Epoch[160] Batch[0] avg_epoch_loss=2.566148\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:29 INFO 139780359198336] #quality_metric: host=algo-1, epoch=160, batch=0 train loss <loss>=2.566147804260254\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:34 INFO 139780359198336] Epoch[160] Batch[5] avg_epoch_loss=2.461687\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:34 INFO 139780359198336] #quality_metric: host=algo-1, epoch=160, batch=5 train loss <loss>=2.4616869688034058\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:34 INFO 139780359198336] Epoch[160] Batch [5]#011Speed: 62.71 samples/sec#011loss=2.461687\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:39 INFO 139780359198336] Epoch[160] Batch[10] avg_epoch_loss=2.485657\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:39 INFO 139780359198336] #quality_metric: host=algo-1, epoch=160, batch=10 train loss <loss>=2.514421558380127\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:39 INFO 139780359198336] Epoch[160] Batch [10]#011Speed: 59.29 samples/sec#011loss=2.514422\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:39 INFO 139780359198336] processed a total of 689 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526585.4246492, \"EndTime\": 1617526599.9671595, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14542.033672332764, \"count\": 1, \"min\": 14542.033672332764, \"max\": 14542.033672332764}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:39 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=47.37953882343436 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:39 INFO 139780359198336] #progress_metric: host=algo-1, completed 40.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:39 INFO 139780359198336] #quality_metric: host=algo-1, epoch=160, train loss <loss>=2.4856572367928247\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:39 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:44 INFO 139780359198336] Epoch[161] Batch[0] avg_epoch_loss=2.403269\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:44 INFO 139780359198336] #quality_metric: host=algo-1, epoch=161, batch=0 train loss <loss>=2.403269052505493\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:49 INFO 139780359198336] Epoch[161] Batch[5] avg_epoch_loss=2.424891\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:49 INFO 139780359198336] #quality_metric: host=algo-1, epoch=161, batch=5 train loss <loss>=2.4248905976613364\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:49 INFO 139780359198336] Epoch[161] Batch [5]#011Speed: 61.05 samples/sec#011loss=2.424891\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:53 INFO 139780359198336] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526599.967232, \"EndTime\": 1617526613.5659156, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13598.18434715271, \"count\": 1, \"min\": 13598.18434715271, \"max\": 13598.18434715271}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:53 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.10874363614036 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:53 INFO 139780359198336] #progress_metric: host=algo-1, completed 40.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:53 INFO 139780359198336] #quality_metric: host=algo-1, epoch=161, train loss <loss>=2.426067423820496\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:53 INFO 139780359198336] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:53 INFO 139780359198336] Saved checkpoint to \"/opt/ml/model/state_7dc8fceb-82b6-4c6c-9b99-d1a3ace6b616-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526613.565988, \"EndTime\": 1617526613.752186, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 185.58549880981445, \"count\": 1, \"min\": 185.58549880981445, \"max\": 185.58549880981445}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:57 INFO 139780359198336] Epoch[162] Batch[0] avg_epoch_loss=2.412512\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:56:57 INFO 139780359198336] #quality_metric: host=algo-1, epoch=162, batch=0 train loss <loss>=2.4125118255615234\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 08:57:03 INFO 139780359198336] Epoch[162] Batch[5] avg_epoch_loss=2.469299\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:03 INFO 139780359198336] #quality_metric: host=algo-1, epoch=162, batch=5 train loss <loss>=2.469298521677653\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:03 INFO 139780359198336] Epoch[162] Batch [5]#011Speed: 60.90 samples/sec#011loss=2.469299\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:09 INFO 139780359198336] Epoch[162] Batch[10] avg_epoch_loss=2.471048\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:09 INFO 139780359198336] #quality_metric: host=algo-1, epoch=162, batch=10 train loss <loss>=2.4731472969055175\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:09 INFO 139780359198336] Epoch[162] Batch [10]#011Speed: 53.46 samples/sec#011loss=2.473147\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:09 INFO 139780359198336] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526613.7522557, \"EndTime\": 1617526629.1502898, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 15397.967338562012, \"count\": 1, \"min\": 15397.967338562012, \"max\": 15397.967338562012}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:09 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=42.927472808969085 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:09 INFO 139780359198336] #progress_metric: host=algo-1, completed 40.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:09 INFO 139780359198336] #quality_metric: host=algo-1, epoch=162, train loss <loss>=2.471047964963046\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:09 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:13 INFO 139780359198336] Epoch[163] Batch[0] avg_epoch_loss=2.508446\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:13 INFO 139780359198336] #quality_metric: host=algo-1, epoch=163, batch=0 train loss <loss>=2.508445978164673\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:18 INFO 139780359198336] Epoch[163] Batch[5] avg_epoch_loss=2.503577\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:18 INFO 139780359198336] #quality_metric: host=algo-1, epoch=163, batch=5 train loss <loss>=2.5035773118336997\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:18 INFO 139780359198336] Epoch[163] Batch [5]#011Speed: 61.71 samples/sec#011loss=2.503577\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:23 INFO 139780359198336] Epoch[163] Batch[10] avg_epoch_loss=2.517314\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:23 INFO 139780359198336] #quality_metric: host=algo-1, epoch=163, batch=10 train loss <loss>=2.5337977409362793\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:23 INFO 139780359198336] Epoch[163] Batch [10]#011Speed: 61.22 samples/sec#011loss=2.533798\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:23 INFO 139780359198336] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526629.1503532, \"EndTime\": 1617526643.7884154, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14637.709856033325, \"count\": 1, \"min\": 14637.709856033325, \"max\": 14637.709856033325}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:23 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.883737056718246 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:23 INFO 139780359198336] #progress_metric: host=algo-1, completed 41.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:23 INFO 139780359198336] #quality_metric: host=algo-1, epoch=163, train loss <loss>=2.5173138705166904\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:23 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:27 INFO 139780359198336] Epoch[164] Batch[0] avg_epoch_loss=2.612157\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:27 INFO 139780359198336] #quality_metric: host=algo-1, epoch=164, batch=0 train loss <loss>=2.612156629562378\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:33 INFO 139780359198336] Epoch[164] Batch[5] avg_epoch_loss=2.490850\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:33 INFO 139780359198336] #quality_metric: host=algo-1, epoch=164, batch=5 train loss <loss>=2.49085009098053\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:33 INFO 139780359198336] Epoch[164] Batch [5]#011Speed: 63.45 samples/sec#011loss=2.490850\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:38 INFO 139780359198336] Epoch[164] Batch[10] avg_epoch_loss=2.417329\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:38 INFO 139780359198336] #quality_metric: host=algo-1, epoch=164, batch=10 train loss <loss>=2.32910475730896\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:38 INFO 139780359198336] Epoch[164] Batch [10]#011Speed: 61.39 samples/sec#011loss=2.329105\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:38 INFO 139780359198336] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526643.7884886, \"EndTime\": 1617526658.2526631, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14463.552236557007, \"count\": 1, \"min\": 14463.552236557007, \"max\": 14463.552236557007}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:38 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.00926618343006 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:38 INFO 139780359198336] #progress_metric: host=algo-1, completed 41.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:38 INFO 139780359198336] #quality_metric: host=algo-1, epoch=164, train loss <loss>=2.4173294847661797\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:38 INFO 139780359198336] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:38 INFO 139780359198336] Saved checkpoint to \"/opt/ml/model/state_7ccc0ec6-a912-4115-9dbb-3583860574eb-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526658.2527301, \"EndTime\": 1617526658.4393744, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 186.15078926086426, \"count\": 1, \"min\": 186.15078926086426, \"max\": 186.15078926086426}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:42 INFO 139780359198336] Epoch[165] Batch[0] avg_epoch_loss=2.566984\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:42 INFO 139780359198336] #quality_metric: host=algo-1, epoch=165, batch=0 train loss <loss>=2.5669844150543213\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:47 INFO 139780359198336] Epoch[165] Batch[5] avg_epoch_loss=2.532288\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:47 INFO 139780359198336] #quality_metric: host=algo-1, epoch=165, batch=5 train loss <loss>=2.532288432121277\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:47 INFO 139780359198336] Epoch[165] Batch [5]#011Speed: 63.10 samples/sec#011loss=2.532288\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:51 INFO 139780359198336] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526658.4394383, \"EndTime\": 1617526671.88482, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13445.32060623169, \"count\": 1, \"min\": 13445.32060623169, \"max\": 13445.32060623169}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:51 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=47.59978591437068 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:51 INFO 139780359198336] #progress_metric: host=algo-1, completed 41.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:51 INFO 139780359198336] #quality_metric: host=algo-1, epoch=165, train loss <loss>=2.5322739839553834\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:51 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:56 INFO 139780359198336] Epoch[166] Batch[0] avg_epoch_loss=2.384550\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:57:56 INFO 139780359198336] #quality_metric: host=algo-1, epoch=166, batch=0 train loss <loss>=2.3845503330230713\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:01 INFO 139780359198336] Epoch[166] Batch[5] avg_epoch_loss=2.438472\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:01 INFO 139780359198336] #quality_metric: host=algo-1, epoch=166, batch=5 train loss <loss>=2.4384716351826987\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:01 INFO 139780359198336] Epoch[166] Batch [5]#011Speed: 63.04 samples/sec#011loss=2.438472\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:05 INFO 139780359198336] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526671.8849041, \"EndTime\": 1617526685.555259, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13669.995069503784, \"count\": 1, \"min\": 13669.995069503784, \"max\": 13669.995069503784}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:05 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.744318685522316 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:05 INFO 139780359198336] #progress_metric: host=algo-1, completed 41.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:05 INFO 139780359198336] #quality_metric: host=algo-1, epoch=166, train loss <loss>=2.4575244426727294\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:05 INFO 139780359198336] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 08:58:10 INFO 139780359198336] Epoch[167] Batch[0] avg_epoch_loss=2.461763\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:10 INFO 139780359198336] #quality_metric: host=algo-1, epoch=167, batch=0 train loss <loss>=2.4617626667022705\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:15 INFO 139780359198336] Epoch[167] Batch[5] avg_epoch_loss=2.505101\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:15 INFO 139780359198336] #quality_metric: host=algo-1, epoch=167, batch=5 train loss <loss>=2.5051005283991494\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:15 INFO 139780359198336] Epoch[167] Batch [5]#011Speed: 62.98 samples/sec#011loss=2.505101\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:19 INFO 139780359198336] processed a total of 598 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526685.5553424, \"EndTime\": 1617526699.451952, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13896.257638931274, \"count\": 1, \"min\": 13896.257638931274, \"max\": 13896.257638931274}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:19 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.03285570611297 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:19 INFO 139780359198336] #progress_metric: host=algo-1, completed 42.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:19 INFO 139780359198336] #quality_metric: host=algo-1, epoch=167, train loss <loss>=2.5020226001739503\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:19 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:23 INFO 139780359198336] Epoch[168] Batch[0] avg_epoch_loss=2.514517\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:23 INFO 139780359198336] #quality_metric: host=algo-1, epoch=168, batch=0 train loss <loss>=2.514516830444336\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:28 INFO 139780359198336] Epoch[168] Batch[5] avg_epoch_loss=2.548273\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:28 INFO 139780359198336] #quality_metric: host=algo-1, epoch=168, batch=5 train loss <loss>=2.5482730070749917\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:28 INFO 139780359198336] Epoch[168] Batch [5]#011Speed: 62.19 samples/sec#011loss=2.548273\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:32 INFO 139780359198336] processed a total of 603 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526699.4520245, \"EndTime\": 1617526712.965951, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13513.435363769531, \"count\": 1, \"min\": 13513.435363769531, \"max\": 13513.435363769531}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:32 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.621853399004976 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:32 INFO 139780359198336] #progress_metric: host=algo-1, completed 42.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:32 INFO 139780359198336] #quality_metric: host=algo-1, epoch=168, train loss <loss>=2.5745843172073366\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:32 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:37 INFO 139780359198336] Epoch[169] Batch[0] avg_epoch_loss=2.522190\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:37 INFO 139780359198336] #quality_metric: host=algo-1, epoch=169, batch=0 train loss <loss>=2.5221903324127197\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:42 INFO 139780359198336] Epoch[169] Batch[5] avg_epoch_loss=2.449764\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:42 INFO 139780359198336] #quality_metric: host=algo-1, epoch=169, batch=5 train loss <loss>=2.4497637351353965\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:42 INFO 139780359198336] Epoch[169] Batch [5]#011Speed: 62.93 samples/sec#011loss=2.449764\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:47 INFO 139780359198336] Epoch[169] Batch[10] avg_epoch_loss=2.477694\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:47 INFO 139780359198336] #quality_metric: host=algo-1, epoch=169, batch=10 train loss <loss>=2.51121129989624\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:47 INFO 139780359198336] Epoch[169] Batch [10]#011Speed: 60.19 samples/sec#011loss=2.511211\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:47 INFO 139780359198336] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526712.9660347, \"EndTime\": 1617526727.4876506, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14521.160364151001, \"count\": 1, \"min\": 14521.160364151001, \"max\": 14521.160364151001}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:47 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.93266144958291 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:47 INFO 139780359198336] #progress_metric: host=algo-1, completed 42.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:47 INFO 139780359198336] #quality_metric: host=algo-1, epoch=169, train loss <loss>=2.477694446390325\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:47 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:51 INFO 139780359198336] Epoch[170] Batch[0] avg_epoch_loss=2.442289\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:51 INFO 139780359198336] #quality_metric: host=algo-1, epoch=170, batch=0 train loss <loss>=2.442289352416992\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:56 INFO 139780359198336] Epoch[170] Batch[5] avg_epoch_loss=2.519079\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:56 INFO 139780359198336] #quality_metric: host=algo-1, epoch=170, batch=5 train loss <loss>=2.519078850746155\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:58:56 INFO 139780359198336] Epoch[170] Batch [5]#011Speed: 62.54 samples/sec#011loss=2.519079\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:00 INFO 139780359198336] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526727.4877176, \"EndTime\": 1617526740.9784484, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13490.357637405396, \"count\": 1, \"min\": 13490.357637405396, \"max\": 13490.357637405396}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:00 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=47.29265128592051 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:00 INFO 139780359198336] #progress_metric: host=algo-1, completed 42.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:00 INFO 139780359198336] #quality_metric: host=algo-1, epoch=170, train loss <loss>=2.525294303894043\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:00 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:05 INFO 139780359198336] Epoch[171] Batch[0] avg_epoch_loss=2.467923\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:05 INFO 139780359198336] #quality_metric: host=algo-1, epoch=171, batch=0 train loss <loss>=2.4679226875305176\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:10 INFO 139780359198336] Epoch[171] Batch[5] avg_epoch_loss=2.507376\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:10 INFO 139780359198336] #quality_metric: host=algo-1, epoch=171, batch=5 train loss <loss>=2.5073761145273843\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:10 INFO 139780359198336] Epoch[171] Batch [5]#011Speed: 62.28 samples/sec#011loss=2.507376\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:16 INFO 139780359198336] Epoch[171] Batch[10] avg_epoch_loss=2.554865\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:16 INFO 139780359198336] #quality_metric: host=algo-1, epoch=171, batch=10 train loss <loss>=2.6118515491485597\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:16 INFO 139780359198336] Epoch[171] Batch [10]#011Speed: 59.54 samples/sec#011loss=2.611852\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:16 INFO 139780359198336] processed a total of 669 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526740.9785218, \"EndTime\": 1617526756.0924482, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 15113.324880599976, \"count\": 1, \"min\": 15113.324880599976, \"max\": 15113.324880599976}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:16 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.2652164111119 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:16 INFO 139780359198336] #progress_metric: host=algo-1, completed 43.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:16 INFO 139780359198336] #quality_metric: host=algo-1, epoch=171, train loss <loss>=2.5548649484461006\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:16 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:20 INFO 139780359198336] Epoch[172] Batch[0] avg_epoch_loss=2.505535\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:20 INFO 139780359198336] #quality_metric: host=algo-1, epoch=172, batch=0 train loss <loss>=2.5055348873138428\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:25 INFO 139780359198336] Epoch[172] Batch[5] avg_epoch_loss=2.509043\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:25 INFO 139780359198336] #quality_metric: host=algo-1, epoch=172, batch=5 train loss <loss>=2.5090427001317344\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:25 INFO 139780359198336] Epoch[172] Batch [5]#011Speed: 62.85 samples/sec#011loss=2.509043\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:29 INFO 139780359198336] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526756.0925128, \"EndTime\": 1617526769.6499515, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13557.12866783142, \"count\": 1, \"min\": 13557.12866783142, \"max\": 13557.12866783142}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:29 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.73206554995951 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:29 INFO 139780359198336] #progress_metric: host=algo-1, completed 43.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:29 INFO 139780359198336] #quality_metric: host=algo-1, epoch=172, train loss <loss>=2.528814959526062\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:29 INFO 139780359198336] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 08:59:33 INFO 139780359198336] Epoch[173] Batch[0] avg_epoch_loss=2.603963\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:33 INFO 139780359198336] #quality_metric: host=algo-1, epoch=173, batch=0 train loss <loss>=2.6039633750915527\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:38 INFO 139780359198336] Epoch[173] Batch[5] avg_epoch_loss=2.523305\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:38 INFO 139780359198336] #quality_metric: host=algo-1, epoch=173, batch=5 train loss <loss>=2.523305336634318\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:38 INFO 139780359198336] Epoch[173] Batch [5]#011Speed: 63.00 samples/sec#011loss=2.523305\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:44 INFO 139780359198336] Epoch[173] Batch[10] avg_epoch_loss=2.528194\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:44 INFO 139780359198336] #quality_metric: host=algo-1, epoch=173, batch=10 train loss <loss>=2.5340600490570067\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:44 INFO 139780359198336] Epoch[173] Batch [10]#011Speed: 59.63 samples/sec#011loss=2.534060\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:44 INFO 139780359198336] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526769.6500218, \"EndTime\": 1617526784.1817453, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14531.248569488525, \"count\": 1, \"min\": 14531.248569488525, \"max\": 14531.248569488525}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:44 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.24485703027099 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:44 INFO 139780359198336] #progress_metric: host=algo-1, completed 43.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:44 INFO 139780359198336] #quality_metric: host=algo-1, epoch=173, train loss <loss>=2.5281938422809946\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:44 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:48 INFO 139780359198336] Epoch[174] Batch[0] avg_epoch_loss=2.569002\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:48 INFO 139780359198336] #quality_metric: host=algo-1, epoch=174, batch=0 train loss <loss>=2.5690016746520996\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:53 INFO 139780359198336] Epoch[174] Batch[5] avg_epoch_loss=2.465999\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:53 INFO 139780359198336] #quality_metric: host=algo-1, epoch=174, batch=5 train loss <loss>=2.4659986098607383\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:53 INFO 139780359198336] Epoch[174] Batch [5]#011Speed: 61.15 samples/sec#011loss=2.465999\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:57 INFO 139780359198336] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526784.181811, \"EndTime\": 1617526797.7956805, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13613.538980484009, \"count\": 1, \"min\": 13613.538980484009, \"max\": 13613.538980484009}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:57 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.71778165920602 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:57 INFO 139780359198336] #progress_metric: host=algo-1, completed 43.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:57 INFO 139780359198336] #quality_metric: host=algo-1, epoch=174, train loss <loss>=2.4716856241226197\u001b[0m\n",
      "\u001b[34m[04/04/2021 08:59:57 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:02 INFO 139780359198336] Epoch[175] Batch[0] avg_epoch_loss=2.468172\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:02 INFO 139780359198336] #quality_metric: host=algo-1, epoch=175, batch=0 train loss <loss>=2.4681715965270996\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:07 INFO 139780359198336] Epoch[175] Batch[5] avg_epoch_loss=2.491729\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:07 INFO 139780359198336] #quality_metric: host=algo-1, epoch=175, batch=5 train loss <loss>=2.491728901863098\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:07 INFO 139780359198336] Epoch[175] Batch [5]#011Speed: 55.32 samples/sec#011loss=2.491729\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:12 INFO 139780359198336] processed a total of 613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526797.795751, \"EndTime\": 1617526812.0859854, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14289.74199295044, \"count\": 1, \"min\": 14289.74199295044, \"max\": 14289.74199295044}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:12 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=42.897591896417445 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:12 INFO 139780359198336] #progress_metric: host=algo-1, completed 44.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:12 INFO 139780359198336] #quality_metric: host=algo-1, epoch=175, train loss <loss>=2.4820249319076537\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:12 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:16 INFO 139780359198336] Epoch[176] Batch[0] avg_epoch_loss=2.621012\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:16 INFO 139780359198336] #quality_metric: host=algo-1, epoch=176, batch=0 train loss <loss>=2.6210122108459473\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:21 INFO 139780359198336] Epoch[176] Batch[5] avg_epoch_loss=2.514468\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:21 INFO 139780359198336] #quality_metric: host=algo-1, epoch=176, batch=5 train loss <loss>=2.5144676764806113\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:21 INFO 139780359198336] Epoch[176] Batch [5]#011Speed: 60.98 samples/sec#011loss=2.514468\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:26 INFO 139780359198336] Epoch[176] Batch[10] avg_epoch_loss=2.525671\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:26 INFO 139780359198336] #quality_metric: host=algo-1, epoch=176, batch=10 train loss <loss>=2.539116048812866\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:26 INFO 139780359198336] Epoch[176] Batch [10]#011Speed: 60.71 samples/sec#011loss=2.539116\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:26 INFO 139780359198336] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526812.0860555, \"EndTime\": 1617526826.7819788, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14695.37377357483, \"count\": 1, \"min\": 14695.37377357483, \"max\": 14695.37377357483}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:26 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.435417822283995 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:26 INFO 139780359198336] #progress_metric: host=algo-1, completed 44.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:26 INFO 139780359198336] #quality_metric: host=algo-1, epoch=176, train loss <loss>=2.5256714820861816\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:26 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:30 INFO 139780359198336] Epoch[177] Batch[0] avg_epoch_loss=2.544197\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:30 INFO 139780359198336] #quality_metric: host=algo-1, epoch=177, batch=0 train loss <loss>=2.544196844100952\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:36 INFO 139780359198336] Epoch[177] Batch[5] avg_epoch_loss=2.506858\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:36 INFO 139780359198336] #quality_metric: host=algo-1, epoch=177, batch=5 train loss <loss>=2.506857673327128\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:36 INFO 139780359198336] Epoch[177] Batch [5]#011Speed: 62.35 samples/sec#011loss=2.506858\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:40 INFO 139780359198336] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526826.7820537, \"EndTime\": 1617526840.2452776, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13462.753057479858, \"count\": 1, \"min\": 13462.753057479858, \"max\": 13462.753057479858}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:40 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=47.24106614549224 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:40 INFO 139780359198336] #progress_metric: host=algo-1, completed 44.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:40 INFO 139780359198336] #quality_metric: host=algo-1, epoch=177, train loss <loss>=2.533972716331482\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:40 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:44 INFO 139780359198336] Epoch[178] Batch[0] avg_epoch_loss=2.585741\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:44 INFO 139780359198336] #quality_metric: host=algo-1, epoch=178, batch=0 train loss <loss>=2.5857410430908203\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:49 INFO 139780359198336] Epoch[178] Batch[5] avg_epoch_loss=2.461706\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:49 INFO 139780359198336] #quality_metric: host=algo-1, epoch=178, batch=5 train loss <loss>=2.4617059230804443\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:49 INFO 139780359198336] Epoch[178] Batch [5]#011Speed: 63.01 samples/sec#011loss=2.461706\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:00:53 INFO 139780359198336] processed a total of 601 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526840.2453506, \"EndTime\": 1617526853.8616488, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13615.941524505615, \"count\": 1, \"min\": 13615.941524505615, \"max\": 13615.941524505615}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:53 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.13882615587212 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:53 INFO 139780359198336] #progress_metric: host=algo-1, completed 44.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:53 INFO 139780359198336] #quality_metric: host=algo-1, epoch=178, train loss <loss>=2.537579894065857\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:53 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:58 INFO 139780359198336] Epoch[179] Batch[0] avg_epoch_loss=2.567871\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:00:58 INFO 139780359198336] #quality_metric: host=algo-1, epoch=179, batch=0 train loss <loss>=2.567870616912842\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:03 INFO 139780359198336] Epoch[179] Batch[5] avg_epoch_loss=2.580444\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:03 INFO 139780359198336] #quality_metric: host=algo-1, epoch=179, batch=5 train loss <loss>=2.580443501472473\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:03 INFO 139780359198336] Epoch[179] Batch [5]#011Speed: 58.77 samples/sec#011loss=2.580444\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:08 INFO 139780359198336] processed a total of 605 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526853.8617938, \"EndTime\": 1617526868.2343278, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14372.160911560059, \"count\": 1, \"min\": 14372.160911560059, \"max\": 14372.160911560059}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:08 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=42.09477740903997 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:08 INFO 139780359198336] #progress_metric: host=algo-1, completed 45.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:08 INFO 139780359198336] #quality_metric: host=algo-1, epoch=179, train loss <loss>=2.5346320152282713\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:08 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:12 INFO 139780359198336] Epoch[180] Batch[0] avg_epoch_loss=2.400394\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:12 INFO 139780359198336] #quality_metric: host=algo-1, epoch=180, batch=0 train loss <loss>=2.4003937244415283\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:17 INFO 139780359198336] Epoch[180] Batch[5] avg_epoch_loss=2.538118\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:17 INFO 139780359198336] #quality_metric: host=algo-1, epoch=180, batch=5 train loss <loss>=2.538117607434591\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:17 INFO 139780359198336] Epoch[180] Batch [5]#011Speed: 62.86 samples/sec#011loss=2.538118\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:21 INFO 139780359198336] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526868.2344563, \"EndTime\": 1617526881.7010002, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13466.04323387146, \"count\": 1, \"min\": 13466.04323387146, \"max\": 13466.04323387146}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:21 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=47.15522593939911 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:21 INFO 139780359198336] #progress_metric: host=algo-1, completed 45.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:21 INFO 139780359198336] #quality_metric: host=algo-1, epoch=180, train loss <loss>=2.503423500061035\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:21 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:25 INFO 139780359198336] Epoch[181] Batch[0] avg_epoch_loss=2.612762\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:25 INFO 139780359198336] #quality_metric: host=algo-1, epoch=181, batch=0 train loss <loss>=2.612762451171875\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:31 INFO 139780359198336] Epoch[181] Batch[5] avg_epoch_loss=2.466713\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:31 INFO 139780359198336] #quality_metric: host=algo-1, epoch=181, batch=5 train loss <loss>=2.4667134284973145\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:31 INFO 139780359198336] Epoch[181] Batch [5]#011Speed: 62.22 samples/sec#011loss=2.466713\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:35 INFO 139780359198336] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526881.7010818, \"EndTime\": 1617526895.2566085, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13555.050611495972, \"count\": 1, \"min\": 13555.050611495972, \"max\": 13555.050611495972}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:35 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.10786130557481 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:35 INFO 139780359198336] #progress_metric: host=algo-1, completed 45.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:35 INFO 139780359198336] #quality_metric: host=algo-1, epoch=181, train loss <loss>=2.435983657836914\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:35 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:39 INFO 139780359198336] Epoch[182] Batch[0] avg_epoch_loss=2.462686\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:39 INFO 139780359198336] #quality_metric: host=algo-1, epoch=182, batch=0 train loss <loss>=2.4626858234405518\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:44 INFO 139780359198336] Epoch[182] Batch[5] avg_epoch_loss=2.458710\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:44 INFO 139780359198336] #quality_metric: host=algo-1, epoch=182, batch=5 train loss <loss>=2.458710233370463\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:44 INFO 139780359198336] Epoch[182] Batch [5]#011Speed: 62.91 samples/sec#011loss=2.458710\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:49 INFO 139780359198336] Epoch[182] Batch[10] avg_epoch_loss=2.459803\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:49 INFO 139780359198336] #quality_metric: host=algo-1, epoch=182, batch=10 train loss <loss>=2.4611138820648195\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:49 INFO 139780359198336] Epoch[182] Batch [10]#011Speed: 58.29 samples/sec#011loss=2.461114\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:49 INFO 139780359198336] processed a total of 700 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526895.2566953, \"EndTime\": 1617526909.7848282, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14527.770280838013, \"count\": 1, \"min\": 14527.770280838013, \"max\": 14527.770280838013}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:49 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=48.1832657621775 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:49 INFO 139780359198336] #progress_metric: host=algo-1, completed 45.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:49 INFO 139780359198336] #quality_metric: host=algo-1, epoch=182, train loss <loss>=2.4598028009588067\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:49 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:54 INFO 139780359198336] Epoch[183] Batch[0] avg_epoch_loss=2.420580\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:54 INFO 139780359198336] #quality_metric: host=algo-1, epoch=183, batch=0 train loss <loss>=2.420579671859741\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:59 INFO 139780359198336] Epoch[183] Batch[5] avg_epoch_loss=2.454180\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:59 INFO 139780359198336] #quality_metric: host=algo-1, epoch=183, batch=5 train loss <loss>=2.454179525375366\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:01:59 INFO 139780359198336] Epoch[183] Batch [5]#011Speed: 62.25 samples/sec#011loss=2.454180\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:03 INFO 139780359198336] processed a total of 599 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526909.784893, \"EndTime\": 1617526923.7222333, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13936.972856521606, \"count\": 1, \"min\": 13936.972856521606, \"max\": 13936.972856521606}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:03 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=42.978849649318875 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:03 INFO 139780359198336] #progress_metric: host=algo-1, completed 46.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:03 INFO 139780359198336] #quality_metric: host=algo-1, epoch=183, train loss <loss>=2.447380876541138\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:03 INFO 139780359198336] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:02:08 INFO 139780359198336] Epoch[184] Batch[0] avg_epoch_loss=2.456459\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:08 INFO 139780359198336] #quality_metric: host=algo-1, epoch=184, batch=0 train loss <loss>=2.456458806991577\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:13 INFO 139780359198336] Epoch[184] Batch[5] avg_epoch_loss=2.505460\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:13 INFO 139780359198336] #quality_metric: host=algo-1, epoch=184, batch=5 train loss <loss>=2.5054604212443032\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:13 INFO 139780359198336] Epoch[184] Batch [5]#011Speed: 62.05 samples/sec#011loss=2.505460\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:18 INFO 139780359198336] Epoch[184] Batch[10] avg_epoch_loss=2.458837\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:18 INFO 139780359198336] #quality_metric: host=algo-1, epoch=184, batch=10 train loss <loss>=2.402888226509094\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:18 INFO 139780359198336] Epoch[184] Batch [10]#011Speed: 60.07 samples/sec#011loss=2.402888\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:18 INFO 139780359198336] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526923.7223122, \"EndTime\": 1617526938.6315434, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14908.215761184692, \"count\": 1, \"min\": 14908.215761184692, \"max\": 14908.215761184692}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:18 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.740121996760564 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:18 INFO 139780359198336] #progress_metric: host=algo-1, completed 46.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:18 INFO 139780359198336] #quality_metric: host=algo-1, epoch=184, train loss <loss>=2.458836696364663\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:18 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:22 INFO 139780359198336] Epoch[185] Batch[0] avg_epoch_loss=2.426758\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:22 INFO 139780359198336] #quality_metric: host=algo-1, epoch=185, batch=0 train loss <loss>=2.426758050918579\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:28 INFO 139780359198336] Epoch[185] Batch[5] avg_epoch_loss=2.546851\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:28 INFO 139780359198336] #quality_metric: host=algo-1, epoch=185, batch=5 train loss <loss>=2.546850641568502\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:28 INFO 139780359198336] Epoch[185] Batch [5]#011Speed: 58.39 samples/sec#011loss=2.546851\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:33 INFO 139780359198336] Epoch[185] Batch[10] avg_epoch_loss=2.464573\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:33 INFO 139780359198336] #quality_metric: host=algo-1, epoch=185, batch=10 train loss <loss>=2.365839624404907\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:33 INFO 139780359198336] Epoch[185] Batch [10]#011Speed: 60.79 samples/sec#011loss=2.365840\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:33 INFO 139780359198336] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526938.6316092, \"EndTime\": 1617526953.4677687, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14835.84213256836, \"count\": 1, \"min\": 14835.84213256836, \"max\": 14835.84213256836}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:33 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.48646106848187 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:33 INFO 139780359198336] #progress_metric: host=algo-1, completed 46.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:33 INFO 139780359198336] #quality_metric: host=algo-1, epoch=185, train loss <loss>=2.4645729064941406\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:33 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:37 INFO 139780359198336] Epoch[186] Batch[0] avg_epoch_loss=2.409875\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:37 INFO 139780359198336] #quality_metric: host=algo-1, epoch=186, batch=0 train loss <loss>=2.409874677658081\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:42 INFO 139780359198336] Epoch[186] Batch[5] avg_epoch_loss=2.477812\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:42 INFO 139780359198336] #quality_metric: host=algo-1, epoch=186, batch=5 train loss <loss>=2.4778122901916504\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:42 INFO 139780359198336] Epoch[186] Batch [5]#011Speed: 63.12 samples/sec#011loss=2.477812\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:46 INFO 139780359198336] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526953.4678698, \"EndTime\": 1617526966.8639107, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13395.575284957886, \"count\": 1, \"min\": 13395.575284957886, \"max\": 13395.575284957886}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:46 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.58215867551216 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:46 INFO 139780359198336] #progress_metric: host=algo-1, completed 46.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:46 INFO 139780359198336] #quality_metric: host=algo-1, epoch=186, train loss <loss>=2.4512531995773315\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:46 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:50 INFO 139780359198336] Epoch[187] Batch[0] avg_epoch_loss=2.438983\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:50 INFO 139780359198336] #quality_metric: host=algo-1, epoch=187, batch=0 train loss <loss>=2.438983201980591\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:56 INFO 139780359198336] Epoch[187] Batch[5] avg_epoch_loss=2.476262\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:56 INFO 139780359198336] #quality_metric: host=algo-1, epoch=187, batch=5 train loss <loss>=2.476261774698893\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:02:56 INFO 139780359198336] Epoch[187] Batch [5]#011Speed: 61.39 samples/sec#011loss=2.476262\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:01 INFO 139780359198336] Epoch[187] Batch[10] avg_epoch_loss=2.491568\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:01 INFO 139780359198336] #quality_metric: host=algo-1, epoch=187, batch=10 train loss <loss>=2.5099355220794677\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:01 INFO 139780359198336] Epoch[187] Batch [10]#011Speed: 58.94 samples/sec#011loss=2.509936\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:01 INFO 139780359198336] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526966.8639853, \"EndTime\": 1617526981.626146, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14761.770486831665, \"count\": 1, \"min\": 14761.770486831665, \"max\": 14761.770486831665}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:01 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.522705775038226 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:01 INFO 139780359198336] #progress_metric: host=algo-1, completed 47.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:01 INFO 139780359198336] #quality_metric: host=algo-1, epoch=187, train loss <loss>=2.491568023508245\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:01 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:06 INFO 139780359198336] Epoch[188] Batch[0] avg_epoch_loss=2.410306\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:06 INFO 139780359198336] #quality_metric: host=algo-1, epoch=188, batch=0 train loss <loss>=2.410306453704834\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:11 INFO 139780359198336] Epoch[188] Batch[5] avg_epoch_loss=2.459752\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:11 INFO 139780359198336] #quality_metric: host=algo-1, epoch=188, batch=5 train loss <loss>=2.459752003351847\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:11 INFO 139780359198336] Epoch[188] Batch [5]#011Speed: 63.69 samples/sec#011loss=2.459752\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:15 INFO 139780359198336] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526981.6262112, \"EndTime\": 1617526995.305768, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13679.197072982788, \"count\": 1, \"min\": 13679.197072982788, \"max\": 13679.197072982788}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:15 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.76252349272529 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:15 INFO 139780359198336] #progress_metric: host=algo-1, completed 47.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:15 INFO 139780359198336] #quality_metric: host=algo-1, epoch=188, train loss <loss>=2.4953811883926393\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:15 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:19 INFO 139780359198336] Epoch[189] Batch[0] avg_epoch_loss=2.485976\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:19 INFO 139780359198336] #quality_metric: host=algo-1, epoch=189, batch=0 train loss <loss>=2.485975980758667\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:24 INFO 139780359198336] Epoch[189] Batch[5] avg_epoch_loss=2.447845\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:24 INFO 139780359198336] #quality_metric: host=algo-1, epoch=189, batch=5 train loss <loss>=2.447845141092936\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:24 INFO 139780359198336] Epoch[189] Batch [5]#011Speed: 60.40 samples/sec#011loss=2.447845\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:03:30 INFO 139780359198336] Epoch[189] Batch[10] avg_epoch_loss=2.490833\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:30 INFO 139780359198336] #quality_metric: host=algo-1, epoch=189, batch=10 train loss <loss>=2.542419099807739\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:30 INFO 139780359198336] Epoch[189] Batch [10]#011Speed: 58.94 samples/sec#011loss=2.542419\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:30 INFO 139780359198336] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617526995.3058524, \"EndTime\": 1617527010.1461363, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14839.756488800049, \"count\": 1, \"min\": 14839.756488800049, \"max\": 14839.756488800049}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:30 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.67698079029806 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:30 INFO 139780359198336] #progress_metric: host=algo-1, completed 47.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:30 INFO 139780359198336] #quality_metric: host=algo-1, epoch=189, train loss <loss>=2.4908333041451196\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:30 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:34 INFO 139780359198336] Epoch[190] Batch[0] avg_epoch_loss=2.550297\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:34 INFO 139780359198336] #quality_metric: host=algo-1, epoch=190, batch=0 train loss <loss>=2.5502970218658447\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:39 INFO 139780359198336] Epoch[190] Batch[5] avg_epoch_loss=2.524862\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:39 INFO 139780359198336] #quality_metric: host=algo-1, epoch=190, batch=5 train loss <loss>=2.524862011273702\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:39 INFO 139780359198336] Epoch[190] Batch [5]#011Speed: 62.52 samples/sec#011loss=2.524862\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:44 INFO 139780359198336] Epoch[190] Batch[10] avg_epoch_loss=2.516340\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:44 INFO 139780359198336] #quality_metric: host=algo-1, epoch=190, batch=10 train loss <loss>=2.50611252784729\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:44 INFO 139780359198336] Epoch[190] Batch [10]#011Speed: 59.91 samples/sec#011loss=2.506113\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:44 INFO 139780359198336] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527010.1462045, \"EndTime\": 1617527024.7318943, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14585.259437561035, \"count\": 1, \"min\": 14585.259437561035, \"max\": 14585.259437561035}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:44 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.35954289697583 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:44 INFO 139780359198336] #progress_metric: host=algo-1, completed 47.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:44 INFO 139780359198336] #quality_metric: host=algo-1, epoch=190, train loss <loss>=2.516339518807151\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:44 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:48 INFO 139780359198336] Epoch[191] Batch[0] avg_epoch_loss=2.493455\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:48 INFO 139780359198336] #quality_metric: host=algo-1, epoch=191, batch=0 train loss <loss>=2.493455171585083\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:54 INFO 139780359198336] Epoch[191] Batch[5] avg_epoch_loss=2.477808\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:54 INFO 139780359198336] #quality_metric: host=algo-1, epoch=191, batch=5 train loss <loss>=2.477807879447937\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:54 INFO 139780359198336] Epoch[191] Batch [5]#011Speed: 61.82 samples/sec#011loss=2.477808\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:58 INFO 139780359198336] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527024.7319648, \"EndTime\": 1617527038.4469059, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13714.437007904053, \"count\": 1, \"min\": 13714.437007904053, \"max\": 13714.437007904053}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:58 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.30122803515661 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:58 INFO 139780359198336] #progress_metric: host=algo-1, completed 48.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:58 INFO 139780359198336] #quality_metric: host=algo-1, epoch=191, train loss <loss>=2.4744751930236815\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:03:58 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:03 INFO 139780359198336] Epoch[192] Batch[0] avg_epoch_loss=2.473774\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:03 INFO 139780359198336] #quality_metric: host=algo-1, epoch=192, batch=0 train loss <loss>=2.473773956298828\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:08 INFO 139780359198336] Epoch[192] Batch[5] avg_epoch_loss=2.431327\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:08 INFO 139780359198336] #quality_metric: host=algo-1, epoch=192, batch=5 train loss <loss>=2.4313268264134726\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:08 INFO 139780359198336] Epoch[192] Batch [5]#011Speed: 56.00 samples/sec#011loss=2.431327\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:12 INFO 139780359198336] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527038.4469767, \"EndTime\": 1617527052.8626637, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14415.291547775269, \"count\": 1, \"min\": 14415.291547775269, \"max\": 14415.291547775269}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:12 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.77262110113221 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:12 INFO 139780359198336] #progress_metric: host=algo-1, completed 48.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:12 INFO 139780359198336] #quality_metric: host=algo-1, epoch=192, train loss <loss>=2.46405770778656\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:12 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:17 INFO 139780359198336] Epoch[193] Batch[0] avg_epoch_loss=2.575772\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:17 INFO 139780359198336] #quality_metric: host=algo-1, epoch=193, batch=0 train loss <loss>=2.575772285461426\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:22 INFO 139780359198336] Epoch[193] Batch[5] avg_epoch_loss=2.499098\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:22 INFO 139780359198336] #quality_metric: host=algo-1, epoch=193, batch=5 train loss <loss>=2.499097983042399\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:22 INFO 139780359198336] Epoch[193] Batch [5]#011Speed: 62.35 samples/sec#011loss=2.499098\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:26 INFO 139780359198336] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527052.8627448, \"EndTime\": 1617527066.5040479, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13640.961170196533, \"count\": 1, \"min\": 13640.961170196533, \"max\": 13640.961170196533}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:26 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.744239703181485 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:26 INFO 139780359198336] #progress_metric: host=algo-1, completed 48.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:26 INFO 139780359198336] #quality_metric: host=algo-1, epoch=193, train loss <loss>=2.5028022289276124\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:26 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:30 INFO 139780359198336] Epoch[194] Batch[0] avg_epoch_loss=2.530599\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:30 INFO 139780359198336] #quality_metric: host=algo-1, epoch=194, batch=0 train loss <loss>=2.5305988788604736\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:35 INFO 139780359198336] Epoch[194] Batch[5] avg_epoch_loss=2.478836\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:35 INFO 139780359198336] #quality_metric: host=algo-1, epoch=194, batch=5 train loss <loss>=2.4788361390431723\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:35 INFO 139780359198336] Epoch[194] Batch [5]#011Speed: 62.49 samples/sec#011loss=2.478836\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:41 INFO 139780359198336] Epoch[194] Batch[10] avg_epoch_loss=2.503799\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:41 INFO 139780359198336] #quality_metric: host=algo-1, epoch=194, batch=10 train loss <loss>=2.533755302429199\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:41 INFO 139780359198336] Epoch[194] Batch [10]#011Speed: 59.76 samples/sec#011loss=2.533755\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:41 INFO 139780359198336] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527066.5041175, \"EndTime\": 1617527081.1598747, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14655.346393585205, \"count\": 1, \"min\": 14655.346393585205, \"max\": 14655.346393585205}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:41 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.21563996643989 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:41 INFO 139780359198336] #progress_metric: host=algo-1, completed 48.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:41 INFO 139780359198336] #quality_metric: host=algo-1, epoch=194, train loss <loss>=2.50379939512773\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:41 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:45 INFO 139780359198336] Epoch[195] Batch[0] avg_epoch_loss=2.491147\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:45 INFO 139780359198336] #quality_metric: host=algo-1, epoch=195, batch=0 train loss <loss>=2.491147041320801\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:04:50 INFO 139780359198336] Epoch[195] Batch[5] avg_epoch_loss=2.496059\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:50 INFO 139780359198336] #quality_metric: host=algo-1, epoch=195, batch=5 train loss <loss>=2.496058940887451\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:50 INFO 139780359198336] Epoch[195] Batch [5]#011Speed: 62.40 samples/sec#011loss=2.496059\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:55 INFO 139780359198336] Epoch[195] Batch[10] avg_epoch_loss=2.451751\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:55 INFO 139780359198336] #quality_metric: host=algo-1, epoch=195, batch=10 train loss <loss>=2.3985811710357665\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:55 INFO 139780359198336] Epoch[195] Batch [10]#011Speed: 61.38 samples/sec#011loss=2.398581\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:55 INFO 139780359198336] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527081.1599433, \"EndTime\": 1617527095.6773992, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14517.091751098633, \"count\": 1, \"min\": 14517.091751098633, \"max\": 14517.091751098633}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:55 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.56785522286878 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:55 INFO 139780359198336] #progress_metric: host=algo-1, completed 49.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:55 INFO 139780359198336] #quality_metric: host=algo-1, epoch=195, train loss <loss>=2.45175086368214\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:55 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:59 INFO 139780359198336] Epoch[196] Batch[0] avg_epoch_loss=2.558312\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:04:59 INFO 139780359198336] #quality_metric: host=algo-1, epoch=196, batch=0 train loss <loss>=2.55831241607666\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:05 INFO 139780359198336] Epoch[196] Batch[5] avg_epoch_loss=2.492233\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:05 INFO 139780359198336] #quality_metric: host=algo-1, epoch=196, batch=5 train loss <loss>=2.4922325213750205\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:05 INFO 139780359198336] Epoch[196] Batch [5]#011Speed: 53.69 samples/sec#011loss=2.492233\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:11 INFO 139780359198336] Epoch[196] Batch[10] avg_epoch_loss=2.429028\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:11 INFO 139780359198336] #quality_metric: host=algo-1, epoch=196, batch=10 train loss <loss>=2.3531831026077272\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:11 INFO 139780359198336] Epoch[196] Batch [10]#011Speed: 60.94 samples/sec#011loss=2.353183\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:11 INFO 139780359198336] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527095.6774657, \"EndTime\": 1617527111.1952045, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 15517.43459701538, \"count\": 1, \"min\": 15517.43459701538, \"max\": 15517.43459701538}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:11 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=41.63034839553435 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:11 INFO 139780359198336] #progress_metric: host=algo-1, completed 49.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:11 INFO 139780359198336] #quality_metric: host=algo-1, epoch=196, train loss <loss>=2.4290282401171597\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:11 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:15 INFO 139780359198336] Epoch[197] Batch[0] avg_epoch_loss=2.532049\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:15 INFO 139780359198336] #quality_metric: host=algo-1, epoch=197, batch=0 train loss <loss>=2.5320494174957275\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:20 INFO 139780359198336] Epoch[197] Batch[5] avg_epoch_loss=2.442585\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:20 INFO 139780359198336] #quality_metric: host=algo-1, epoch=197, batch=5 train loss <loss>=2.442584832509359\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:20 INFO 139780359198336] Epoch[197] Batch [5]#011Speed: 61.41 samples/sec#011loss=2.442585\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:25 INFO 139780359198336] Epoch[197] Batch[10] avg_epoch_loss=2.492975\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:25 INFO 139780359198336] #quality_metric: host=algo-1, epoch=197, batch=10 train loss <loss>=2.553442668914795\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:25 INFO 139780359198336] Epoch[197] Batch [10]#011Speed: 59.34 samples/sec#011loss=2.553443\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:25 INFO 139780359198336] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527111.1952665, \"EndTime\": 1617527125.9566917, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14761.000871658325, \"count\": 1, \"min\": 14761.000871658325, \"max\": 14761.000871658325}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:25 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.64438790767908 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:25 INFO 139780359198336] #progress_metric: host=algo-1, completed 49.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:25 INFO 139780359198336] #quality_metric: host=algo-1, epoch=197, train loss <loss>=2.4929747581481934\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:25 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:30 INFO 139780359198336] Epoch[198] Batch[0] avg_epoch_loss=2.594888\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:30 INFO 139780359198336] #quality_metric: host=algo-1, epoch=198, batch=0 train loss <loss>=2.594888210296631\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:35 INFO 139780359198336] Epoch[198] Batch[5] avg_epoch_loss=2.487981\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:35 INFO 139780359198336] #quality_metric: host=algo-1, epoch=198, batch=5 train loss <loss>=2.487981160481771\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:35 INFO 139780359198336] Epoch[198] Batch [5]#011Speed: 62.73 samples/sec#011loss=2.487981\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:40 INFO 139780359198336] Epoch[198] Batch[10] avg_epoch_loss=2.537887\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:40 INFO 139780359198336] #quality_metric: host=algo-1, epoch=198, batch=10 train loss <loss>=2.5977732658386232\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:40 INFO 139780359198336] Epoch[198] Batch [10]#011Speed: 59.34 samples/sec#011loss=2.597773\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:40 INFO 139780359198336] processed a total of 675 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527125.9567537, \"EndTime\": 1617527140.5516207, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14594.526529312134, \"count\": 1, \"min\": 14594.526529312134, \"max\": 14594.526529312134}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:40 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.249918768945946 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:40 INFO 139780359198336] #progress_metric: host=algo-1, completed 49.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:40 INFO 139780359198336] #quality_metric: host=algo-1, epoch=198, train loss <loss>=2.5378866629167036\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:40 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:44 INFO 139780359198336] Epoch[199] Batch[0] avg_epoch_loss=2.617522\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:44 INFO 139780359198336] #quality_metric: host=algo-1, epoch=199, batch=0 train loss <loss>=2.6175222396850586\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:49 INFO 139780359198336] Epoch[199] Batch[5] avg_epoch_loss=2.503380\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:49 INFO 139780359198336] #quality_metric: host=algo-1, epoch=199, batch=5 train loss <loss>=2.503379782040914\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:49 INFO 139780359198336] Epoch[199] Batch [5]#011Speed: 63.05 samples/sec#011loss=2.503380\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:55 INFO 139780359198336] Epoch[199] Batch[10] avg_epoch_loss=2.503656\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:55 INFO 139780359198336] #quality_metric: host=algo-1, epoch=199, batch=10 train loss <loss>=2.503987169265747\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:55 INFO 139780359198336] Epoch[199] Batch [10]#011Speed: 59.40 samples/sec#011loss=2.503987\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:55 INFO 139780359198336] processed a total of 683 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527140.5516853, \"EndTime\": 1617527155.0393705, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14487.37621307373, \"count\": 1, \"min\": 14487.37621307373, \"max\": 14487.37621307373}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:55 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=47.14417600643846 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:55 INFO 139780359198336] #progress_metric: host=algo-1, completed 50.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:55 INFO 139780359198336] #quality_metric: host=algo-1, epoch=199, train loss <loss>=2.503655867143111\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:55 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:59 INFO 139780359198336] Epoch[200] Batch[0] avg_epoch_loss=2.538932\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:05:59 INFO 139780359198336] #quality_metric: host=algo-1, epoch=200, batch=0 train loss <loss>=2.5389318466186523\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:06:05 INFO 139780359198336] Epoch[200] Batch[5] avg_epoch_loss=2.507172\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:05 INFO 139780359198336] #quality_metric: host=algo-1, epoch=200, batch=5 train loss <loss>=2.5071720679601035\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:05 INFO 139780359198336] Epoch[200] Batch [5]#011Speed: 56.10 samples/sec#011loss=2.507172\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:09 INFO 139780359198336] processed a total of 605 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527155.039437, \"EndTime\": 1617527169.4117634, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14372.011661529541, \"count\": 1, \"min\": 14372.011661529541, \"max\": 14372.011661529541}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:09 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=42.09539261907521 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:09 INFO 139780359198336] #progress_metric: host=algo-1, completed 50.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:09 INFO 139780359198336] #quality_metric: host=algo-1, epoch=200, train loss <loss>=2.4916418552398683\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:09 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:13 INFO 139780359198336] Epoch[201] Batch[0] avg_epoch_loss=2.422459\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:13 INFO 139780359198336] #quality_metric: host=algo-1, epoch=201, batch=0 train loss <loss>=2.4224586486816406\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:18 INFO 139780359198336] Epoch[201] Batch[5] avg_epoch_loss=2.513194\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:18 INFO 139780359198336] #quality_metric: host=algo-1, epoch=201, batch=5 train loss <loss>=2.5131938457489014\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:18 INFO 139780359198336] Epoch[201] Batch [5]#011Speed: 62.57 samples/sec#011loss=2.513194\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:22 INFO 139780359198336] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527169.4118376, \"EndTime\": 1617527182.872357, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13460.111379623413, \"count\": 1, \"min\": 13460.111379623413, \"max\": 13460.111379623413}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:22 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.581723013648464 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:22 INFO 139780359198336] #progress_metric: host=algo-1, completed 50.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:22 INFO 139780359198336] #quality_metric: host=algo-1, epoch=201, train loss <loss>=2.516075539588928\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:22 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:27 INFO 139780359198336] Epoch[202] Batch[0] avg_epoch_loss=2.391591\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:27 INFO 139780359198336] #quality_metric: host=algo-1, epoch=202, batch=0 train loss <loss>=2.3915910720825195\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:32 INFO 139780359198336] Epoch[202] Batch[5] avg_epoch_loss=2.440180\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:32 INFO 139780359198336] #quality_metric: host=algo-1, epoch=202, batch=5 train loss <loss>=2.4401803414026895\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:32 INFO 139780359198336] Epoch[202] Batch [5]#011Speed: 60.34 samples/sec#011loss=2.440180\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:37 INFO 139780359198336] Epoch[202] Batch[10] avg_epoch_loss=2.397991\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:37 INFO 139780359198336] #quality_metric: host=algo-1, epoch=202, batch=10 train loss <loss>=2.3473644256591797\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:37 INFO 139780359198336] Epoch[202] Batch [10]#011Speed: 61.04 samples/sec#011loss=2.347364\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:37 INFO 139780359198336] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527182.8724303, \"EndTime\": 1617527197.6010802, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14728.252172470093, \"count\": 1, \"min\": 14728.252172470093, \"max\": 14728.252172470093}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:37 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.743646690792545 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:37 INFO 139780359198336] #progress_metric: host=algo-1, completed 50.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:37 INFO 139780359198336] #quality_metric: host=algo-1, epoch=202, train loss <loss>=2.3979912887920034\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:37 INFO 139780359198336] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:37 INFO 139780359198336] Saved checkpoint to \"/opt/ml/model/state_3b4f8b36-d8d0-4c5b-a9c9-39779858f6d7-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527197.6011446, \"EndTime\": 1617527197.8022382, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 200.7460594177246, \"count\": 1, \"min\": 200.7460594177246, \"max\": 200.7460594177246}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:42 INFO 139780359198336] Epoch[203] Batch[0] avg_epoch_loss=2.423698\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:42 INFO 139780359198336] #quality_metric: host=algo-1, epoch=203, batch=0 train loss <loss>=2.4236979484558105\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:47 INFO 139780359198336] Epoch[203] Batch[5] avg_epoch_loss=2.482027\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:47 INFO 139780359198336] #quality_metric: host=algo-1, epoch=203, batch=5 train loss <loss>=2.482027292251587\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:47 INFO 139780359198336] Epoch[203] Batch [5]#011Speed: 62.57 samples/sec#011loss=2.482027\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:51 INFO 139780359198336] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527197.802308, \"EndTime\": 1617527211.2883565, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13485.980033874512, \"count\": 1, \"min\": 13485.980033874512, \"max\": 13485.980033874512}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:51 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.71474259332623 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:51 INFO 139780359198336] #progress_metric: host=algo-1, completed 51.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:51 INFO 139780359198336] #quality_metric: host=algo-1, epoch=203, train loss <loss>=2.4839900016784666\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:51 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:55 INFO 139780359198336] Epoch[204] Batch[0] avg_epoch_loss=2.338100\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:06:55 INFO 139780359198336] #quality_metric: host=algo-1, epoch=204, batch=0 train loss <loss>=2.3381004333496094\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:00 INFO 139780359198336] Epoch[204] Batch[5] avg_epoch_loss=2.451399\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:00 INFO 139780359198336] #quality_metric: host=algo-1, epoch=204, batch=5 train loss <loss>=2.451398571332296\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:00 INFO 139780359198336] Epoch[204] Batch [5]#011Speed: 60.33 samples/sec#011loss=2.451399\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:05 INFO 139780359198336] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527211.2884433, \"EndTime\": 1617527225.6658049, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14376.863718032837, \"count\": 1, \"min\": 14376.863718032837, \"max\": 14376.863718032837}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:05 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.12444745354638 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:05 INFO 139780359198336] #progress_metric: host=algo-1, completed 51.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:05 INFO 139780359198336] #quality_metric: host=algo-1, epoch=204, train loss <loss>=2.4237754583358764\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:05 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:09 INFO 139780359198336] Epoch[205] Batch[0] avg_epoch_loss=2.599412\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:09 INFO 139780359198336] #quality_metric: host=algo-1, epoch=205, batch=0 train loss <loss>=2.599412441253662\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:14 INFO 139780359198336] Epoch[205] Batch[5] avg_epoch_loss=2.449831\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:14 INFO 139780359198336] #quality_metric: host=algo-1, epoch=205, batch=5 train loss <loss>=2.449831247329712\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:14 INFO 139780359198336] Epoch[205] Batch [5]#011Speed: 62.06 samples/sec#011loss=2.449831\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:20 INFO 139780359198336] Epoch[205] Batch[10] avg_epoch_loss=2.461247\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:20 INFO 139780359198336] #quality_metric: host=algo-1, epoch=205, batch=10 train loss <loss>=2.474946308135986\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:20 INFO 139780359198336] Epoch[205] Batch [10]#011Speed: 59.00 samples/sec#011loss=2.474946\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:20 INFO 139780359198336] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527225.665897, \"EndTime\": 1617527240.40852, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14741.287469863892, \"count\": 1, \"min\": 14741.287469863892, \"max\": 14741.287469863892}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:20 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.5683779523708 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:20 INFO 139780359198336] #progress_metric: host=algo-1, completed 51.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:20 INFO 139780359198336] #quality_metric: host=algo-1, epoch=205, train loss <loss>=2.4612471840598364\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:20 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:24 INFO 139780359198336] Epoch[206] Batch[0] avg_epoch_loss=2.415437\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:24 INFO 139780359198336] #quality_metric: host=algo-1, epoch=206, batch=0 train loss <loss>=2.4154374599456787\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:07:29 INFO 139780359198336] Epoch[206] Batch[5] avg_epoch_loss=2.480526\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:29 INFO 139780359198336] #quality_metric: host=algo-1, epoch=206, batch=5 train loss <loss>=2.480525533358256\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:29 INFO 139780359198336] Epoch[206] Batch [5]#011Speed: 61.24 samples/sec#011loss=2.480526\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:35 INFO 139780359198336] Epoch[206] Batch[10] avg_epoch_loss=2.478464\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:35 INFO 139780359198336] #quality_metric: host=algo-1, epoch=206, batch=10 train loss <loss>=2.475991058349609\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:35 INFO 139780359198336] Epoch[206] Batch [10]#011Speed: 59.97 samples/sec#011loss=2.475991\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:35 INFO 139780359198336] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527240.4085913, \"EndTime\": 1617527255.0285158, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14619.507312774658, \"count\": 1, \"min\": 14619.507312774658, \"max\": 14619.507312774658}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:35 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.96568446734354 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:35 INFO 139780359198336] #progress_metric: host=algo-1, completed 51.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:35 INFO 139780359198336] #quality_metric: host=algo-1, epoch=206, train loss <loss>=2.4784644083543257\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:35 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:39 INFO 139780359198336] Epoch[207] Batch[0] avg_epoch_loss=2.660628\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:39 INFO 139780359198336] #quality_metric: host=algo-1, epoch=207, batch=0 train loss <loss>=2.660627841949463\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:44 INFO 139780359198336] Epoch[207] Batch[5] avg_epoch_loss=2.519315\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:44 INFO 139780359198336] #quality_metric: host=algo-1, epoch=207, batch=5 train loss <loss>=2.519314964612325\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:44 INFO 139780359198336] Epoch[207] Batch [5]#011Speed: 63.27 samples/sec#011loss=2.519315\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:49 INFO 139780359198336] Epoch[207] Batch[10] avg_epoch_loss=2.456324\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:49 INFO 139780359198336] #quality_metric: host=algo-1, epoch=207, batch=10 train loss <loss>=2.38073525428772\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:49 INFO 139780359198336] Epoch[207] Batch [10]#011Speed: 61.61 samples/sec#011loss=2.380735\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:49 INFO 139780359198336] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527255.0285807, \"EndTime\": 1617527269.4877095, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14458.815813064575, \"count\": 1, \"min\": 14458.815813064575, \"max\": 14458.815813064575}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:49 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.60915563711131 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:49 INFO 139780359198336] #progress_metric: host=algo-1, completed 52.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:49 INFO 139780359198336] #quality_metric: host=algo-1, epoch=207, train loss <loss>=2.45632418719205\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:49 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:53 INFO 139780359198336] Epoch[208] Batch[0] avg_epoch_loss=2.285854\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:53 INFO 139780359198336] #quality_metric: host=algo-1, epoch=208, batch=0 train loss <loss>=2.2858541011810303\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:58 INFO 139780359198336] Epoch[208] Batch[5] avg_epoch_loss=2.470939\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:58 INFO 139780359198336] #quality_metric: host=algo-1, epoch=208, batch=5 train loss <loss>=2.4709388415018716\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:07:58 INFO 139780359198336] Epoch[208] Batch [5]#011Speed: 63.13 samples/sec#011loss=2.470939\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:03 INFO 139780359198336] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527269.4877746, \"EndTime\": 1617527283.2201285, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13731.876850128174, \"count\": 1, \"min\": 13731.876850128174, \"max\": 13731.876850128174}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:03 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.80537706684086 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:03 INFO 139780359198336] #progress_metric: host=algo-1, completed 52.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:03 INFO 139780359198336] #quality_metric: host=algo-1, epoch=208, train loss <loss>=2.464173674583435\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:03 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:07 INFO 139780359198336] Epoch[209] Batch[0] avg_epoch_loss=2.530297\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:07 INFO 139780359198336] #quality_metric: host=algo-1, epoch=209, batch=0 train loss <loss>=2.53029727935791\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:12 INFO 139780359198336] Epoch[209] Batch[5] avg_epoch_loss=2.495453\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:12 INFO 139780359198336] #quality_metric: host=algo-1, epoch=209, batch=5 train loss <loss>=2.495452960332235\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:12 INFO 139780359198336] Epoch[209] Batch [5]#011Speed: 62.96 samples/sec#011loss=2.495453\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:16 INFO 139780359198336] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527283.2202241, \"EndTime\": 1617527296.9729784, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13751.869916915894, \"count\": 1, \"min\": 13751.869916915894, \"max\": 13751.869916915894}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:16 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.15693936257158 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:16 INFO 139780359198336] #progress_metric: host=algo-1, completed 52.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:16 INFO 139780359198336] #quality_metric: host=algo-1, epoch=209, train loss <loss>=2.5164363861083983\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:16 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:21 INFO 139780359198336] Epoch[210] Batch[0] avg_epoch_loss=2.455170\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:21 INFO 139780359198336] #quality_metric: host=algo-1, epoch=210, batch=0 train loss <loss>=2.4551703929901123\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:26 INFO 139780359198336] Epoch[210] Batch[5] avg_epoch_loss=2.480816\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:26 INFO 139780359198336] #quality_metric: host=algo-1, epoch=210, batch=5 train loss <loss>=2.4808163245519004\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:26 INFO 139780359198336] Epoch[210] Batch [5]#011Speed: 62.16 samples/sec#011loss=2.480816\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:31 INFO 139780359198336] Epoch[210] Batch[10] avg_epoch_loss=2.551729\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:31 INFO 139780359198336] #quality_metric: host=algo-1, epoch=210, batch=10 train loss <loss>=2.6368242263793946\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:31 INFO 139780359198336] Epoch[210] Batch [10]#011Speed: 59.80 samples/sec#011loss=2.636824\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:31 INFO 139780359198336] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527296.9731026, \"EndTime\": 1617527311.7786481, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14805.167436599731, \"count\": 1, \"min\": 14805.167436599731, \"max\": 14805.167436599731}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:31 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.29540960569911 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:31 INFO 139780359198336] #progress_metric: host=algo-1, completed 52.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:31 INFO 139780359198336] #quality_metric: host=algo-1, epoch=210, train loss <loss>=2.5517290072007612\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:31 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:35 INFO 139780359198336] Epoch[211] Batch[0] avg_epoch_loss=2.507789\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:35 INFO 139780359198336] #quality_metric: host=algo-1, epoch=211, batch=0 train loss <loss>=2.507789373397827\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:41 INFO 139780359198336] Epoch[211] Batch[5] avg_epoch_loss=2.461214\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:41 INFO 139780359198336] #quality_metric: host=algo-1, epoch=211, batch=5 train loss <loss>=2.4612141450246177\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:41 INFO 139780359198336] Epoch[211] Batch [5]#011Speed: 62.62 samples/sec#011loss=2.461214\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:08:45 INFO 139780359198336] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527311.778714, \"EndTime\": 1617527325.194707, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13415.600776672363, \"count\": 1, \"min\": 13415.600776672363, \"max\": 13415.600776672363}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:45 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=47.63060960176029 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:45 INFO 139780359198336] #progress_metric: host=algo-1, completed 53.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:45 INFO 139780359198336] #quality_metric: host=algo-1, epoch=211, train loss <loss>=2.462132954597473\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:45 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:49 INFO 139780359198336] Epoch[212] Batch[0] avg_epoch_loss=2.561010\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:49 INFO 139780359198336] #quality_metric: host=algo-1, epoch=212, batch=0 train loss <loss>=2.5610098838806152\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:54 INFO 139780359198336] Epoch[212] Batch[5] avg_epoch_loss=2.477049\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:54 INFO 139780359198336] #quality_metric: host=algo-1, epoch=212, batch=5 train loss <loss>=2.477049469947815\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:54 INFO 139780359198336] Epoch[212] Batch [5]#011Speed: 62.55 samples/sec#011loss=2.477049\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:59 INFO 139780359198336] Epoch[212] Batch[10] avg_epoch_loss=2.421254\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:59 INFO 139780359198336] #quality_metric: host=algo-1, epoch=212, batch=10 train loss <loss>=2.354299211502075\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:59 INFO 139780359198336] Epoch[212] Batch [10]#011Speed: 60.86 samples/sec#011loss=2.354299\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:59 INFO 139780359198336] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527325.1947966, \"EndTime\": 1617527339.7536466, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14558.436393737793, \"count\": 1, \"min\": 14558.436393737793, \"max\": 14558.436393737793}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:59 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.30390657348803 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:59 INFO 139780359198336] #progress_metric: host=algo-1, completed 53.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:59 INFO 139780359198336] #quality_metric: host=algo-1, epoch=212, train loss <loss>=2.421253897927024\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:08:59 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:04 INFO 139780359198336] Epoch[213] Batch[0] avg_epoch_loss=2.428789\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:04 INFO 139780359198336] #quality_metric: host=algo-1, epoch=213, batch=0 train loss <loss>=2.428788900375366\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:09 INFO 139780359198336] Epoch[213] Batch[5] avg_epoch_loss=2.509694\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:09 INFO 139780359198336] #quality_metric: host=algo-1, epoch=213, batch=5 train loss <loss>=2.5096943775812783\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:09 INFO 139780359198336] Epoch[213] Batch [5]#011Speed: 57.84 samples/sec#011loss=2.509694\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:14 INFO 139780359198336] processed a total of 586 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527339.7537138, \"EndTime\": 1617527354.0477557, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14293.604373931885, \"count\": 1, \"min\": 14293.604373931885, \"max\": 14293.604373931885}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:14 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=40.99706832836537 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:14 INFO 139780359198336] #progress_metric: host=algo-1, completed 53.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:14 INFO 139780359198336] #quality_metric: host=algo-1, epoch=213, train loss <loss>=2.5135024309158327\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:14 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:18 INFO 139780359198336] Epoch[214] Batch[0] avg_epoch_loss=2.425583\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:18 INFO 139780359198336] #quality_metric: host=algo-1, epoch=214, batch=0 train loss <loss>=2.4255831241607666\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:23 INFO 139780359198336] Epoch[214] Batch[5] avg_epoch_loss=2.477163\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:23 INFO 139780359198336] #quality_metric: host=algo-1, epoch=214, batch=5 train loss <loss>=2.477162520090739\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:23 INFO 139780359198336] Epoch[214] Batch [5]#011Speed: 62.02 samples/sec#011loss=2.477163\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:28 INFO 139780359198336] Epoch[214] Batch[10] avg_epoch_loss=2.512203\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:28 INFO 139780359198336] #quality_metric: host=algo-1, epoch=214, batch=10 train loss <loss>=2.554251289367676\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:28 INFO 139780359198336] Epoch[214] Batch [10]#011Speed: 59.48 samples/sec#011loss=2.554251\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:28 INFO 139780359198336] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527354.0478263, \"EndTime\": 1617527368.721886, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14673.576354980469, \"count\": 1, \"min\": 14673.576354980469, \"max\": 14673.576354980469}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:28 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.3192601385195 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:28 INFO 139780359198336] #progress_metric: host=algo-1, completed 53.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:28 INFO 139780359198336] #quality_metric: host=algo-1, epoch=214, train loss <loss>=2.5122028697620737\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:28 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:33 INFO 139780359198336] Epoch[215] Batch[0] avg_epoch_loss=2.538048\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:33 INFO 139780359198336] #quality_metric: host=algo-1, epoch=215, batch=0 train loss <loss>=2.5380477905273438\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:38 INFO 139780359198336] Epoch[215] Batch[5] avg_epoch_loss=2.451451\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:38 INFO 139780359198336] #quality_metric: host=algo-1, epoch=215, batch=5 train loss <loss>=2.4514505863189697\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:38 INFO 139780359198336] Epoch[215] Batch [5]#011Speed: 60.54 samples/sec#011loss=2.451451\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:43 INFO 139780359198336] Epoch[215] Batch[10] avg_epoch_loss=2.349272\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:43 INFO 139780359198336] #quality_metric: host=algo-1, epoch=215, batch=10 train loss <loss>=2.2266579389572145\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:43 INFO 139780359198336] Epoch[215] Batch [10]#011Speed: 61.40 samples/sec#011loss=2.226658\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:43 INFO 139780359198336] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527368.7219522, \"EndTime\": 1617527383.5424454, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14820.158958435059, \"count\": 1, \"min\": 14820.158958435059, \"max\": 14820.158958435059}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:43 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.45396961041017 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:43 INFO 139780359198336] #progress_metric: host=algo-1, completed 54.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:43 INFO 139780359198336] #quality_metric: host=algo-1, epoch=215, train loss <loss>=2.3492721102454444\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:43 INFO 139780359198336] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:43 INFO 139780359198336] Saved checkpoint to \"/opt/ml/model/state_3bba2d4b-f2d9-4a1d-836a-51b819772f48-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527383.542521, \"EndTime\": 1617527383.7330496, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 190.0181770324707, \"count\": 1, \"min\": 190.0181770324707, \"max\": 190.0181770324707}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:47 INFO 139780359198336] Epoch[216] Batch[0] avg_epoch_loss=2.475075\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:47 INFO 139780359198336] #quality_metric: host=algo-1, epoch=216, batch=0 train loss <loss>=2.475074529647827\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:09:53 INFO 139780359198336] Epoch[216] Batch[5] avg_epoch_loss=2.516559\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:53 INFO 139780359198336] #quality_metric: host=algo-1, epoch=216, batch=5 train loss <loss>=2.5165594816207886\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:53 INFO 139780359198336] Epoch[216] Batch [5]#011Speed: 62.21 samples/sec#011loss=2.516559\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:57 INFO 139780359198336] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527383.7331233, \"EndTime\": 1617527397.2204006, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13487.212181091309, \"count\": 1, \"min\": 13487.212181091309, \"max\": 13487.212181091309}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:57 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.33983059792442 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:57 INFO 139780359198336] #progress_metric: host=algo-1, completed 54.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:57 INFO 139780359198336] #quality_metric: host=algo-1, epoch=216, train loss <loss>=2.480895161628723\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:09:57 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:01 INFO 139780359198336] Epoch[217] Batch[0] avg_epoch_loss=2.475792\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:01 INFO 139780359198336] #quality_metric: host=algo-1, epoch=217, batch=0 train loss <loss>=2.4757919311523438\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:07 INFO 139780359198336] Epoch[217] Batch[5] avg_epoch_loss=2.495542\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:07 INFO 139780359198336] #quality_metric: host=algo-1, epoch=217, batch=5 train loss <loss>=2.4955424865086875\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:07 INFO 139780359198336] Epoch[217] Batch [5]#011Speed: 52.29 samples/sec#011loss=2.495542\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:11 INFO 139780359198336] processed a total of 589 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527397.2204726, \"EndTime\": 1617527411.8366973, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14615.646362304688, \"count\": 1, \"min\": 14615.646362304688, \"max\": 14615.646362304688}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:11 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=40.299005467589865 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:11 INFO 139780359198336] #progress_metric: host=algo-1, completed 54.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:11 INFO 139780359198336] #quality_metric: host=algo-1, epoch=217, train loss <loss>=2.4613122940063477\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:11 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:16 INFO 139780359198336] Epoch[218] Batch[0] avg_epoch_loss=2.491749\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:16 INFO 139780359198336] #quality_metric: host=algo-1, epoch=218, batch=0 train loss <loss>=2.4917490482330322\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:21 INFO 139780359198336] Epoch[218] Batch[5] avg_epoch_loss=2.473975\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:21 INFO 139780359198336] #quality_metric: host=algo-1, epoch=218, batch=5 train loss <loss>=2.47397518157959\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:21 INFO 139780359198336] Epoch[218] Batch [5]#011Speed: 62.31 samples/sec#011loss=2.473975\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:25 INFO 139780359198336] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527411.8367674, \"EndTime\": 1617527425.3668172, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13529.55675125122, \"count\": 1, \"min\": 13529.55675125122, \"max\": 13529.55675125122}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:25 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.75059764217933 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:25 INFO 139780359198336] #progress_metric: host=algo-1, completed 54.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:25 INFO 139780359198336] #quality_metric: host=algo-1, epoch=218, train loss <loss>=2.4849591970443727\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:25 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:29 INFO 139780359198336] Epoch[219] Batch[0] avg_epoch_loss=2.286159\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:29 INFO 139780359198336] #quality_metric: host=algo-1, epoch=219, batch=0 train loss <loss>=2.2861592769622803\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:34 INFO 139780359198336] Epoch[219] Batch[5] avg_epoch_loss=2.439219\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:34 INFO 139780359198336] #quality_metric: host=algo-1, epoch=219, batch=5 train loss <loss>=2.439218839009603\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:34 INFO 139780359198336] Epoch[219] Batch [5]#011Speed: 60.65 samples/sec#011loss=2.439219\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:39 INFO 139780359198336] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527425.3670747, \"EndTime\": 1617527439.0732343, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13705.653667449951, \"count\": 1, \"min\": 13705.653667449951, \"max\": 13705.653667449951}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:39 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.11181272106006 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:39 INFO 139780359198336] #progress_metric: host=algo-1, completed 55.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:39 INFO 139780359198336] #quality_metric: host=algo-1, epoch=219, train loss <loss>=2.4750286102294923\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:39 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:43 INFO 139780359198336] Epoch[220] Batch[0] avg_epoch_loss=2.461228\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:43 INFO 139780359198336] #quality_metric: host=algo-1, epoch=220, batch=0 train loss <loss>=2.4612276554107666\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:48 INFO 139780359198336] Epoch[220] Batch[5] avg_epoch_loss=2.456431\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:48 INFO 139780359198336] #quality_metric: host=algo-1, epoch=220, batch=5 train loss <loss>=2.4564307928085327\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:48 INFO 139780359198336] Epoch[220] Batch [5]#011Speed: 62.24 samples/sec#011loss=2.456431\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:53 INFO 139780359198336] Epoch[220] Batch[10] avg_epoch_loss=2.442344\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:53 INFO 139780359198336] #quality_metric: host=algo-1, epoch=220, batch=10 train loss <loss>=2.4254392623901366\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:53 INFO 139780359198336] Epoch[220] Batch [10]#011Speed: 59.97 samples/sec#011loss=2.425439\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:53 INFO 139780359198336] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527439.0733614, \"EndTime\": 1617527453.677744, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14603.782653808594, \"count\": 1, \"min\": 14603.782653808594, \"max\": 14603.782653808594}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:53 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.46733947666889 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:53 INFO 139780359198336] #progress_metric: host=algo-1, completed 55.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:53 INFO 139780359198336] #quality_metric: host=algo-1, epoch=220, train loss <loss>=2.442343733527444\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:53 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:57 INFO 139780359198336] Epoch[221] Batch[0] avg_epoch_loss=2.373921\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:10:57 INFO 139780359198336] #quality_metric: host=algo-1, epoch=221, batch=0 train loss <loss>=2.3739211559295654\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:03 INFO 139780359198336] Epoch[221] Batch[5] avg_epoch_loss=2.452779\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:03 INFO 139780359198336] #quality_metric: host=algo-1, epoch=221, batch=5 train loss <loss>=2.452779213587443\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:03 INFO 139780359198336] Epoch[221] Batch [5]#011Speed: 58.73 samples/sec#011loss=2.452779\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:08 INFO 139780359198336] processed a total of 604 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527453.6778145, \"EndTime\": 1617527468.07766, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14399.372339248657, \"count\": 1, \"min\": 14399.372339248657, \"max\": 14399.372339248657}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:08 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=41.945872040830835 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:08 INFO 139780359198336] #progress_metric: host=algo-1, completed 55.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:08 INFO 139780359198336] #quality_metric: host=algo-1, epoch=221, train loss <loss>=2.403839445114136\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:08 INFO 139780359198336] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:11:12 INFO 139780359198336] Epoch[222] Batch[0] avg_epoch_loss=2.498914\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:12 INFO 139780359198336] #quality_metric: host=algo-1, epoch=222, batch=0 train loss <loss>=2.498913526535034\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:17 INFO 139780359198336] Epoch[222] Batch[5] avg_epoch_loss=2.468361\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:17 INFO 139780359198336] #quality_metric: host=algo-1, epoch=222, batch=5 train loss <loss>=2.468361496925354\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:17 INFO 139780359198336] Epoch[222] Batch [5]#011Speed: 62.50 samples/sec#011loss=2.468361\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:21 INFO 139780359198336] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527468.0777621, \"EndTime\": 1617527481.5869524, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13508.539915084839, \"count\": 1, \"min\": 13508.539915084839, \"max\": 13508.539915084839}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:21 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.266618484038624 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:21 INFO 139780359198336] #progress_metric: host=algo-1, completed 55.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:21 INFO 139780359198336] #quality_metric: host=algo-1, epoch=222, train loss <loss>=2.4886827945709227\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:21 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:25 INFO 139780359198336] Epoch[223] Batch[0] avg_epoch_loss=2.506458\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:25 INFO 139780359198336] #quality_metric: host=algo-1, epoch=223, batch=0 train loss <loss>=2.506458282470703\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:30 INFO 139780359198336] Epoch[223] Batch[5] avg_epoch_loss=2.505606\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:30 INFO 139780359198336] #quality_metric: host=algo-1, epoch=223, batch=5 train loss <loss>=2.5056063731511435\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:30 INFO 139780359198336] Epoch[223] Batch [5]#011Speed: 62.94 samples/sec#011loss=2.505606\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:36 INFO 139780359198336] Epoch[223] Batch[10] avg_epoch_loss=2.478477\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:36 INFO 139780359198336] #quality_metric: host=algo-1, epoch=223, batch=10 train loss <loss>=2.4459208488464355\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:36 INFO 139780359198336] Epoch[223] Batch [10]#011Speed: 59.35 samples/sec#011loss=2.445921\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:36 INFO 139780359198336] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527481.5870395, \"EndTime\": 1617527496.2408252, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14653.397798538208, \"count\": 1, \"min\": 14653.397798538208, \"max\": 14653.397798538208}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:36 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.01681047500503 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:36 INFO 139780359198336] #progress_metric: host=algo-1, completed 56.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:36 INFO 139780359198336] #quality_metric: host=algo-1, epoch=223, train loss <loss>=2.4784765893762764\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:36 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:40 INFO 139780359198336] Epoch[224] Batch[0] avg_epoch_loss=2.503823\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:40 INFO 139780359198336] #quality_metric: host=algo-1, epoch=224, batch=0 train loss <loss>=2.5038232803344727\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:45 INFO 139780359198336] Epoch[224] Batch[5] avg_epoch_loss=2.548685\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:45 INFO 139780359198336] #quality_metric: host=algo-1, epoch=224, batch=5 train loss <loss>=2.5486851135889688\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:45 INFO 139780359198336] Epoch[224] Batch [5]#011Speed: 62.95 samples/sec#011loss=2.548685\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:50 INFO 139780359198336] Epoch[224] Batch[10] avg_epoch_loss=2.487683\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:50 INFO 139780359198336] #quality_metric: host=algo-1, epoch=224, batch=10 train loss <loss>=2.414480447769165\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:50 INFO 139780359198336] Epoch[224] Batch [10]#011Speed: 59.62 samples/sec#011loss=2.414480\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:50 INFO 139780359198336] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527496.2408915, \"EndTime\": 1617527510.7479248, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14506.71911239624, \"count\": 1, \"min\": 14506.71911239624, \"max\": 14506.71911239624}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:50 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.21989634176776 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:50 INFO 139780359198336] #progress_metric: host=algo-1, completed 56.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:50 INFO 139780359198336] #quality_metric: host=algo-1, epoch=224, train loss <loss>=2.487682992761785\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:50 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:54 INFO 139780359198336] Epoch[225] Batch[0] avg_epoch_loss=2.553843\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:54 INFO 139780359198336] #quality_metric: host=algo-1, epoch=225, batch=0 train loss <loss>=2.5538432598114014\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:59 INFO 139780359198336] Epoch[225] Batch[5] avg_epoch_loss=2.499517\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:59 INFO 139780359198336] #quality_metric: host=algo-1, epoch=225, batch=5 train loss <loss>=2.4995172023773193\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:11:59 INFO 139780359198336] Epoch[225] Batch [5]#011Speed: 62.53 samples/sec#011loss=2.499517\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:06 INFO 139780359198336] Epoch[225] Batch[10] avg_epoch_loss=2.482992\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:06 INFO 139780359198336] #quality_metric: host=algo-1, epoch=225, batch=10 train loss <loss>=2.463161563873291\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:06 INFO 139780359198336] Epoch[225] Batch [10]#011Speed: 50.93 samples/sec#011loss=2.463162\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:06 INFO 139780359198336] processed a total of 673 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527510.7480571, \"EndTime\": 1617527526.2253828, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 15476.566076278687, \"count\": 1, \"min\": 15476.566076278687, \"max\": 15476.566076278687}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:06 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.4846798030528 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:06 INFO 139780359198336] #progress_metric: host=algo-1, completed 56.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:06 INFO 139780359198336] #quality_metric: host=algo-1, epoch=225, train loss <loss>=2.4829919121482154\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:06 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:10 INFO 139780359198336] Epoch[226] Batch[0] avg_epoch_loss=2.483186\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:10 INFO 139780359198336] #quality_metric: host=algo-1, epoch=226, batch=0 train loss <loss>=2.4831857681274414\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:15 INFO 139780359198336] Epoch[226] Batch[5] avg_epoch_loss=2.474269\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:15 INFO 139780359198336] #quality_metric: host=algo-1, epoch=226, batch=5 train loss <loss>=2.474268913269043\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:15 INFO 139780359198336] Epoch[226] Batch [5]#011Speed: 62.34 samples/sec#011loss=2.474269\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:19 INFO 139780359198336] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527526.225494, \"EndTime\": 1617527539.8165653, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13590.488910675049, \"count\": 1, \"min\": 13590.488910675049, \"max\": 13590.488910675049}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:19 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.42910960177171 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:19 INFO 139780359198336] #progress_metric: host=algo-1, completed 56.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:19 INFO 139780359198336] #quality_metric: host=algo-1, epoch=226, train loss <loss>=2.462798261642456\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:19 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:23 INFO 139780359198336] Epoch[227] Batch[0] avg_epoch_loss=2.465847\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:23 INFO 139780359198336] #quality_metric: host=algo-1, epoch=227, batch=0 train loss <loss>=2.4658470153808594\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:12:28 INFO 139780359198336] Epoch[227] Batch[5] avg_epoch_loss=2.453254\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:28 INFO 139780359198336] #quality_metric: host=algo-1, epoch=227, batch=5 train loss <loss>=2.4532537857691445\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:28 INFO 139780359198336] Epoch[227] Batch [5]#011Speed: 63.42 samples/sec#011loss=2.453254\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:34 INFO 139780359198336] Epoch[227] Batch[10] avg_epoch_loss=2.545747\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:34 INFO 139780359198336] #quality_metric: host=algo-1, epoch=227, batch=10 train loss <loss>=2.656737804412842\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:34 INFO 139780359198336] Epoch[227] Batch [10]#011Speed: 61.23 samples/sec#011loss=2.656738\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:34 INFO 139780359198336] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527539.8166358, \"EndTime\": 1617527554.2137094, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14396.57735824585, \"count\": 1, \"min\": 14396.57735824585, \"max\": 14396.57735824585}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:34 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.635545337399776 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:34 INFO 139780359198336] #progress_metric: host=algo-1, completed 57.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:34 INFO 139780359198336] #quality_metric: host=algo-1, epoch=227, train loss <loss>=2.54574652151628\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:34 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:38 INFO 139780359198336] Epoch[228] Batch[0] avg_epoch_loss=2.458649\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:38 INFO 139780359198336] #quality_metric: host=algo-1, epoch=228, batch=0 train loss <loss>=2.458648920059204\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:43 INFO 139780359198336] Epoch[228] Batch[5] avg_epoch_loss=2.460723\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:43 INFO 139780359198336] #quality_metric: host=algo-1, epoch=228, batch=5 train loss <loss>=2.460722724596659\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:43 INFO 139780359198336] Epoch[228] Batch [5]#011Speed: 63.15 samples/sec#011loss=2.460723\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:47 INFO 139780359198336] processed a total of 613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527554.2137733, \"EndTime\": 1617527567.64137, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13427.279472351074, \"count\": 1, \"min\": 13427.279472351074, \"max\": 13427.279472351074}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:47 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.65299366522602 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:47 INFO 139780359198336] #progress_metric: host=algo-1, completed 57.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:47 INFO 139780359198336] #quality_metric: host=algo-1, epoch=228, train loss <loss>=2.4593496322631836\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:47 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:51 INFO 139780359198336] Epoch[229] Batch[0] avg_epoch_loss=2.429578\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:51 INFO 139780359198336] #quality_metric: host=algo-1, epoch=229, batch=0 train loss <loss>=2.4295783042907715\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:56 INFO 139780359198336] Epoch[229] Batch[5] avg_epoch_loss=2.487557\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:56 INFO 139780359198336] #quality_metric: host=algo-1, epoch=229, batch=5 train loss <loss>=2.487557291984558\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:12:56 INFO 139780359198336] Epoch[229] Batch [5]#011Speed: 63.12 samples/sec#011loss=2.487557\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:00 INFO 139780359198336] processed a total of 599 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527567.641438, \"EndTime\": 1617527580.9828553, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13340.920686721802, \"count\": 1, \"min\": 13340.920686721802, \"max\": 13340.920686721802}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:00 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.8991112868276 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:00 INFO 139780359198336] #progress_metric: host=algo-1, completed 57.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:00 INFO 139780359198336] #quality_metric: host=algo-1, epoch=229, train loss <loss>=2.4406805276870727\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:00 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:05 INFO 139780359198336] Epoch[230] Batch[0] avg_epoch_loss=2.442244\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:05 INFO 139780359198336] #quality_metric: host=algo-1, epoch=230, batch=0 train loss <loss>=2.4422435760498047\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:10 INFO 139780359198336] Epoch[230] Batch[5] avg_epoch_loss=2.452677\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:10 INFO 139780359198336] #quality_metric: host=algo-1, epoch=230, batch=5 train loss <loss>=2.452676773071289\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:10 INFO 139780359198336] Epoch[230] Batch [5]#011Speed: 60.28 samples/sec#011loss=2.452677\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:16 INFO 139780359198336] Epoch[230] Batch[10] avg_epoch_loss=2.510373\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:16 INFO 139780359198336] #quality_metric: host=algo-1, epoch=230, batch=10 train loss <loss>=2.57960844039917\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:16 INFO 139780359198336] Epoch[230] Batch [10]#011Speed: 60.99 samples/sec#011loss=2.579608\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:16 INFO 139780359198336] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527580.9829247, \"EndTime\": 1617527596.1241033, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 15140.651941299438, \"count\": 1, \"min\": 15140.651941299438, \"max\": 15140.651941299438}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:16 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.26073013746746 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:16 INFO 139780359198336] #progress_metric: host=algo-1, completed 57.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:16 INFO 139780359198336] #quality_metric: host=algo-1, epoch=230, train loss <loss>=2.510372985493053\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:16 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:20 INFO 139780359198336] Epoch[231] Batch[0] avg_epoch_loss=2.466598\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:20 INFO 139780359198336] #quality_metric: host=algo-1, epoch=231, batch=0 train loss <loss>=2.46659779548645\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:25 INFO 139780359198336] Epoch[231] Batch[5] avg_epoch_loss=2.410335\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:25 INFO 139780359198336] #quality_metric: host=algo-1, epoch=231, batch=5 train loss <loss>=2.4103345473607383\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:25 INFO 139780359198336] Epoch[231] Batch [5]#011Speed: 62.67 samples/sec#011loss=2.410335\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:29 INFO 139780359198336] processed a total of 594 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527596.1241715, \"EndTime\": 1617527609.6607842, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13536.286354064941, \"count\": 1, \"min\": 13536.286354064941, \"max\": 13536.286354064941}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:29 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.8816662670539 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:29 INFO 139780359198336] #progress_metric: host=algo-1, completed 58.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:29 INFO 139780359198336] #quality_metric: host=algo-1, epoch=231, train loss <loss>=2.3866493701934814\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:29 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:33 INFO 139780359198336] Epoch[232] Batch[0] avg_epoch_loss=2.570422\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:33 INFO 139780359198336] #quality_metric: host=algo-1, epoch=232, batch=0 train loss <loss>=2.5704216957092285\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:39 INFO 139780359198336] Epoch[232] Batch[5] avg_epoch_loss=2.482145\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:39 INFO 139780359198336] #quality_metric: host=algo-1, epoch=232, batch=5 train loss <loss>=2.482144912083944\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:39 INFO 139780359198336] Epoch[232] Batch [5]#011Speed: 61.53 samples/sec#011loss=2.482145\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:43 INFO 139780359198336] processed a total of 584 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527609.660866, \"EndTime\": 1617527623.1866198, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13525.259017944336, \"count\": 1, \"min\": 13525.259017944336, \"max\": 13525.259017944336}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:43 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.17801476889147 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:43 INFO 139780359198336] #progress_metric: host=algo-1, completed 58.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:43 INFO 139780359198336] #quality_metric: host=algo-1, epoch=232, train loss <loss>=2.5211528301239015\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:43 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:47 INFO 139780359198336] Epoch[233] Batch[0] avg_epoch_loss=2.528424\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:47 INFO 139780359198336] #quality_metric: host=algo-1, epoch=233, batch=0 train loss <loss>=2.528423547744751\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:13:52 INFO 139780359198336] Epoch[233] Batch[5] avg_epoch_loss=2.492747\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:52 INFO 139780359198336] #quality_metric: host=algo-1, epoch=233, batch=5 train loss <loss>=2.4927470684051514\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:52 INFO 139780359198336] Epoch[233] Batch [5]#011Speed: 62.36 samples/sec#011loss=2.492747\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:56 INFO 139780359198336] processed a total of 595 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527623.1867273, \"EndTime\": 1617527636.6575534, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13470.433950424194, \"count\": 1, \"min\": 13470.433950424194, \"max\": 13470.433950424194}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:56 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.17047307014671 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:56 INFO 139780359198336] #progress_metric: host=algo-1, completed 58.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:56 INFO 139780359198336] #quality_metric: host=algo-1, epoch=233, train loss <loss>=2.5384019136428835\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:13:56 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:00 INFO 139780359198336] Epoch[234] Batch[0] avg_epoch_loss=2.536230\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:00 INFO 139780359198336] #quality_metric: host=algo-1, epoch=234, batch=0 train loss <loss>=2.5362303256988525\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:06 INFO 139780359198336] Epoch[234] Batch[5] avg_epoch_loss=2.495032\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:06 INFO 139780359198336] #quality_metric: host=algo-1, epoch=234, batch=5 train loss <loss>=2.4950318733851113\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:06 INFO 139780359198336] Epoch[234] Batch [5]#011Speed: 53.41 samples/sec#011loss=2.495032\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:11 INFO 139780359198336] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527636.6576257, \"EndTime\": 1617527651.0876882, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14429.58402633667, \"count\": 1, \"min\": 14429.58402633667, \"max\": 14429.58402633667}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:11 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.10552390620557 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:11 INFO 139780359198336] #progress_metric: host=algo-1, completed 58.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:11 INFO 139780359198336] #quality_metric: host=algo-1, epoch=234, train loss <loss>=2.506585216522217\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:11 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:15 INFO 139780359198336] Epoch[235] Batch[0] avg_epoch_loss=2.510577\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:15 INFO 139780359198336] #quality_metric: host=algo-1, epoch=235, batch=0 train loss <loss>=2.510577440261841\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:20 INFO 139780359198336] Epoch[235] Batch[5] avg_epoch_loss=2.466882\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:20 INFO 139780359198336] #quality_metric: host=algo-1, epoch=235, batch=5 train loss <loss>=2.4668822288513184\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:20 INFO 139780359198336] Epoch[235] Batch [5]#011Speed: 62.38 samples/sec#011loss=2.466882\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:24 INFO 139780359198336] processed a total of 598 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527651.087771, \"EndTime\": 1617527664.6275275, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13539.23511505127, \"count\": 1, \"min\": 13539.23511505127, \"max\": 13539.23511505127}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:24 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.167538054094464 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:24 INFO 139780359198336] #progress_metric: host=algo-1, completed 59.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:24 INFO 139780359198336] #quality_metric: host=algo-1, epoch=235, train loss <loss>=2.448873782157898\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:24 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:28 INFO 139780359198336] Epoch[236] Batch[0] avg_epoch_loss=2.423481\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:28 INFO 139780359198336] #quality_metric: host=algo-1, epoch=236, batch=0 train loss <loss>=2.423480987548828\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:34 INFO 139780359198336] Epoch[236] Batch[5] avg_epoch_loss=2.473803\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:34 INFO 139780359198336] #quality_metric: host=algo-1, epoch=236, batch=5 train loss <loss>=2.473803440729777\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:34 INFO 139780359198336] Epoch[236] Batch [5]#011Speed: 62.40 samples/sec#011loss=2.473803\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:39 INFO 139780359198336] Epoch[236] Batch[10] avg_epoch_loss=2.482316\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:39 INFO 139780359198336] #quality_metric: host=algo-1, epoch=236, batch=10 train loss <loss>=2.4925318717956544\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:39 INFO 139780359198336] Epoch[236] Batch [10]#011Speed: 59.89 samples/sec#011loss=2.492532\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:39 INFO 139780359198336] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527664.6276078, \"EndTime\": 1617527679.3547873, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14726.71389579773, \"count\": 1, \"min\": 14726.71389579773, \"max\": 14726.71389579773}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:39 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.27302041921437 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:39 INFO 139780359198336] #progress_metric: host=algo-1, completed 59.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:39 INFO 139780359198336] #quality_metric: host=algo-1, epoch=236, train loss <loss>=2.4823163639415395\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:39 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:43 INFO 139780359198336] Epoch[237] Batch[0] avg_epoch_loss=2.578489\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:43 INFO 139780359198336] #quality_metric: host=algo-1, epoch=237, batch=0 train loss <loss>=2.57848858833313\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:48 INFO 139780359198336] Epoch[237] Batch[5] avg_epoch_loss=2.506594\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:48 INFO 139780359198336] #quality_metric: host=algo-1, epoch=237, batch=5 train loss <loss>=2.506594260533651\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:48 INFO 139780359198336] Epoch[237] Batch [5]#011Speed: 63.29 samples/sec#011loss=2.506594\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:53 INFO 139780359198336] Epoch[237] Batch[10] avg_epoch_loss=2.481668\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:53 INFO 139780359198336] #quality_metric: host=algo-1, epoch=237, batch=10 train loss <loss>=2.451756000518799\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:53 INFO 139780359198336] Epoch[237] Batch [10]#011Speed: 61.07 samples/sec#011loss=2.451756\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:53 INFO 139780359198336] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527679.3548465, \"EndTime\": 1617527693.8220825, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14466.744422912598, \"count\": 1, \"min\": 14466.744422912598, \"max\": 14466.744422912598}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:53 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.37734034104034 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:53 INFO 139780359198336] #progress_metric: host=algo-1, completed 59.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:53 INFO 139780359198336] #quality_metric: host=algo-1, epoch=237, train loss <loss>=2.4816677787087182\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:53 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:58 INFO 139780359198336] Epoch[238] Batch[0] avg_epoch_loss=2.483849\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:14:58 INFO 139780359198336] #quality_metric: host=algo-1, epoch=238, batch=0 train loss <loss>=2.483848810195923\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:03 INFO 139780359198336] Epoch[238] Batch[5] avg_epoch_loss=2.487540\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:03 INFO 139780359198336] #quality_metric: host=algo-1, epoch=238, batch=5 train loss <loss>=2.487540364265442\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:03 INFO 139780359198336] Epoch[238] Batch [5]#011Speed: 60.19 samples/sec#011loss=2.487540\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:08 INFO 139780359198336] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527693.8221483, \"EndTime\": 1617527708.2560124, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14433.51149559021, \"count\": 1, \"min\": 14433.51149559021, \"max\": 14433.51149559021}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:08 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.20234299515352 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:08 INFO 139780359198336] #progress_metric: host=algo-1, completed 59.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:08 INFO 139780359198336] #quality_metric: host=algo-1, epoch=238, train loss <loss>=2.497720646858215\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:08 INFO 139780359198336] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:15:12 INFO 139780359198336] Epoch[239] Batch[0] avg_epoch_loss=2.501789\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:12 INFO 139780359198336] #quality_metric: host=algo-1, epoch=239, batch=0 train loss <loss>=2.501788854598999\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:17 INFO 139780359198336] Epoch[239] Batch[5] avg_epoch_loss=2.453185\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:17 INFO 139780359198336] #quality_metric: host=algo-1, epoch=239, batch=5 train loss <loss>=2.4531853199005127\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:17 INFO 139780359198336] Epoch[239] Batch [5]#011Speed: 62.68 samples/sec#011loss=2.453185\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:22 INFO 139780359198336] Epoch[239] Batch[10] avg_epoch_loss=2.429800\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:22 INFO 139780359198336] #quality_metric: host=algo-1, epoch=239, batch=10 train loss <loss>=2.4017380714416503\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:22 INFO 139780359198336] Epoch[239] Batch [10]#011Speed: 58.81 samples/sec#011loss=2.401738\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:22 INFO 139780359198336] processed a total of 678 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527708.2560918, \"EndTime\": 1617527722.8145304, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14558.003187179565, \"count\": 1, \"min\": 14558.003187179565, \"max\": 14558.003187179565}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:22 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.57198023397468 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:22 INFO 139780359198336] #progress_metric: host=algo-1, completed 60.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:22 INFO 139780359198336] #quality_metric: host=algo-1, epoch=239, train loss <loss>=2.429800206964666\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:22 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:26 INFO 139780359198336] Epoch[240] Batch[0] avg_epoch_loss=2.532475\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:26 INFO 139780359198336] #quality_metric: host=algo-1, epoch=240, batch=0 train loss <loss>=2.532475233078003\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:32 INFO 139780359198336] Epoch[240] Batch[5] avg_epoch_loss=2.515921\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:32 INFO 139780359198336] #quality_metric: host=algo-1, epoch=240, batch=5 train loss <loss>=2.5159205198287964\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:32 INFO 139780359198336] Epoch[240] Batch [5]#011Speed: 62.29 samples/sec#011loss=2.515921\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:37 INFO 139780359198336] Epoch[240] Batch[10] avg_epoch_loss=2.482188\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:37 INFO 139780359198336] #quality_metric: host=algo-1, epoch=240, batch=10 train loss <loss>=2.4417083263397217\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:37 INFO 139780359198336] Epoch[240] Batch [10]#011Speed: 60.29 samples/sec#011loss=2.441708\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:37 INFO 139780359198336] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527722.8146067, \"EndTime\": 1617527737.4417286, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14626.807451248169, \"count\": 1, \"min\": 14626.807451248169, \"max\": 14626.807451248169}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:37 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.780306549607054 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:37 INFO 139780359198336] #progress_metric: host=algo-1, completed 60.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:37 INFO 139780359198336] #quality_metric: host=algo-1, epoch=240, train loss <loss>=2.4821877046064897\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:37 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:41 INFO 139780359198336] Epoch[241] Batch[0] avg_epoch_loss=2.539993\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:41 INFO 139780359198336] #quality_metric: host=algo-1, epoch=241, batch=0 train loss <loss>=2.539992570877075\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:46 INFO 139780359198336] Epoch[241] Batch[5] avg_epoch_loss=2.464784\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:46 INFO 139780359198336] #quality_metric: host=algo-1, epoch=241, batch=5 train loss <loss>=2.4647840658823648\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:46 INFO 139780359198336] Epoch[241] Batch [5]#011Speed: 60.96 samples/sec#011loss=2.464784\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:52 INFO 139780359198336] Epoch[241] Batch[10] avg_epoch_loss=2.510164\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:52 INFO 139780359198336] #quality_metric: host=algo-1, epoch=241, batch=10 train loss <loss>=2.564621019363403\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:52 INFO 139780359198336] Epoch[241] Batch [10]#011Speed: 60.04 samples/sec#011loss=2.564621\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:52 INFO 139780359198336] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527737.441849, \"EndTime\": 1617527752.3003519, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14857.982635498047, \"count\": 1, \"min\": 14857.982635498047, \"max\": 14857.982635498047}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:52 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.62217991110043 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:52 INFO 139780359198336] #progress_metric: host=algo-1, completed 60.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:52 INFO 139780359198336] #quality_metric: host=algo-1, epoch=241, train loss <loss>=2.510164499282837\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:52 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:56 INFO 139780359198336] Epoch[242] Batch[0] avg_epoch_loss=2.569352\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:15:56 INFO 139780359198336] #quality_metric: host=algo-1, epoch=242, batch=0 train loss <loss>=2.5693519115448\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:01 INFO 139780359198336] Epoch[242] Batch[5] avg_epoch_loss=2.496253\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:01 INFO 139780359198336] #quality_metric: host=algo-1, epoch=242, batch=5 train loss <loss>=2.496253172556559\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:01 INFO 139780359198336] Epoch[242] Batch [5]#011Speed: 62.22 samples/sec#011loss=2.496253\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:07 INFO 139780359198336] Epoch[242] Batch[10] avg_epoch_loss=2.599055\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:07 INFO 139780359198336] #quality_metric: host=algo-1, epoch=242, batch=10 train loss <loss>=2.722418212890625\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:07 INFO 139780359198336] Epoch[242] Batch [10]#011Speed: 52.30 samples/sec#011loss=2.722418\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:07 INFO 139780359198336] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527752.3004203, \"EndTime\": 1617527767.753532, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 15452.676057815552, \"count\": 1, \"min\": 15452.676057815552, \"max\": 15452.676057815552}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:07 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=42.12836468235026 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:07 INFO 139780359198336] #progress_metric: host=algo-1, completed 60.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:07 INFO 139780359198336] #quality_metric: host=algo-1, epoch=242, train loss <loss>=2.599055463617498\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:07 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:12 INFO 139780359198336] Epoch[243] Batch[0] avg_epoch_loss=2.442228\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:12 INFO 139780359198336] #quality_metric: host=algo-1, epoch=243, batch=0 train loss <loss>=2.442228078842163\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:17 INFO 139780359198336] Epoch[243] Batch[5] avg_epoch_loss=2.451238\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:17 INFO 139780359198336] #quality_metric: host=algo-1, epoch=243, batch=5 train loss <loss>=2.4512378772099814\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:17 INFO 139780359198336] Epoch[243] Batch [5]#011Speed: 62.12 samples/sec#011loss=2.451238\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:22 INFO 139780359198336] Epoch[243] Batch[10] avg_epoch_loss=2.400165\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:22 INFO 139780359198336] #quality_metric: host=algo-1, epoch=243, batch=10 train loss <loss>=2.3388771533966066\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:22 INFO 139780359198336] Epoch[243] Batch [10]#011Speed: 59.64 samples/sec#011loss=2.338877\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:22 INFO 139780359198336] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527767.753598, \"EndTime\": 1617527782.5199735, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14766.070365905762, \"count\": 1, \"min\": 14766.070365905762, \"max\": 14766.070365905762}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:22 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.425857610480655 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:22 INFO 139780359198336] #progress_metric: host=algo-1, completed 61.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:22 INFO 139780359198336] #quality_metric: host=algo-1, epoch=243, train loss <loss>=2.4001648209311743\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:22 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:26 INFO 139780359198336] Epoch[244] Batch[0] avg_epoch_loss=2.504877\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:26 INFO 139780359198336] #quality_metric: host=algo-1, epoch=244, batch=0 train loss <loss>=2.5048773288726807\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:16:31 INFO 139780359198336] Epoch[244] Batch[5] avg_epoch_loss=2.473665\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:31 INFO 139780359198336] #quality_metric: host=algo-1, epoch=244, batch=5 train loss <loss>=2.4736653566360474\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:31 INFO 139780359198336] Epoch[244] Batch [5]#011Speed: 61.99 samples/sec#011loss=2.473665\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:37 INFO 139780359198336] Epoch[244] Batch[10] avg_epoch_loss=2.542590\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:37 INFO 139780359198336] #quality_metric: host=algo-1, epoch=244, batch=10 train loss <loss>=2.625298833847046\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:37 INFO 139780359198336] Epoch[244] Batch [10]#011Speed: 60.62 samples/sec#011loss=2.625299\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:37 INFO 139780359198336] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527782.5200434, \"EndTime\": 1617527797.1803794, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14659.944534301758, \"count\": 1, \"min\": 14659.944534301758, \"max\": 14659.944534301758}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:37 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.611047342381944 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:37 INFO 139780359198336] #progress_metric: host=algo-1, completed 61.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:37 INFO 139780359198336] #quality_metric: host=algo-1, epoch=244, train loss <loss>=2.5425896644592285\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:37 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:41 INFO 139780359198336] Epoch[245] Batch[0] avg_epoch_loss=2.477072\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:41 INFO 139780359198336] #quality_metric: host=algo-1, epoch=245, batch=0 train loss <loss>=2.477071762084961\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:46 INFO 139780359198336] Epoch[245] Batch[5] avg_epoch_loss=2.495180\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:46 INFO 139780359198336] #quality_metric: host=algo-1, epoch=245, batch=5 train loss <loss>=2.495180130004883\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:46 INFO 139780359198336] Epoch[245] Batch [5]#011Speed: 62.53 samples/sec#011loss=2.495180\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:50 INFO 139780359198336] processed a total of 605 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527797.1804454, \"EndTime\": 1617527810.7454967, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13564.61215019226, \"count\": 1, \"min\": 13564.61215019226, \"max\": 13564.61215019226}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:50 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.60101343652778 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:50 INFO 139780359198336] #progress_metric: host=algo-1, completed 61.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:50 INFO 139780359198336] #quality_metric: host=algo-1, epoch=245, train loss <loss>=2.5416505336761475\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:50 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:54 INFO 139780359198336] Epoch[246] Batch[0] avg_epoch_loss=2.565353\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:54 INFO 139780359198336] #quality_metric: host=algo-1, epoch=246, batch=0 train loss <loss>=2.56535267829895\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:59 INFO 139780359198336] Epoch[246] Batch[5] avg_epoch_loss=2.493238\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:59 INFO 139780359198336] #quality_metric: host=algo-1, epoch=246, batch=5 train loss <loss>=2.4932380517323813\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:16:59 INFO 139780359198336] Epoch[246] Batch [5]#011Speed: 62.67 samples/sec#011loss=2.493238\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:05 INFO 139780359198336] Epoch[246] Batch[10] avg_epoch_loss=2.588251\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:05 INFO 139780359198336] #quality_metric: host=algo-1, epoch=246, batch=10 train loss <loss>=2.7022661685943605\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:05 INFO 139780359198336] Epoch[246] Batch [10]#011Speed: 53.51 samples/sec#011loss=2.702266\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:05 INFO 139780359198336] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527810.7455678, \"EndTime\": 1617527825.9594183, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 15213.310718536377, \"count\": 1, \"min\": 15213.310718536377, \"max\": 15213.310718536377}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:05 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.25132216272531 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:05 INFO 139780359198336] #progress_metric: host=algo-1, completed 61.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:05 INFO 139780359198336] #quality_metric: host=algo-1, epoch=246, train loss <loss>=2.58825083212419\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:05 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:10 INFO 139780359198336] Epoch[247] Batch[0] avg_epoch_loss=2.601989\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:10 INFO 139780359198336] #quality_metric: host=algo-1, epoch=247, batch=0 train loss <loss>=2.6019885540008545\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:15 INFO 139780359198336] Epoch[247] Batch[5] avg_epoch_loss=2.491080\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:15 INFO 139780359198336] #quality_metric: host=algo-1, epoch=247, batch=5 train loss <loss>=2.4910799264907837\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:15 INFO 139780359198336] Epoch[247] Batch [5]#011Speed: 60.02 samples/sec#011loss=2.491080\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:20 INFO 139780359198336] Epoch[247] Batch[10] avg_epoch_loss=2.436361\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:20 INFO 139780359198336] #quality_metric: host=algo-1, epoch=247, batch=10 train loss <loss>=2.3706986904144287\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:20 INFO 139780359198336] Epoch[247] Batch [10]#011Speed: 58.80 samples/sec#011loss=2.370699\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:20 INFO 139780359198336] processed a total of 676 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527825.9594827, \"EndTime\": 1617527840.987552, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 15027.666091918945, \"count\": 1, \"min\": 15027.666091918945, \"max\": 15027.666091918945}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:20 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.98339229080331 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:20 INFO 139780359198336] #progress_metric: host=algo-1, completed 62.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:20 INFO 139780359198336] #quality_metric: host=algo-1, epoch=247, train loss <loss>=2.4363611828197134\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:20 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:25 INFO 139780359198336] Epoch[248] Batch[0] avg_epoch_loss=2.439289\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:25 INFO 139780359198336] #quality_metric: host=algo-1, epoch=248, batch=0 train loss <loss>=2.43928861618042\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:30 INFO 139780359198336] Epoch[248] Batch[5] avg_epoch_loss=2.469338\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:30 INFO 139780359198336] #quality_metric: host=algo-1, epoch=248, batch=5 train loss <loss>=2.4693382581075034\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:30 INFO 139780359198336] Epoch[248] Batch [5]#011Speed: 62.78 samples/sec#011loss=2.469338\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:35 INFO 139780359198336] Epoch[248] Batch[10] avg_epoch_loss=2.462259\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:35 INFO 139780359198336] #quality_metric: host=algo-1, epoch=248, batch=10 train loss <loss>=2.4537649631500242\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:35 INFO 139780359198336] Epoch[248] Batch [10]#011Speed: 60.89 samples/sec#011loss=2.453765\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:35 INFO 139780359198336] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527840.9876208, \"EndTime\": 1617527855.5292895, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14541.301965713501, \"count\": 1, \"min\": 14541.301965713501, \"max\": 14541.301965713501}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:35 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.9377548393562 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:35 INFO 139780359198336] #progress_metric: host=algo-1, completed 62.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:35 INFO 139780359198336] #quality_metric: host=algo-1, epoch=248, train loss <loss>=2.4622594876722856\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:35 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:39 INFO 139780359198336] Epoch[249] Batch[0] avg_epoch_loss=2.374759\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:39 INFO 139780359198336] #quality_metric: host=algo-1, epoch=249, batch=0 train loss <loss>=2.374758720397949\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:17:44 INFO 139780359198336] Epoch[249] Batch[5] avg_epoch_loss=2.472053\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:44 INFO 139780359198336] #quality_metric: host=algo-1, epoch=249, batch=5 train loss <loss>=2.4720534880956015\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:44 INFO 139780359198336] Epoch[249] Batch [5]#011Speed: 61.09 samples/sec#011loss=2.472053\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:49 INFO 139780359198336] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527855.5293667, \"EndTime\": 1617527869.094242, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13564.393758773804, \"count\": 1, \"min\": 13564.393758773804, \"max\": 13564.393758773804}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:49 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.70755636356644 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:49 INFO 139780359198336] #progress_metric: host=algo-1, completed 62.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:49 INFO 139780359198336] #quality_metric: host=algo-1, epoch=249, train loss <loss>=2.510088300704956\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:49 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:53 INFO 139780359198336] Epoch[250] Batch[0] avg_epoch_loss=2.536089\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:53 INFO 139780359198336] #quality_metric: host=algo-1, epoch=250, batch=0 train loss <loss>=2.5360889434814453\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:58 INFO 139780359198336] Epoch[250] Batch[5] avg_epoch_loss=2.480438\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:58 INFO 139780359198336] #quality_metric: host=algo-1, epoch=250, batch=5 train loss <loss>=2.4804380337397256\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:17:58 INFO 139780359198336] Epoch[250] Batch [5]#011Speed: 63.03 samples/sec#011loss=2.480438\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:03 INFO 139780359198336] Epoch[250] Batch[10] avg_epoch_loss=2.497245\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:03 INFO 139780359198336] #quality_metric: host=algo-1, epoch=250, batch=10 train loss <loss>=2.5174129486083983\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:03 INFO 139780359198336] Epoch[250] Batch [10]#011Speed: 56.24 samples/sec#011loss=2.517413\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:03 INFO 139780359198336] processed a total of 678 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527869.0943146, \"EndTime\": 1617527883.8884661, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14793.658018112183, \"count\": 1, \"min\": 14793.658018112183, \"max\": 14793.658018112183}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:03 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.82979384024689 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:03 INFO 139780359198336] #progress_metric: host=algo-1, completed 62.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:03 INFO 139780359198336] #quality_metric: host=algo-1, epoch=250, train loss <loss>=2.497244813225486\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:03 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:08 INFO 139780359198336] Epoch[251] Batch[0] avg_epoch_loss=2.346584\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:08 INFO 139780359198336] #quality_metric: host=algo-1, epoch=251, batch=0 train loss <loss>=2.3465843200683594\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:13 INFO 139780359198336] Epoch[251] Batch[5] avg_epoch_loss=2.465553\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:13 INFO 139780359198336] #quality_metric: host=algo-1, epoch=251, batch=5 train loss <loss>=2.465552727381388\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:13 INFO 139780359198336] Epoch[251] Batch [5]#011Speed: 62.00 samples/sec#011loss=2.465553\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:17 INFO 139780359198336] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527883.8885515, \"EndTime\": 1617527897.640817, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13751.517295837402, \"count\": 1, \"min\": 13751.517295837402, \"max\": 13751.517295837402}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:17 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.012878305121625 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:17 INFO 139780359198336] #progress_metric: host=algo-1, completed 63.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:17 INFO 139780359198336] #quality_metric: host=algo-1, epoch=251, train loss <loss>=2.5170296669006347\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:17 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:21 INFO 139780359198336] Epoch[252] Batch[0] avg_epoch_loss=2.344372\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:21 INFO 139780359198336] #quality_metric: host=algo-1, epoch=252, batch=0 train loss <loss>=2.344372034072876\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:26 INFO 139780359198336] Epoch[252] Batch[5] avg_epoch_loss=2.477716\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:26 INFO 139780359198336] #quality_metric: host=algo-1, epoch=252, batch=5 train loss <loss>=2.477715531984965\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:26 INFO 139780359198336] Epoch[252] Batch [5]#011Speed: 62.83 samples/sec#011loss=2.477716\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:32 INFO 139780359198336] Epoch[252] Batch[10] avg_epoch_loss=2.468801\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:32 INFO 139780359198336] #quality_metric: host=algo-1, epoch=252, batch=10 train loss <loss>=2.4581030368804933\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:32 INFO 139780359198336] Epoch[252] Batch [10]#011Speed: 58.55 samples/sec#011loss=2.458103\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:32 INFO 139780359198336] processed a total of 691 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527897.6408877, \"EndTime\": 1617527912.1844919, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14543.0428981781, \"count\": 1, \"min\": 14543.0428981781, \"max\": 14543.0428981781}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:32 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=47.51378592304301 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:32 INFO 139780359198336] #progress_metric: host=algo-1, completed 63.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:32 INFO 139780359198336] #quality_metric: host=algo-1, epoch=252, train loss <loss>=2.468800761482932\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:32 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:36 INFO 139780359198336] Epoch[253] Batch[0] avg_epoch_loss=2.434721\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:36 INFO 139780359198336] #quality_metric: host=algo-1, epoch=253, batch=0 train loss <loss>=2.4347212314605713\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:41 INFO 139780359198336] Epoch[253] Batch[5] avg_epoch_loss=2.486686\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:41 INFO 139780359198336] #quality_metric: host=algo-1, epoch=253, batch=5 train loss <loss>=2.4866859118143716\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:41 INFO 139780359198336] Epoch[253] Batch [5]#011Speed: 62.09 samples/sec#011loss=2.486686\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:46 INFO 139780359198336] Epoch[253] Batch[10] avg_epoch_loss=2.445620\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:46 INFO 139780359198336] #quality_metric: host=algo-1, epoch=253, batch=10 train loss <loss>=2.3963409423828126\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:46 INFO 139780359198336] Epoch[253] Batch [10]#011Speed: 58.46 samples/sec#011loss=2.396341\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:46 INFO 139780359198336] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527912.1845632, \"EndTime\": 1617527926.9342232, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14749.23300743103, \"count\": 1, \"min\": 14749.23300743103, \"max\": 14749.23300743103}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:46 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.88338223613457 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:46 INFO 139780359198336] #progress_metric: host=algo-1, completed 63.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:46 INFO 139780359198336] #quality_metric: host=algo-1, epoch=253, train loss <loss>=2.4456200166182085\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:46 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:51 INFO 139780359198336] Epoch[254] Batch[0] avg_epoch_loss=2.419189\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:51 INFO 139780359198336] #quality_metric: host=algo-1, epoch=254, batch=0 train loss <loss>=2.419189453125\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:56 INFO 139780359198336] Epoch[254] Batch[5] avg_epoch_loss=2.545942\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:56 INFO 139780359198336] #quality_metric: host=algo-1, epoch=254, batch=5 train loss <loss>=2.545942028363546\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:18:56 INFO 139780359198336] Epoch[254] Batch [5]#011Speed: 62.62 samples/sec#011loss=2.545942\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:00 INFO 139780359198336] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527926.9342906, \"EndTime\": 1617527940.4597282, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13525.029182434082, \"count\": 1, \"min\": 13525.029182434082, \"max\": 13525.029182434082}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:00 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=47.24531351428676 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:00 INFO 139780359198336] #progress_metric: host=algo-1, completed 63.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:00 INFO 139780359198336] #quality_metric: host=algo-1, epoch=254, train loss <loss>=2.52526912689209\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:00 INFO 139780359198336] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:19:05 INFO 139780359198336] Epoch[255] Batch[0] avg_epoch_loss=2.491647\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:05 INFO 139780359198336] #quality_metric: host=algo-1, epoch=255, batch=0 train loss <loss>=2.491647481918335\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:10 INFO 139780359198336] Epoch[255] Batch[5] avg_epoch_loss=2.455153\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:10 INFO 139780359198336] #quality_metric: host=algo-1, epoch=255, batch=5 train loss <loss>=2.4551527897516885\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:10 INFO 139780359198336] Epoch[255] Batch [5]#011Speed: 57.86 samples/sec#011loss=2.455153\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:15 INFO 139780359198336] Epoch[255] Batch[10] avg_epoch_loss=2.421415\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:15 INFO 139780359198336] #quality_metric: host=algo-1, epoch=255, batch=10 train loss <loss>=2.380929183959961\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:15 INFO 139780359198336] Epoch[255] Batch [10]#011Speed: 60.33 samples/sec#011loss=2.380929\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:15 INFO 139780359198336] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527940.4598172, \"EndTime\": 1617527955.8451824, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 15384.70721244812, \"count\": 1, \"min\": 15384.70721244812, \"max\": 15384.70721244812}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:15 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=41.66443815693327 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:15 INFO 139780359198336] #progress_metric: host=algo-1, completed 64.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:15 INFO 139780359198336] #quality_metric: host=algo-1, epoch=255, train loss <loss>=2.421414787119085\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:15 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:19 INFO 139780359198336] Epoch[256] Batch[0] avg_epoch_loss=2.376272\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:19 INFO 139780359198336] #quality_metric: host=algo-1, epoch=256, batch=0 train loss <loss>=2.376272439956665\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:24 INFO 139780359198336] Epoch[256] Batch[5] avg_epoch_loss=2.515575\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:24 INFO 139780359198336] #quality_metric: host=algo-1, epoch=256, batch=5 train loss <loss>=2.515575408935547\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:24 INFO 139780359198336] Epoch[256] Batch [5]#011Speed: 62.82 samples/sec#011loss=2.515575\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:30 INFO 139780359198336] Epoch[256] Batch[10] avg_epoch_loss=2.487782\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:30 INFO 139780359198336] #quality_metric: host=algo-1, epoch=256, batch=10 train loss <loss>=2.4544297218322755\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:30 INFO 139780359198336] Epoch[256] Batch [10]#011Speed: 58.92 samples/sec#011loss=2.454430\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:30 INFO 139780359198336] processed a total of 679 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527955.8452656, \"EndTime\": 1617527970.383423, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14537.736177444458, \"count\": 1, \"min\": 14537.736177444458, \"max\": 14537.736177444458}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:30 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.70570308699716 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:30 INFO 139780359198336] #progress_metric: host=algo-1, completed 64.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:30 INFO 139780359198336] #quality_metric: host=algo-1, epoch=256, train loss <loss>=2.4877819147976963\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:30 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:34 INFO 139780359198336] Epoch[257] Batch[0] avg_epoch_loss=2.516270\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:34 INFO 139780359198336] #quality_metric: host=algo-1, epoch=257, batch=0 train loss <loss>=2.5162696838378906\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:39 INFO 139780359198336] Epoch[257] Batch[5] avg_epoch_loss=2.469003\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:39 INFO 139780359198336] #quality_metric: host=algo-1, epoch=257, batch=5 train loss <loss>=2.469002683957418\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:39 INFO 139780359198336] Epoch[257] Batch [5]#011Speed: 62.22 samples/sec#011loss=2.469003\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:45 INFO 139780359198336] Epoch[257] Batch[10] avg_epoch_loss=2.471234\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:45 INFO 139780359198336] #quality_metric: host=algo-1, epoch=257, batch=10 train loss <loss>=2.473911905288696\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:45 INFO 139780359198336] Epoch[257] Batch [10]#011Speed: 59.50 samples/sec#011loss=2.473912\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:45 INFO 139780359198336] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527970.3834944, \"EndTime\": 1617527985.0754218, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14691.58387184143, \"count\": 1, \"min\": 14691.58387184143, \"max\": 14691.58387184143}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:45 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.76620889591133 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:45 INFO 139780359198336] #progress_metric: host=algo-1, completed 64.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:45 INFO 139780359198336] #quality_metric: host=algo-1, epoch=257, train loss <loss>=2.471234148198908\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:45 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:49 INFO 139780359198336] Epoch[258] Batch[0] avg_epoch_loss=2.482118\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:49 INFO 139780359198336] #quality_metric: host=algo-1, epoch=258, batch=0 train loss <loss>=2.4821178913116455\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:54 INFO 139780359198336] Epoch[258] Batch[5] avg_epoch_loss=2.448153\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:54 INFO 139780359198336] #quality_metric: host=algo-1, epoch=258, batch=5 train loss <loss>=2.4481533765792847\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:54 INFO 139780359198336] Epoch[258] Batch [5]#011Speed: 62.79 samples/sec#011loss=2.448153\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:59 INFO 139780359198336] Epoch[258] Batch[10] avg_epoch_loss=2.468380\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:59 INFO 139780359198336] #quality_metric: host=algo-1, epoch=258, batch=10 train loss <loss>=2.4926515102386473\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:59 INFO 139780359198336] Epoch[258] Batch [10]#011Speed: 58.65 samples/sec#011loss=2.492652\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:59 INFO 139780359198336] processed a total of 702 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527985.0755026, \"EndTime\": 1617527999.6437168, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14567.760944366455, \"count\": 1, \"min\": 14567.760944366455, \"max\": 14567.760944366455}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:59 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=48.188221887049146 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:59 INFO 139780359198336] #progress_metric: host=algo-1, completed 64.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:59 INFO 139780359198336] #quality_metric: host=algo-1, epoch=258, train loss <loss>=2.4683798009699043\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:19:59 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:04 INFO 139780359198336] Epoch[259] Batch[0] avg_epoch_loss=2.383761\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:04 INFO 139780359198336] #quality_metric: host=algo-1, epoch=259, batch=0 train loss <loss>=2.383760690689087\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:09 INFO 139780359198336] Epoch[259] Batch[5] avg_epoch_loss=2.440465\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:09 INFO 139780359198336] #quality_metric: host=algo-1, epoch=259, batch=5 train loss <loss>=2.440465251604716\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:09 INFO 139780359198336] Epoch[259] Batch [5]#011Speed: 56.39 samples/sec#011loss=2.440465\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:13 INFO 139780359198336] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617527999.643795, \"EndTime\": 1617528013.89982, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14255.521535873413, \"count\": 1, \"min\": 14255.521535873413, \"max\": 14255.521535873413}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:13 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.33320512918501 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:13 INFO 139780359198336] #progress_metric: host=algo-1, completed 65.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:13 INFO 139780359198336] #quality_metric: host=algo-1, epoch=259, train loss <loss>=2.4683055877685547\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:13 INFO 139780359198336] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:20:18 INFO 139780359198336] Epoch[260] Batch[0] avg_epoch_loss=2.528753\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:18 INFO 139780359198336] #quality_metric: host=algo-1, epoch=260, batch=0 train loss <loss>=2.5287530422210693\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:23 INFO 139780359198336] Epoch[260] Batch[5] avg_epoch_loss=2.480491\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:23 INFO 139780359198336] #quality_metric: host=algo-1, epoch=260, batch=5 train loss <loss>=2.4804908434549966\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:23 INFO 139780359198336] Epoch[260] Batch [5]#011Speed: 61.94 samples/sec#011loss=2.480491\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:27 INFO 139780359198336] processed a total of 612 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528013.8999343, \"EndTime\": 1617528027.5008595, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13600.287437438965, \"count\": 1, \"min\": 13600.287437438965, \"max\": 13600.287437438965}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:27 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.99869790408961 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:27 INFO 139780359198336] #progress_metric: host=algo-1, completed 65.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:27 INFO 139780359198336] #quality_metric: host=algo-1, epoch=260, train loss <loss>=2.5105210065841677\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:27 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:31 INFO 139780359198336] Epoch[261] Batch[0] avg_epoch_loss=2.551963\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:31 INFO 139780359198336] #quality_metric: host=algo-1, epoch=261, batch=0 train loss <loss>=2.5519626140594482\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:36 INFO 139780359198336] Epoch[261] Batch[5] avg_epoch_loss=2.487667\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:36 INFO 139780359198336] #quality_metric: host=algo-1, epoch=261, batch=5 train loss <loss>=2.4876672824223838\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:36 INFO 139780359198336] Epoch[261] Batch [5]#011Speed: 62.48 samples/sec#011loss=2.487667\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:42 INFO 139780359198336] Epoch[261] Batch[10] avg_epoch_loss=2.400380\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:42 INFO 139780359198336] #quality_metric: host=algo-1, epoch=261, batch=10 train loss <loss>=2.2956343412399294\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:42 INFO 139780359198336] Epoch[261] Batch [10]#011Speed: 60.50 samples/sec#011loss=2.295634\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:42 INFO 139780359198336] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528027.5009294, \"EndTime\": 1617528042.1099555, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14608.522176742554, \"count\": 1, \"min\": 14608.522176742554, \"max\": 14608.522176742554}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:42 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.357320659575294 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:42 INFO 139780359198336] #progress_metric: host=algo-1, completed 65.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:42 INFO 139780359198336] #quality_metric: host=algo-1, epoch=261, train loss <loss>=2.4003795818849043\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:42 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:46 INFO 139780359198336] Epoch[262] Batch[0] avg_epoch_loss=2.461783\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:46 INFO 139780359198336] #quality_metric: host=algo-1, epoch=262, batch=0 train loss <loss>=2.4617831707000732\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:51 INFO 139780359198336] Epoch[262] Batch[5] avg_epoch_loss=2.420116\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:51 INFO 139780359198336] #quality_metric: host=algo-1, epoch=262, batch=5 train loss <loss>=2.4201156298319497\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:51 INFO 139780359198336] Epoch[262] Batch [5]#011Speed: 62.91 samples/sec#011loss=2.420116\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:55 INFO 139780359198336] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528042.1100385, \"EndTime\": 1617528055.5825005, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13472.078561782837, \"count\": 1, \"min\": 13472.078561782837, \"max\": 13472.078561782837}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:55 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=47.505245061416666 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:55 INFO 139780359198336] #progress_metric: host=algo-1, completed 65.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:55 INFO 139780359198336] #quality_metric: host=algo-1, epoch=262, train loss <loss>=2.445003795623779\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:55 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:59 INFO 139780359198336] Epoch[263] Batch[0] avg_epoch_loss=2.516606\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:20:59 INFO 139780359198336] #quality_metric: host=algo-1, epoch=263, batch=0 train loss <loss>=2.5166056156158447\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:05 INFO 139780359198336] Epoch[263] Batch[5] avg_epoch_loss=2.538350\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:05 INFO 139780359198336] #quality_metric: host=algo-1, epoch=263, batch=5 train loss <loss>=2.5383498271306357\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:05 INFO 139780359198336] Epoch[263] Batch [5]#011Speed: 57.57 samples/sec#011loss=2.538350\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:09 INFO 139780359198336] processed a total of 615 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528055.582582, \"EndTime\": 1617528069.9081504, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14325.074911117554, \"count\": 1, \"min\": 14325.074911117554, \"max\": 14325.074911117554}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:09 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=42.93135969010695 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:09 INFO 139780359198336] #progress_metric: host=algo-1, completed 66.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:09 INFO 139780359198336] #quality_metric: host=algo-1, epoch=263, train loss <loss>=2.5122499227523805\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:09 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:14 INFO 139780359198336] Epoch[264] Batch[0] avg_epoch_loss=2.498734\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:14 INFO 139780359198336] #quality_metric: host=algo-1, epoch=264, batch=0 train loss <loss>=2.4987339973449707\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:19 INFO 139780359198336] Epoch[264] Batch[5] avg_epoch_loss=2.471269\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:19 INFO 139780359198336] #quality_metric: host=algo-1, epoch=264, batch=5 train loss <loss>=2.4712687730789185\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:19 INFO 139780359198336] Epoch[264] Batch [5]#011Speed: 60.61 samples/sec#011loss=2.471269\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:23 INFO 139780359198336] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528069.9082353, \"EndTime\": 1617528083.620777, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13712.034940719604, \"count\": 1, \"min\": 13712.034940719604, \"max\": 13712.034940719604}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:23 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.236406887389876 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:23 INFO 139780359198336] #progress_metric: host=algo-1, completed 66.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:23 INFO 139780359198336] #quality_metric: host=algo-1, epoch=264, train loss <loss>=2.4692414522171022\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:23 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:27 INFO 139780359198336] Epoch[265] Batch[0] avg_epoch_loss=2.580976\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:27 INFO 139780359198336] #quality_metric: host=algo-1, epoch=265, batch=0 train loss <loss>=2.5809760093688965\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:32 INFO 139780359198336] Epoch[265] Batch[5] avg_epoch_loss=2.512479\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:32 INFO 139780359198336] #quality_metric: host=algo-1, epoch=265, batch=5 train loss <loss>=2.512479225794474\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:32 INFO 139780359198336] Epoch[265] Batch [5]#011Speed: 62.74 samples/sec#011loss=2.512479\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:37 INFO 139780359198336] processed a total of 609 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528083.620843, \"EndTime\": 1617528097.0405803, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13419.2533493042, \"count\": 1, \"min\": 13419.2533493042, \"max\": 13419.2533493042}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:37 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.38213306786036 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:37 INFO 139780359198336] #progress_metric: host=algo-1, completed 66.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:37 INFO 139780359198336] #quality_metric: host=algo-1, epoch=265, train loss <loss>=2.566003847122192\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:37 INFO 139780359198336] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:21:41 INFO 139780359198336] Epoch[266] Batch[0] avg_epoch_loss=2.523107\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:41 INFO 139780359198336] #quality_metric: host=algo-1, epoch=266, batch=0 train loss <loss>=2.523106575012207\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:46 INFO 139780359198336] Epoch[266] Batch[5] avg_epoch_loss=2.503768\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:46 INFO 139780359198336] #quality_metric: host=algo-1, epoch=266, batch=5 train loss <loss>=2.5037681659062705\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:46 INFO 139780359198336] Epoch[266] Batch [5]#011Speed: 61.00 samples/sec#011loss=2.503768\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:51 INFO 139780359198336] Epoch[266] Batch[10] avg_epoch_loss=2.582415\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:51 INFO 139780359198336] #quality_metric: host=algo-1, epoch=266, batch=10 train loss <loss>=2.6767910003662108\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:51 INFO 139780359198336] Epoch[266] Batch [10]#011Speed: 60.50 samples/sec#011loss=2.676791\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:51 INFO 139780359198336] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528097.0406659, \"EndTime\": 1617528111.7455518, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14704.315900802612, \"count\": 1, \"min\": 14704.315900802612, \"max\": 14704.315900802612}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:51 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.61244249859655 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:51 INFO 139780359198336] #progress_metric: host=algo-1, completed 66.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:51 INFO 139780359198336] #quality_metric: host=algo-1, epoch=266, train loss <loss>=2.582414908842607\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:51 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:55 INFO 139780359198336] Epoch[267] Batch[0] avg_epoch_loss=2.477195\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:21:55 INFO 139780359198336] #quality_metric: host=algo-1, epoch=267, batch=0 train loss <loss>=2.4771945476531982\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:00 INFO 139780359198336] Epoch[267] Batch[5] avg_epoch_loss=2.455845\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:00 INFO 139780359198336] #quality_metric: host=algo-1, epoch=267, batch=5 train loss <loss>=2.45584507783254\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:00 INFO 139780359198336] Epoch[267] Batch [5]#011Speed: 62.61 samples/sec#011loss=2.455845\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:07 INFO 139780359198336] Epoch[267] Batch[10] avg_epoch_loss=2.441967\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:07 INFO 139780359198336] #quality_metric: host=algo-1, epoch=267, batch=10 train loss <loss>=2.4253126621246337\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:07 INFO 139780359198336] Epoch[267] Batch [10]#011Speed: 51.31 samples/sec#011loss=2.425313\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:07 INFO 139780359198336] processed a total of 689 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528111.745622, \"EndTime\": 1617528127.0932226, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 15347.170114517212, \"count\": 1, \"min\": 15347.170114517212, \"max\": 15347.170114517212}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:07 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.893975062108595 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:07 INFO 139780359198336] #progress_metric: host=algo-1, completed 67.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:07 INFO 139780359198336] #quality_metric: host=algo-1, epoch=267, train loss <loss>=2.4419667070562188\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:07 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:11 INFO 139780359198336] Epoch[268] Batch[0] avg_epoch_loss=2.504360\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:11 INFO 139780359198336] #quality_metric: host=algo-1, epoch=268, batch=0 train loss <loss>=2.504359722137451\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:16 INFO 139780359198336] Epoch[268] Batch[5] avg_epoch_loss=2.476816\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:16 INFO 139780359198336] #quality_metric: host=algo-1, epoch=268, batch=5 train loss <loss>=2.4768155415852866\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:16 INFO 139780359198336] Epoch[268] Batch [5]#011Speed: 61.30 samples/sec#011loss=2.476816\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:21 INFO 139780359198336] Epoch[268] Batch[10] avg_epoch_loss=2.497431\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:21 INFO 139780359198336] #quality_metric: host=algo-1, epoch=268, batch=10 train loss <loss>=2.5221697330474853\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:21 INFO 139780359198336] Epoch[268] Batch [10]#011Speed: 59.27 samples/sec#011loss=2.522170\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:21 INFO 139780359198336] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528127.093293, \"EndTime\": 1617528141.9254014, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14831.775903701782, \"count\": 1, \"min\": 14831.775903701782, \"max\": 14831.775903701782}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:21 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.43130214421805 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:21 INFO 139780359198336] #progress_metric: host=algo-1, completed 67.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:21 INFO 139780359198336] #quality_metric: host=algo-1, epoch=268, train loss <loss>=2.497431083159013\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:21 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:26 INFO 139780359198336] Epoch[269] Batch[0] avg_epoch_loss=2.311912\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:26 INFO 139780359198336] #quality_metric: host=algo-1, epoch=269, batch=0 train loss <loss>=2.3119118213653564\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:31 INFO 139780359198336] Epoch[269] Batch[5] avg_epoch_loss=2.462564\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:31 INFO 139780359198336] #quality_metric: host=algo-1, epoch=269, batch=5 train loss <loss>=2.46256430943807\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:31 INFO 139780359198336] Epoch[269] Batch [5]#011Speed: 63.39 samples/sec#011loss=2.462564\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:35 INFO 139780359198336] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528141.9254751, \"EndTime\": 1617528155.2364771, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13310.53614616394, \"count\": 1, \"min\": 13310.53614616394, \"max\": 13310.53614616394}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:35 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.57923420804661 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:35 INFO 139780359198336] #progress_metric: host=algo-1, completed 67.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:35 INFO 139780359198336] #quality_metric: host=algo-1, epoch=269, train loss <loss>=2.482800841331482\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:35 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:39 INFO 139780359198336] Epoch[270] Batch[0] avg_epoch_loss=2.318636\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:39 INFO 139780359198336] #quality_metric: host=algo-1, epoch=270, batch=0 train loss <loss>=2.3186357021331787\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:44 INFO 139780359198336] Epoch[270] Batch[5] avg_epoch_loss=2.387832\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:44 INFO 139780359198336] #quality_metric: host=algo-1, epoch=270, batch=5 train loss <loss>=2.3878324826558432\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:44 INFO 139780359198336] Epoch[270] Batch [5]#011Speed: 63.14 samples/sec#011loss=2.387832\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:49 INFO 139780359198336] Epoch[270] Batch[10] avg_epoch_loss=2.434519\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:49 INFO 139780359198336] #quality_metric: host=algo-1, epoch=270, batch=10 train loss <loss>=2.4905434131622313\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:49 INFO 139780359198336] Epoch[270] Batch [10]#011Speed: 57.00 samples/sec#011loss=2.490543\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:50 INFO 139780359198336] processed a total of 711 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528155.2365544, \"EndTime\": 1617528170.8808837, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 15643.836975097656, \"count\": 1, \"min\": 15643.836975097656, \"max\": 15643.836975097656}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:50 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.448884489520196 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:50 INFO 139780359198336] #progress_metric: host=algo-1, completed 67.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:50 INFO 139780359198336] #quality_metric: host=algo-1, epoch=270, train loss <loss>=2.422837197780609\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:50 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:55 INFO 139780359198336] Epoch[271] Batch[0] avg_epoch_loss=2.540473\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:22:55 INFO 139780359198336] #quality_metric: host=algo-1, epoch=271, batch=0 train loss <loss>=2.540472984313965\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:23:00 INFO 139780359198336] Epoch[271] Batch[5] avg_epoch_loss=2.495315\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:00 INFO 139780359198336] #quality_metric: host=algo-1, epoch=271, batch=5 train loss <loss>=2.495315432548523\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:00 INFO 139780359198336] Epoch[271] Batch [5]#011Speed: 63.36 samples/sec#011loss=2.495315\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:04 INFO 139780359198336] processed a total of 610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528170.8809612, \"EndTime\": 1617528184.5908647, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13709.418058395386, \"count\": 1, \"min\": 13709.418058395386, \"max\": 13709.418058395386}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:04 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.49452840129592 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:04 INFO 139780359198336] #progress_metric: host=algo-1, completed 68.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:04 INFO 139780359198336] #quality_metric: host=algo-1, epoch=271, train loss <loss>=2.4867141962051393\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:04 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:08 INFO 139780359198336] Epoch[272] Batch[0] avg_epoch_loss=2.314216\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:08 INFO 139780359198336] #quality_metric: host=algo-1, epoch=272, batch=0 train loss <loss>=2.314215898513794\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:14 INFO 139780359198336] Epoch[272] Batch[5] avg_epoch_loss=2.455926\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:14 INFO 139780359198336] #quality_metric: host=algo-1, epoch=272, batch=5 train loss <loss>=2.4559263785680137\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:14 INFO 139780359198336] Epoch[272] Batch [5]#011Speed: 62.71 samples/sec#011loss=2.455926\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:19 INFO 139780359198336] Epoch[272] Batch[10] avg_epoch_loss=2.466540\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:19 INFO 139780359198336] #quality_metric: host=algo-1, epoch=272, batch=10 train loss <loss>=2.4792772769927978\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:19 INFO 139780359198336] Epoch[272] Batch [10]#011Speed: 60.36 samples/sec#011loss=2.479277\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:19 INFO 139780359198336] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528184.590962, \"EndTime\": 1617528199.402609, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14811.173439025879, \"count\": 1, \"min\": 14811.173439025879, \"max\": 14811.173439025879}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:19 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.75047332739865 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:19 INFO 139780359198336] #progress_metric: host=algo-1, completed 68.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:19 INFO 139780359198336] #quality_metric: host=algo-1, epoch=272, train loss <loss>=2.4665404233065518\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:19 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:23 INFO 139780359198336] Epoch[273] Batch[0] avg_epoch_loss=2.484859\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:23 INFO 139780359198336] #quality_metric: host=algo-1, epoch=273, batch=0 train loss <loss>=2.4848592281341553\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:28 INFO 139780359198336] Epoch[273] Batch[5] avg_epoch_loss=2.462857\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:28 INFO 139780359198336] #quality_metric: host=algo-1, epoch=273, batch=5 train loss <loss>=2.462857246398926\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:28 INFO 139780359198336] Epoch[273] Batch [5]#011Speed: 63.13 samples/sec#011loss=2.462857\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:32 INFO 139780359198336] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528199.4026744, \"EndTime\": 1617528212.7753346, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13372.34902381897, \"count\": 1, \"min\": 13372.34902381897, \"max\": 13372.34902381897}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:32 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=47.85960687598937 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:32 INFO 139780359198336] #progress_metric: host=algo-1, completed 68.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:32 INFO 139780359198336] #quality_metric: host=algo-1, epoch=273, train loss <loss>=2.4690932273864745\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:32 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:36 INFO 139780359198336] Epoch[274] Batch[0] avg_epoch_loss=2.539981\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:36 INFO 139780359198336] #quality_metric: host=algo-1, epoch=274, batch=0 train loss <loss>=2.5399811267852783\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:42 INFO 139780359198336] Epoch[274] Batch[5] avg_epoch_loss=2.505019\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:42 INFO 139780359198336] #quality_metric: host=algo-1, epoch=274, batch=5 train loss <loss>=2.505018870035807\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:42 INFO 139780359198336] Epoch[274] Batch [5]#011Speed: 63.01 samples/sec#011loss=2.505019\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:46 INFO 139780359198336] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528212.775403, \"EndTime\": 1617528226.163947, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13388.094425201416, \"count\": 1, \"min\": 13388.094425201416, \"max\": 13388.094425201416}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:46 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.60795807194799 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:46 INFO 139780359198336] #progress_metric: host=algo-1, completed 68.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:46 INFO 139780359198336] #quality_metric: host=algo-1, epoch=274, train loss <loss>=2.4828272581100466\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:46 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:50 INFO 139780359198336] Epoch[275] Batch[0] avg_epoch_loss=2.408534\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:50 INFO 139780359198336] #quality_metric: host=algo-1, epoch=275, batch=0 train loss <loss>=2.408534288406372\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:55 INFO 139780359198336] Epoch[275] Batch[5] avg_epoch_loss=2.472026\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:55 INFO 139780359198336] #quality_metric: host=algo-1, epoch=275, batch=5 train loss <loss>=2.472026228904724\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:23:55 INFO 139780359198336] Epoch[275] Batch [5]#011Speed: 61.80 samples/sec#011loss=2.472026\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:00 INFO 139780359198336] Epoch[275] Batch[10] avg_epoch_loss=2.411239\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:00 INFO 139780359198336] #quality_metric: host=algo-1, epoch=275, batch=10 train loss <loss>=2.338294792175293\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:00 INFO 139780359198336] Epoch[275] Batch [10]#011Speed: 60.46 samples/sec#011loss=2.338295\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:00 INFO 139780359198336] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528226.1640909, \"EndTime\": 1617528240.8447924, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14680.306911468506, \"count\": 1, \"min\": 14680.306911468506, \"max\": 14680.306911468506}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:00 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.20858990977064 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:00 INFO 139780359198336] #progress_metric: host=algo-1, completed 69.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:00 INFO 139780359198336] #quality_metric: host=algo-1, epoch=275, train loss <loss>=2.4112392122095283\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:00 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:05 INFO 139780359198336] Epoch[276] Batch[0] avg_epoch_loss=2.523642\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:05 INFO 139780359198336] #quality_metric: host=algo-1, epoch=276, batch=0 train loss <loss>=2.52364182472229\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:10 INFO 139780359198336] Epoch[276] Batch[5] avg_epoch_loss=2.455691\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:10 INFO 139780359198336] #quality_metric: host=algo-1, epoch=276, batch=5 train loss <loss>=2.455690542856852\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:10 INFO 139780359198336] Epoch[276] Batch [5]#011Speed: 57.77 samples/sec#011loss=2.455691\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:15 INFO 139780359198336] processed a total of 597 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528240.8448617, \"EndTime\": 1617528255.0846405, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14239.471912384033, \"count\": 1, \"min\": 14239.471912384033, \"max\": 14239.471912384033}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:15 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=41.9253716511663 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:15 INFO 139780359198336] #progress_metric: host=algo-1, completed 69.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:15 INFO 139780359198336] #quality_metric: host=algo-1, epoch=276, train loss <loss>=2.458512306213379\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:15 INFO 139780359198336] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:24:19 INFO 139780359198336] Epoch[277] Batch[0] avg_epoch_loss=2.529830\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:19 INFO 139780359198336] #quality_metric: host=algo-1, epoch=277, batch=0 train loss <loss>=2.529829502105713\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:24 INFO 139780359198336] Epoch[277] Batch[5] avg_epoch_loss=2.479220\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:24 INFO 139780359198336] #quality_metric: host=algo-1, epoch=277, batch=5 train loss <loss>=2.479219834009806\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:24 INFO 139780359198336] Epoch[277] Batch [5]#011Speed: 62.22 samples/sec#011loss=2.479220\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:28 INFO 139780359198336] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528255.084726, \"EndTime\": 1617528268.670267, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13585.141897201538, \"count\": 1, \"min\": 13585.141897201538, \"max\": 13585.141897201538}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:28 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.96268649500042 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:28 INFO 139780359198336] #progress_metric: host=algo-1, completed 69.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:28 INFO 139780359198336] #quality_metric: host=algo-1, epoch=277, train loss <loss>=2.4788976669311524\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:28 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:32 INFO 139780359198336] Epoch[278] Batch[0] avg_epoch_loss=2.567987\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:32 INFO 139780359198336] #quality_metric: host=algo-1, epoch=278, batch=0 train loss <loss>=2.5679872035980225\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:37 INFO 139780359198336] Epoch[278] Batch[5] avg_epoch_loss=2.465189\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:37 INFO 139780359198336] #quality_metric: host=algo-1, epoch=278, batch=5 train loss <loss>=2.4651887814203897\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:37 INFO 139780359198336] Epoch[278] Batch [5]#011Speed: 62.60 samples/sec#011loss=2.465189\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:43 INFO 139780359198336] Epoch[278] Batch[10] avg_epoch_loss=2.477157\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:43 INFO 139780359198336] #quality_metric: host=algo-1, epoch=278, batch=10 train loss <loss>=2.491518831253052\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:43 INFO 139780359198336] Epoch[278] Batch [10]#011Speed: 59.54 samples/sec#011loss=2.491519\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:43 INFO 139780359198336] processed a total of 673 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528268.6703436, \"EndTime\": 1617528283.2336457, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14562.81042098999, \"count\": 1, \"min\": 14562.81042098999, \"max\": 14562.81042098999}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:43 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.213363541003204 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:43 INFO 139780359198336] #progress_metric: host=algo-1, completed 69.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:43 INFO 139780359198336] #quality_metric: host=algo-1, epoch=278, train loss <loss>=2.4771569858897817\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:43 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:47 INFO 139780359198336] Epoch[279] Batch[0] avg_epoch_loss=2.466989\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:47 INFO 139780359198336] #quality_metric: host=algo-1, epoch=279, batch=0 train loss <loss>=2.4669885635375977\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:52 INFO 139780359198336] Epoch[279] Batch[5] avg_epoch_loss=2.467981\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:52 INFO 139780359198336] #quality_metric: host=algo-1, epoch=279, batch=5 train loss <loss>=2.4679811795552573\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:52 INFO 139780359198336] Epoch[279] Batch [5]#011Speed: 61.09 samples/sec#011loss=2.467981\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:57 INFO 139780359198336] Epoch[279] Batch[10] avg_epoch_loss=2.436218\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:57 INFO 139780359198336] #quality_metric: host=algo-1, epoch=279, batch=10 train loss <loss>=2.3981019496917724\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:57 INFO 139780359198336] Epoch[279] Batch [10]#011Speed: 58.94 samples/sec#011loss=2.398102\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:57 INFO 139780359198336] processed a total of 690 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528283.2336948, \"EndTime\": 1617528297.9154675, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14681.528568267822, \"count\": 1, \"min\": 14681.528568267822, \"max\": 14681.528568267822}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:57 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.99749987122281 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:57 INFO 139780359198336] #progress_metric: host=algo-1, completed 70.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:57 INFO 139780359198336] #quality_metric: host=algo-1, epoch=279, train loss <loss>=2.4362178932536733\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:24:57 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:02 INFO 139780359198336] Epoch[280] Batch[0] avg_epoch_loss=2.441007\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:02 INFO 139780359198336] #quality_metric: host=algo-1, epoch=280, batch=0 train loss <loss>=2.441006898880005\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:08 INFO 139780359198336] Epoch[280] Batch[5] avg_epoch_loss=2.422445\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:08 INFO 139780359198336] #quality_metric: host=algo-1, epoch=280, batch=5 train loss <loss>=2.4224446217219033\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:08 INFO 139780359198336] Epoch[280] Batch [5]#011Speed: 54.83 samples/sec#011loss=2.422445\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:12 INFO 139780359198336] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528297.9155405, \"EndTime\": 1617528312.3501837, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14434.25464630127, \"count\": 1, \"min\": 14434.25464630127, \"max\": 14434.25464630127}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:12 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.09159449186248 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:12 INFO 139780359198336] #progress_metric: host=algo-1, completed 70.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:12 INFO 139780359198336] #quality_metric: host=algo-1, epoch=280, train loss <loss>=2.4637351512908934\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:12 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:16 INFO 139780359198336] Epoch[281] Batch[0] avg_epoch_loss=2.327478\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:16 INFO 139780359198336] #quality_metric: host=algo-1, epoch=281, batch=0 train loss <loss>=2.3274776935577393\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:21 INFO 139780359198336] Epoch[281] Batch[5] avg_epoch_loss=2.499169\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:21 INFO 139780359198336] #quality_metric: host=algo-1, epoch=281, batch=5 train loss <loss>=2.4991690715154014\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:21 INFO 139780359198336] Epoch[281] Batch [5]#011Speed: 61.66 samples/sec#011loss=2.499169\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:25 INFO 139780359198336] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528312.3502648, \"EndTime\": 1617528325.9667394, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13616.122007369995, \"count\": 1, \"min\": 13616.122007369995, \"max\": 13616.122007369995}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:25 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.92932154116693 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:25 INFO 139780359198336] #progress_metric: host=algo-1, completed 70.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:25 INFO 139780359198336] #quality_metric: host=algo-1, epoch=281, train loss <loss>=2.509060525894165\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:25 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:29 INFO 139780359198336] Epoch[282] Batch[0] avg_epoch_loss=2.316744\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:29 INFO 139780359198336] #quality_metric: host=algo-1, epoch=282, batch=0 train loss <loss>=2.3167436122894287\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:35 INFO 139780359198336] Epoch[282] Batch[5] avg_epoch_loss=2.391355\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:35 INFO 139780359198336] #quality_metric: host=algo-1, epoch=282, batch=5 train loss <loss>=2.391355276107788\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:35 INFO 139780359198336] Epoch[282] Batch [5]#011Speed: 62.58 samples/sec#011loss=2.391355\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:25:40 INFO 139780359198336] Epoch[282] Batch[10] avg_epoch_loss=2.421600\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:40 INFO 139780359198336] #quality_metric: host=algo-1, epoch=282, batch=10 train loss <loss>=2.4578946113586424\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:40 INFO 139780359198336] Epoch[282] Batch [10]#011Speed: 58.27 samples/sec#011loss=2.457895\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:40 INFO 139780359198336] processed a total of 690 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528325.9668097, \"EndTime\": 1617528340.5794713, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14612.09750175476, \"count\": 1, \"min\": 14612.09750175476, \"max\": 14612.09750175476}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:40 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=47.22082003552963 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:40 INFO 139780359198336] #progress_metric: host=algo-1, completed 70.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:40 INFO 139780359198336] #quality_metric: host=algo-1, epoch=282, train loss <loss>=2.42160042849454\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:40 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:44 INFO 139780359198336] Epoch[283] Batch[0] avg_epoch_loss=2.462996\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:44 INFO 139780359198336] #quality_metric: host=algo-1, epoch=283, batch=0 train loss <loss>=2.462996482849121\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:49 INFO 139780359198336] Epoch[283] Batch[5] avg_epoch_loss=2.451964\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:49 INFO 139780359198336] #quality_metric: host=algo-1, epoch=283, batch=5 train loss <loss>=2.451964100201925\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:49 INFO 139780359198336] Epoch[283] Batch [5]#011Speed: 62.17 samples/sec#011loss=2.451964\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:55 INFO 139780359198336] Epoch[283] Batch[10] avg_epoch_loss=2.458547\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:55 INFO 139780359198336] #quality_metric: host=algo-1, epoch=283, batch=10 train loss <loss>=2.4664470672607424\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:55 INFO 139780359198336] Epoch[283] Batch [10]#011Speed: 57.29 samples/sec#011loss=2.466447\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:55 INFO 139780359198336] processed a total of 683 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528340.57954, \"EndTime\": 1617528355.3434715, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14763.49663734436, \"count\": 1, \"min\": 14763.49663734436, \"max\": 14763.49663734436}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:55 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.262454271226844 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:55 INFO 139780359198336] #progress_metric: host=algo-1, completed 71.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:55 INFO 139780359198336] #quality_metric: host=algo-1, epoch=283, train loss <loss>=2.458547267046842\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:55 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:59 INFO 139780359198336] Epoch[284] Batch[0] avg_epoch_loss=2.481686\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:25:59 INFO 139780359198336] #quality_metric: host=algo-1, epoch=284, batch=0 train loss <loss>=2.4816858768463135\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:05 INFO 139780359198336] Epoch[284] Batch[5] avg_epoch_loss=2.467580\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:05 INFO 139780359198336] #quality_metric: host=algo-1, epoch=284, batch=5 train loss <loss>=2.4675803184509277\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:05 INFO 139780359198336] Epoch[284] Batch [5]#011Speed: 58.54 samples/sec#011loss=2.467580\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:10 INFO 139780359198336] Epoch[284] Batch[10] avg_epoch_loss=2.419215\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:10 INFO 139780359198336] #quality_metric: host=algo-1, epoch=284, batch=10 train loss <loss>=2.3611764430999758\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:10 INFO 139780359198336] Epoch[284] Batch [10]#011Speed: 56.15 samples/sec#011loss=2.361176\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:10 INFO 139780359198336] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528355.3435369, \"EndTime\": 1617528370.770581, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 15426.692724227905, \"count\": 1, \"min\": 15426.692724227905, \"max\": 15426.692724227905}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:10 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=41.74551306696771 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:10 INFO 139780359198336] #progress_metric: host=algo-1, completed 71.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:10 INFO 139780359198336] #quality_metric: host=algo-1, epoch=284, train loss <loss>=2.4192149205641313\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:10 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:14 INFO 139780359198336] Epoch[285] Batch[0] avg_epoch_loss=2.392782\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:14 INFO 139780359198336] #quality_metric: host=algo-1, epoch=285, batch=0 train loss <loss>=2.39278244972229\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:20 INFO 139780359198336] Epoch[285] Batch[5] avg_epoch_loss=2.443117\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:20 INFO 139780359198336] #quality_metric: host=algo-1, epoch=285, batch=5 train loss <loss>=2.4431174198786416\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:20 INFO 139780359198336] Epoch[285] Batch [5]#011Speed: 62.44 samples/sec#011loss=2.443117\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:25 INFO 139780359198336] Epoch[285] Batch[10] avg_epoch_loss=2.405443\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:25 INFO 139780359198336] #quality_metric: host=algo-1, epoch=285, batch=10 train loss <loss>=2.3602335929870604\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:25 INFO 139780359198336] Epoch[285] Batch [10]#011Speed: 59.09 samples/sec#011loss=2.360234\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:25 INFO 139780359198336] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528370.7706606, \"EndTime\": 1617528385.4979491, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14726.858139038086, \"count\": 1, \"min\": 14726.858139038086, \"max\": 14726.858139038086}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:25 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.661417591040944 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:25 INFO 139780359198336] #progress_metric: host=algo-1, completed 71.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:25 INFO 139780359198336] #quality_metric: host=algo-1, epoch=285, train loss <loss>=2.405442953109741\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:25 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:29 INFO 139780359198336] Epoch[286] Batch[0] avg_epoch_loss=2.415115\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:29 INFO 139780359198336] #quality_metric: host=algo-1, epoch=286, batch=0 train loss <loss>=2.415114641189575\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:34 INFO 139780359198336] Epoch[286] Batch[5] avg_epoch_loss=2.480479\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:34 INFO 139780359198336] #quality_metric: host=algo-1, epoch=286, batch=5 train loss <loss>=2.4804786841074624\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:34 INFO 139780359198336] Epoch[286] Batch [5]#011Speed: 62.27 samples/sec#011loss=2.480479\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:39 INFO 139780359198336] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528385.4980173, \"EndTime\": 1617528399.0240347, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13525.560855865479, \"count\": 1, \"min\": 13525.560855865479, \"max\": 13525.560855865479}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:39 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.430209198530605 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:39 INFO 139780359198336] #progress_metric: host=algo-1, completed 71.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:39 INFO 139780359198336] #quality_metric: host=algo-1, epoch=286, train loss <loss>=2.4704394817352293\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:39 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:43 INFO 139780359198336] Epoch[287] Batch[0] avg_epoch_loss=2.469883\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:43 INFO 139780359198336] #quality_metric: host=algo-1, epoch=287, batch=0 train loss <loss>=2.469883441925049\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:48 INFO 139780359198336] Epoch[287] Batch[5] avg_epoch_loss=2.449217\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:48 INFO 139780359198336] #quality_metric: host=algo-1, epoch=287, batch=5 train loss <loss>=2.449217438697815\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:48 INFO 139780359198336] Epoch[287] Batch [5]#011Speed: 62.44 samples/sec#011loss=2.449217\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:26:53 INFO 139780359198336] Epoch[287] Batch[10] avg_epoch_loss=2.426551\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:53 INFO 139780359198336] #quality_metric: host=algo-1, epoch=287, batch=10 train loss <loss>=2.399351406097412\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:53 INFO 139780359198336] Epoch[287] Batch [10]#011Speed: 59.24 samples/sec#011loss=2.399351\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:53 INFO 139780359198336] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528399.0241156, \"EndTime\": 1617528413.7305424, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14705.93810081482, \"count\": 1, \"min\": 14705.93810081482, \"max\": 14705.93810081482}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:53 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.19951858262851 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:53 INFO 139780359198336] #progress_metric: host=algo-1, completed 72.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:53 INFO 139780359198336] #quality_metric: host=algo-1, epoch=287, train loss <loss>=2.4265510602430864\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:53 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:57 INFO 139780359198336] Epoch[288] Batch[0] avg_epoch_loss=2.477035\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:26:57 INFO 139780359198336] #quality_metric: host=algo-1, epoch=288, batch=0 train loss <loss>=2.4770348072052\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:03 INFO 139780359198336] Epoch[288] Batch[5] avg_epoch_loss=2.412601\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:03 INFO 139780359198336] #quality_metric: host=algo-1, epoch=288, batch=5 train loss <loss>=2.412601431210836\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:03 INFO 139780359198336] Epoch[288] Batch [5]#011Speed: 60.48 samples/sec#011loss=2.412601\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:08 INFO 139780359198336] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528413.730609, \"EndTime\": 1617528428.1485314, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14417.474269866943, \"count\": 1, \"min\": 14417.474269866943, \"max\": 14417.474269866943}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:08 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.557900613443366 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:08 INFO 139780359198336] #progress_metric: host=algo-1, completed 72.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:08 INFO 139780359198336] #quality_metric: host=algo-1, epoch=288, train loss <loss>=2.4478952884674072\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:08 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:12 INFO 139780359198336] Epoch[289] Batch[0] avg_epoch_loss=2.406888\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:12 INFO 139780359198336] #quality_metric: host=algo-1, epoch=289, batch=0 train loss <loss>=2.4068875312805176\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:17 INFO 139780359198336] Epoch[289] Batch[5] avg_epoch_loss=2.451289\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:17 INFO 139780359198336] #quality_metric: host=algo-1, epoch=289, batch=5 train loss <loss>=2.4512888193130493\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:17 INFO 139780359198336] Epoch[289] Batch [5]#011Speed: 61.40 samples/sec#011loss=2.451289\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:21 INFO 139780359198336] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528428.1486146, \"EndTime\": 1617528441.728448, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13579.469680786133, \"count\": 1, \"min\": 13579.469680786133, \"max\": 13579.469680786133}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:21 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.65675852959964 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:21 INFO 139780359198336] #progress_metric: host=algo-1, completed 72.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:21 INFO 139780359198336] #quality_metric: host=algo-1, epoch=289, train loss <loss>=2.413213515281677\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:21 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:25 INFO 139780359198336] Epoch[290] Batch[0] avg_epoch_loss=2.417995\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:25 INFO 139780359198336] #quality_metric: host=algo-1, epoch=290, batch=0 train loss <loss>=2.4179954528808594\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:30 INFO 139780359198336] Epoch[290] Batch[5] avg_epoch_loss=2.412405\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:30 INFO 139780359198336] #quality_metric: host=algo-1, epoch=290, batch=5 train loss <loss>=2.4124052921930947\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:30 INFO 139780359198336] Epoch[290] Batch [5]#011Speed: 63.64 samples/sec#011loss=2.412405\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:35 INFO 139780359198336] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528441.7285345, \"EndTime\": 1617528455.1126187, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13383.726596832275, \"count\": 1, \"min\": 13383.726596832275, \"max\": 13383.726596832275}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:35 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.772630943574555 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:35 INFO 139780359198336] #progress_metric: host=algo-1, completed 72.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:35 INFO 139780359198336] #quality_metric: host=algo-1, epoch=290, train loss <loss>=2.4196226596832275\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:35 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:39 INFO 139780359198336] Epoch[291] Batch[0] avg_epoch_loss=2.533642\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:39 INFO 139780359198336] #quality_metric: host=algo-1, epoch=291, batch=0 train loss <loss>=2.533642053604126\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:44 INFO 139780359198336] Epoch[291] Batch[5] avg_epoch_loss=2.426618\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:44 INFO 139780359198336] #quality_metric: host=algo-1, epoch=291, batch=5 train loss <loss>=2.4266181786855063\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:44 INFO 139780359198336] Epoch[291] Batch [5]#011Speed: 63.23 samples/sec#011loss=2.426618\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:48 INFO 139780359198336] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528455.1127505, \"EndTime\": 1617528468.4686987, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13355.373859405518, \"count\": 1, \"min\": 13355.373859405518, \"max\": 13355.373859405518}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:48 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.64751196472653 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:48 INFO 139780359198336] #progress_metric: host=algo-1, completed 73.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:48 INFO 139780359198336] #quality_metric: host=algo-1, epoch=291, train loss <loss>=2.463364839553833\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:48 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:52 INFO 139780359198336] Epoch[292] Batch[0] avg_epoch_loss=2.411263\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:52 INFO 139780359198336] #quality_metric: host=algo-1, epoch=292, batch=0 train loss <loss>=2.4112629890441895\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:57 INFO 139780359198336] Epoch[292] Batch[5] avg_epoch_loss=2.459511\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:57 INFO 139780359198336] #quality_metric: host=algo-1, epoch=292, batch=5 train loss <loss>=2.4595113595326743\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:27:57 INFO 139780359198336] Epoch[292] Batch [5]#011Speed: 62.63 samples/sec#011loss=2.459511\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:03 INFO 139780359198336] Epoch[292] Batch[10] avg_epoch_loss=2.486154\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:03 INFO 139780359198336] #quality_metric: host=algo-1, epoch=292, batch=10 train loss <loss>=2.5181248664855955\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:03 INFO 139780359198336] Epoch[292] Batch [10]#011Speed: 57.95 samples/sec#011loss=2.518125\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:03 INFO 139780359198336] processed a total of 676 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528468.4687712, \"EndTime\": 1617528483.2236567, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14754.37045097351, \"count\": 1, \"min\": 14754.37045097351, \"max\": 14754.37045097351}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:03 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.81664113505002 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:03 INFO 139780359198336] #progress_metric: host=algo-1, completed 73.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:03 INFO 139780359198336] #quality_metric: host=algo-1, epoch=292, train loss <loss>=2.4861538626930932\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:03 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:07 INFO 139780359198336] Epoch[293] Batch[0] avg_epoch_loss=2.456603\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:07 INFO 139780359198336] #quality_metric: host=algo-1, epoch=293, batch=0 train loss <loss>=2.4566028118133545\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:28:12 INFO 139780359198336] Epoch[293] Batch[5] avg_epoch_loss=2.447916\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:12 INFO 139780359198336] #quality_metric: host=algo-1, epoch=293, batch=5 train loss <loss>=2.4479164679845176\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:12 INFO 139780359198336] Epoch[293] Batch [5]#011Speed: 63.03 samples/sec#011loss=2.447916\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:18 INFO 139780359198336] Epoch[293] Batch[10] avg_epoch_loss=2.442988\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:18 INFO 139780359198336] #quality_metric: host=algo-1, epoch=293, batch=10 train loss <loss>=2.4370739459991455\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:18 INFO 139780359198336] Epoch[293] Batch [10]#011Speed: 60.50 samples/sec#011loss=2.437074\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:18 INFO 139780359198336] processed a total of 669 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528483.2237213, \"EndTime\": 1617528498.0043693, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14780.319213867188, \"count\": 1, \"min\": 14780.319213867188, \"max\": 14780.319213867188}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:18 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.2625895199739 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:18 INFO 139780359198336] #progress_metric: host=algo-1, completed 73.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:18 INFO 139780359198336] #quality_metric: host=algo-1, epoch=293, train loss <loss>=2.4429880489002573\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:18 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:22 INFO 139780359198336] Epoch[294] Batch[0] avg_epoch_loss=2.378520\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:22 INFO 139780359198336] #quality_metric: host=algo-1, epoch=294, batch=0 train loss <loss>=2.3785197734832764\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:27 INFO 139780359198336] Epoch[294] Batch[5] avg_epoch_loss=2.475880\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:27 INFO 139780359198336] #quality_metric: host=algo-1, epoch=294, batch=5 train loss <loss>=2.4758800665537515\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:27 INFO 139780359198336] Epoch[294] Batch [5]#011Speed: 61.50 samples/sec#011loss=2.475880\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:31 INFO 139780359198336] processed a total of 616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528498.0044394, \"EndTime\": 1617528511.5628514, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13558.051824569702, \"count\": 1, \"min\": 13558.051824569702, \"max\": 13558.051824569702}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:31 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.433913435238914 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:31 INFO 139780359198336] #progress_metric: host=algo-1, completed 73.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:31 INFO 139780359198336] #quality_metric: host=algo-1, epoch=294, train loss <loss>=2.497197651863098\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:31 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:35 INFO 139780359198336] Epoch[295] Batch[0] avg_epoch_loss=2.442394\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:35 INFO 139780359198336] #quality_metric: host=algo-1, epoch=295, batch=0 train loss <loss>=2.442394495010376\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:40 INFO 139780359198336] Epoch[295] Batch[5] avg_epoch_loss=2.405989\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:40 INFO 139780359198336] #quality_metric: host=algo-1, epoch=295, batch=5 train loss <loss>=2.405988852183024\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:40 INFO 139780359198336] Epoch[295] Batch [5]#011Speed: 62.62 samples/sec#011loss=2.405989\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:45 INFO 139780359198336] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528511.5629213, \"EndTime\": 1617528525.0964882, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13533.077001571655, \"count\": 1, \"min\": 13533.077001571655, \"max\": 13533.077001571655}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:45 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=47.21723134217842 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:45 INFO 139780359198336] #progress_metric: host=algo-1, completed 74.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:45 INFO 139780359198336] #quality_metric: host=algo-1, epoch=295, train loss <loss>=2.4126211643218993\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:45 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:49 INFO 139780359198336] Epoch[296] Batch[0] avg_epoch_loss=2.335659\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:49 INFO 139780359198336] #quality_metric: host=algo-1, epoch=296, batch=0 train loss <loss>=2.3356587886810303\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:54 INFO 139780359198336] Epoch[296] Batch[5] avg_epoch_loss=2.410015\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:54 INFO 139780359198336] #quality_metric: host=algo-1, epoch=296, batch=5 train loss <loss>=2.4100149869918823\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:54 INFO 139780359198336] Epoch[296] Batch [5]#011Speed: 61.19 samples/sec#011loss=2.410015\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:58 INFO 139780359198336] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528525.0965722, \"EndTime\": 1617528538.7764106, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13679.478406906128, \"count\": 1, \"min\": 13679.478406906128, \"max\": 13679.478406906128}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:58 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.98071956062504 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:58 INFO 139780359198336] #progress_metric: host=algo-1, completed 74.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:58 INFO 139780359198336] #quality_metric: host=algo-1, epoch=296, train loss <loss>=2.4210654735565185\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:28:58 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:03 INFO 139780359198336] Epoch[297] Batch[0] avg_epoch_loss=2.499159\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:03 INFO 139780359198336] #quality_metric: host=algo-1, epoch=297, batch=0 train loss <loss>=2.499159097671509\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:08 INFO 139780359198336] Epoch[297] Batch[5] avg_epoch_loss=2.453262\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:08 INFO 139780359198336] #quality_metric: host=algo-1, epoch=297, batch=5 train loss <loss>=2.453262289365133\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:08 INFO 139780359198336] Epoch[297] Batch [5]#011Speed: 54.85 samples/sec#011loss=2.453262\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:13 INFO 139780359198336] processed a total of 589 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528538.7765455, \"EndTime\": 1617528553.0298014, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14252.834558486938, \"count\": 1, \"min\": 14252.834558486938, \"max\": 14252.834558486938}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:13 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=41.32481722624635 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:13 INFO 139780359198336] #progress_metric: host=algo-1, completed 74.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:13 INFO 139780359198336] #quality_metric: host=algo-1, epoch=297, train loss <loss>=2.413233232498169\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:13 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:17 INFO 139780359198336] Epoch[298] Batch[0] avg_epoch_loss=2.393915\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:17 INFO 139780359198336] #quality_metric: host=algo-1, epoch=298, batch=0 train loss <loss>=2.3939149379730225\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:22 INFO 139780359198336] Epoch[298] Batch[5] avg_epoch_loss=2.387669\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:22 INFO 139780359198336] #quality_metric: host=algo-1, epoch=298, batch=5 train loss <loss>=2.3876692851384482\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:22 INFO 139780359198336] Epoch[298] Batch [5]#011Speed: 61.90 samples/sec#011loss=2.387669\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:26 INFO 139780359198336] processed a total of 595 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528553.029872, \"EndTime\": 1617528566.8079696, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13777.659177780151, \"count\": 1, \"min\": 13777.659177780151, \"max\": 13777.659177780151}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:26 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.18552679961219 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:26 INFO 139780359198336] #progress_metric: host=algo-1, completed 74.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:26 INFO 139780359198336] #quality_metric: host=algo-1, epoch=298, train loss <loss>=2.438923740386963\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:26 INFO 139780359198336] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:29:31 INFO 139780359198336] Epoch[299] Batch[0] avg_epoch_loss=2.388917\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:31 INFO 139780359198336] #quality_metric: host=algo-1, epoch=299, batch=0 train loss <loss>=2.3889172077178955\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:36 INFO 139780359198336] Epoch[299] Batch[5] avg_epoch_loss=2.490041\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:36 INFO 139780359198336] #quality_metric: host=algo-1, epoch=299, batch=5 train loss <loss>=2.4900405009587607\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:36 INFO 139780359198336] Epoch[299] Batch [5]#011Speed: 62.74 samples/sec#011loss=2.490041\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:40 INFO 139780359198336] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528566.8080382, \"EndTime\": 1617528580.4245458, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13616.05453491211, \"count\": 1, \"min\": 13616.05453491211, \"max\": 13616.05453491211}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:40 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.929383992535314 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:40 INFO 139780359198336] #progress_metric: host=algo-1, completed 75.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:40 INFO 139780359198336] #quality_metric: host=algo-1, epoch=299, train loss <loss>=2.4856487035751345\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:40 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:44 INFO 139780359198336] Epoch[300] Batch[0] avg_epoch_loss=2.317744\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:44 INFO 139780359198336] #quality_metric: host=algo-1, epoch=300, batch=0 train loss <loss>=2.317744493484497\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:49 INFO 139780359198336] Epoch[300] Batch[5] avg_epoch_loss=2.426860\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:49 INFO 139780359198336] #quality_metric: host=algo-1, epoch=300, batch=5 train loss <loss>=2.4268603324890137\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:49 INFO 139780359198336] Epoch[300] Batch [5]#011Speed: 61.94 samples/sec#011loss=2.426860\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:55 INFO 139780359198336] Epoch[300] Batch[10] avg_epoch_loss=2.439104\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:55 INFO 139780359198336] #quality_metric: host=algo-1, epoch=300, batch=10 train loss <loss>=2.4537970542907717\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:55 INFO 139780359198336] Epoch[300] Batch [10]#011Speed: 61.06 samples/sec#011loss=2.453797\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:55 INFO 139780359198336] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528580.4246178, \"EndTime\": 1617528595.0673077, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14642.262935638428, \"count\": 1, \"min\": 14642.262935638428, \"max\": 14642.262935638428}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:55 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.776782489878805 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:55 INFO 139780359198336] #progress_metric: host=algo-1, completed 75.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:55 INFO 139780359198336] #quality_metric: host=algo-1, epoch=300, train loss <loss>=2.439104296944358\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:55 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:59 INFO 139780359198336] Epoch[301] Batch[0] avg_epoch_loss=2.374037\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:29:59 INFO 139780359198336] #quality_metric: host=algo-1, epoch=301, batch=0 train loss <loss>=2.3740367889404297\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:04 INFO 139780359198336] Epoch[301] Batch[5] avg_epoch_loss=2.359721\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:04 INFO 139780359198336] #quality_metric: host=algo-1, epoch=301, batch=5 train loss <loss>=2.3597205877304077\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:04 INFO 139780359198336] Epoch[301] Batch [5]#011Speed: 58.00 samples/sec#011loss=2.359721\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:10 INFO 139780359198336] Epoch[301] Batch[10] avg_epoch_loss=2.374996\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:10 INFO 139780359198336] #quality_metric: host=algo-1, epoch=301, batch=10 train loss <loss>=2.3933271169662476\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:10 INFO 139780359198336] Epoch[301] Batch [10]#011Speed: 54.93 samples/sec#011loss=2.393327\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:10 INFO 139780359198336] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528595.0673847, \"EndTime\": 1617528610.6135445, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 15545.712232589722, \"count\": 1, \"min\": 15545.712232589722, \"max\": 15545.712232589722}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:10 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=42.26173724000934 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:10 INFO 139780359198336] #progress_metric: host=algo-1, completed 75.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:10 INFO 139780359198336] #quality_metric: host=algo-1, epoch=301, train loss <loss>=2.3749962828376074\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:10 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:14 INFO 139780359198336] Epoch[302] Batch[0] avg_epoch_loss=2.370759\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:14 INFO 139780359198336] #quality_metric: host=algo-1, epoch=302, batch=0 train loss <loss>=2.370758533477783\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:19 INFO 139780359198336] Epoch[302] Batch[5] avg_epoch_loss=2.420803\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:19 INFO 139780359198336] #quality_metric: host=algo-1, epoch=302, batch=5 train loss <loss>=2.4208032687505088\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:19 INFO 139780359198336] Epoch[302] Batch [5]#011Speed: 62.33 samples/sec#011loss=2.420803\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:24 INFO 139780359198336] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528610.6137738, \"EndTime\": 1617528624.0818224, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13466.891288757324, \"count\": 1, \"min\": 13466.891288757324, \"max\": 13466.891288757324}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:24 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=47.07806343268342 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:24 INFO 139780359198336] #progress_metric: host=algo-1, completed 75.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:24 INFO 139780359198336] #quality_metric: host=algo-1, epoch=302, train loss <loss>=2.413573455810547\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:24 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:28 INFO 139780359198336] Epoch[303] Batch[0] avg_epoch_loss=2.393392\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:28 INFO 139780359198336] #quality_metric: host=algo-1, epoch=303, batch=0 train loss <loss>=2.393392324447632\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:33 INFO 139780359198336] Epoch[303] Batch[5] avg_epoch_loss=2.463537\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:33 INFO 139780359198336] #quality_metric: host=algo-1, epoch=303, batch=5 train loss <loss>=2.463537414868673\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:33 INFO 139780359198336] Epoch[303] Batch [5]#011Speed: 62.16 samples/sec#011loss=2.463537\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:38 INFO 139780359198336] Epoch[303] Batch[10] avg_epoch_loss=2.436076\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:38 INFO 139780359198336] #quality_metric: host=algo-1, epoch=303, batch=10 train loss <loss>=2.4031222820281983\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:38 INFO 139780359198336] Epoch[303] Batch [10]#011Speed: 59.75 samples/sec#011loss=2.403122\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:38 INFO 139780359198336] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528624.08189, \"EndTime\": 1617528638.7988093, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14716.397523880005, \"count\": 1, \"min\": 14716.397523880005, \"max\": 14716.397523880005}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:38 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.30402744384837 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:38 INFO 139780359198336] #progress_metric: host=algo-1, completed 76.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:38 INFO 139780359198336] #quality_metric: host=algo-1, epoch=303, train loss <loss>=2.4360759908502754\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:38 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:42 INFO 139780359198336] Epoch[304] Batch[0] avg_epoch_loss=2.342868\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:42 INFO 139780359198336] #quality_metric: host=algo-1, epoch=304, batch=0 train loss <loss>=2.3428683280944824\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:47 INFO 139780359198336] Epoch[304] Batch[5] avg_epoch_loss=2.459454\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:47 INFO 139780359198336] #quality_metric: host=algo-1, epoch=304, batch=5 train loss <loss>=2.4594538609186807\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:47 INFO 139780359198336] Epoch[304] Batch [5]#011Speed: 62.78 samples/sec#011loss=2.459454\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:30:53 INFO 139780359198336] Epoch[304] Batch[10] avg_epoch_loss=2.503811\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:53 INFO 139780359198336] #quality_metric: host=algo-1, epoch=304, batch=10 train loss <loss>=2.557039213180542\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:53 INFO 139780359198336] Epoch[304] Batch [10]#011Speed: 59.27 samples/sec#011loss=2.557039\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:53 INFO 139780359198336] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528638.7988756, \"EndTime\": 1617528653.3793495, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14580.104351043701, \"count\": 1, \"min\": 14580.104351043701, \"max\": 14580.104351043701}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:53 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.08989534436298 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:53 INFO 139780359198336] #progress_metric: host=algo-1, completed 76.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:53 INFO 139780359198336] #quality_metric: host=algo-1, epoch=304, train loss <loss>=2.503810839219527\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:53 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:57 INFO 139780359198336] Epoch[305] Batch[0] avg_epoch_loss=2.395071\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:30:57 INFO 139780359198336] #quality_metric: host=algo-1, epoch=305, batch=0 train loss <loss>=2.395071029663086\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:03 INFO 139780359198336] Epoch[305] Batch[5] avg_epoch_loss=2.474796\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:03 INFO 139780359198336] #quality_metric: host=algo-1, epoch=305, batch=5 train loss <loss>=2.4747960964838662\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:03 INFO 139780359198336] Epoch[305] Batch [5]#011Speed: 59.95 samples/sec#011loss=2.474796\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:07 INFO 139780359198336] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528653.3794174, \"EndTime\": 1617528667.8510118, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14471.10390663147, \"count\": 1, \"min\": 14471.10390663147, \"max\": 14471.10390663147}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:07 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.25821623115178 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:07 INFO 139780359198336] #progress_metric: host=algo-1, completed 76.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:07 INFO 139780359198336] #quality_metric: host=algo-1, epoch=305, train loss <loss>=2.4849326848983764\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:07 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:12 INFO 139780359198336] Epoch[306] Batch[0] avg_epoch_loss=2.450541\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:12 INFO 139780359198336] #quality_metric: host=algo-1, epoch=306, batch=0 train loss <loss>=2.4505412578582764\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:17 INFO 139780359198336] Epoch[306] Batch[5] avg_epoch_loss=2.426132\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:17 INFO 139780359198336] #quality_metric: host=algo-1, epoch=306, batch=5 train loss <loss>=2.4261316458384194\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:17 INFO 139780359198336] Epoch[306] Batch [5]#011Speed: 62.62 samples/sec#011loss=2.426132\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:21 INFO 139780359198336] processed a total of 606 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528667.8511105, \"EndTime\": 1617528681.3317068, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13480.046510696411, \"count\": 1, \"min\": 13480.046510696411, \"max\": 13480.046510696411}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:21 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.95499022052518 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:21 INFO 139780359198336] #progress_metric: host=algo-1, completed 76.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:21 INFO 139780359198336] #quality_metric: host=algo-1, epoch=306, train loss <loss>=2.4046530604362486\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:21 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:25 INFO 139780359198336] Epoch[307] Batch[0] avg_epoch_loss=2.515294\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:25 INFO 139780359198336] #quality_metric: host=algo-1, epoch=307, batch=0 train loss <loss>=2.515294075012207\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:30 INFO 139780359198336] Epoch[307] Batch[5] avg_epoch_loss=2.420675\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:30 INFO 139780359198336] #quality_metric: host=algo-1, epoch=307, batch=5 train loss <loss>=2.4206748803456626\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:30 INFO 139780359198336] Epoch[307] Batch [5]#011Speed: 61.03 samples/sec#011loss=2.420675\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:35 INFO 139780359198336] processed a total of 611 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528681.3317788, \"EndTime\": 1617528695.0004892, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13668.195724487305, \"count\": 1, \"min\": 13668.195724487305, \"max\": 13668.195724487305}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:35 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.70191254578719 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:35 INFO 139780359198336] #progress_metric: host=algo-1, completed 77.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:35 INFO 139780359198336] #quality_metric: host=algo-1, epoch=307, train loss <loss>=2.478457498550415\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:35 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:39 INFO 139780359198336] Epoch[308] Batch[0] avg_epoch_loss=2.459617\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:39 INFO 139780359198336] #quality_metric: host=algo-1, epoch=308, batch=0 train loss <loss>=2.4596171379089355\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:44 INFO 139780359198336] Epoch[308] Batch[5] avg_epoch_loss=2.434843\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:44 INFO 139780359198336] #quality_metric: host=algo-1, epoch=308, batch=5 train loss <loss>=2.434843381245931\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:44 INFO 139780359198336] Epoch[308] Batch [5]#011Speed: 62.18 samples/sec#011loss=2.434843\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:48 INFO 139780359198336] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528695.0005615, \"EndTime\": 1617528708.5267956, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13525.7408618927, \"count\": 1, \"min\": 13525.7408618927, \"max\": 13525.7408618927}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:48 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.69030846935256 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:48 INFO 139780359198336] #progress_metric: host=algo-1, completed 77.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:48 INFO 139780359198336] #quality_metric: host=algo-1, epoch=308, train loss <loss>=2.5005080938339233\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:48 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:52 INFO 139780359198336] Epoch[309] Batch[0] avg_epoch_loss=2.434955\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:52 INFO 139780359198336] #quality_metric: host=algo-1, epoch=309, batch=0 train loss <loss>=2.4349546432495117\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:57 INFO 139780359198336] Epoch[309] Batch[5] avg_epoch_loss=2.495652\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:57 INFO 139780359198336] #quality_metric: host=algo-1, epoch=309, batch=5 train loss <loss>=2.4956522385279336\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:31:57 INFO 139780359198336] Epoch[309] Batch [5]#011Speed: 60.81 samples/sec#011loss=2.495652\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:03 INFO 139780359198336] Epoch[309] Batch[10] avg_epoch_loss=2.445252\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:03 INFO 139780359198336] #quality_metric: host=algo-1, epoch=309, batch=10 train loss <loss>=2.38477144241333\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:03 INFO 139780359198336] Epoch[309] Batch [10]#011Speed: 53.49 samples/sec#011loss=2.384771\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:03 INFO 139780359198336] processed a total of 702 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528708.526863, \"EndTime\": 1617528723.797521, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 15270.16568183899, \"count\": 1, \"min\": 15270.16568183899, \"max\": 15270.16568183899}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:03 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.97136608539188 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:03 INFO 139780359198336] #progress_metric: host=algo-1, completed 77.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:03 INFO 139780359198336] #quality_metric: host=algo-1, epoch=309, train loss <loss>=2.445251876657659\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:03 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:08 INFO 139780359198336] Epoch[310] Batch[0] avg_epoch_loss=2.403309\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:08 INFO 139780359198336] #quality_metric: host=algo-1, epoch=310, batch=0 train loss <loss>=2.403308868408203\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:32:13 INFO 139780359198336] Epoch[310] Batch[5] avg_epoch_loss=2.475097\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:13 INFO 139780359198336] #quality_metric: host=algo-1, epoch=310, batch=5 train loss <loss>=2.475097139676412\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:13 INFO 139780359198336] Epoch[310] Batch [5]#011Speed: 62.48 samples/sec#011loss=2.475097\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:17 INFO 139780359198336] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528723.7976124, \"EndTime\": 1617528737.572999, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13774.691581726074, \"count\": 1, \"min\": 13774.691581726074, \"max\": 13774.691581726074}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:17 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.880840049270496 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:17 INFO 139780359198336] #progress_metric: host=algo-1, completed 77.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:17 INFO 139780359198336] #quality_metric: host=algo-1, epoch=310, train loss <loss>=2.4580622911453247\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:17 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:21 INFO 139780359198336] Epoch[311] Batch[0] avg_epoch_loss=2.408261\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:21 INFO 139780359198336] #quality_metric: host=algo-1, epoch=311, batch=0 train loss <loss>=2.4082610607147217\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:26 INFO 139780359198336] Epoch[311] Batch[5] avg_epoch_loss=2.446585\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:26 INFO 139780359198336] #quality_metric: host=algo-1, epoch=311, batch=5 train loss <loss>=2.4465845823287964\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:26 INFO 139780359198336] Epoch[311] Batch [5]#011Speed: 63.49 samples/sec#011loss=2.446585\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:32 INFO 139780359198336] Epoch[311] Batch[10] avg_epoch_loss=2.435855\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:32 INFO 139780359198336] #quality_metric: host=algo-1, epoch=311, batch=10 train loss <loss>=2.422979402542114\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:32 INFO 139780359198336] Epoch[311] Batch [10]#011Speed: 58.71 samples/sec#011loss=2.422979\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:32 INFO 139780359198336] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528737.573082, \"EndTime\": 1617528752.1781242, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14604.591846466064, \"count\": 1, \"min\": 14604.591846466064, \"max\": 14604.591846466064}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:32 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.464852213323375 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:32 INFO 139780359198336] #progress_metric: host=algo-1, completed 78.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:32 INFO 139780359198336] #quality_metric: host=algo-1, epoch=311, train loss <loss>=2.4358549551530317\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:32 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:36 INFO 139780359198336] Epoch[312] Batch[0] avg_epoch_loss=2.294865\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:36 INFO 139780359198336] #quality_metric: host=algo-1, epoch=312, batch=0 train loss <loss>=2.294865131378174\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:41 INFO 139780359198336] Epoch[312] Batch[5] avg_epoch_loss=2.429565\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:41 INFO 139780359198336] #quality_metric: host=algo-1, epoch=312, batch=5 train loss <loss>=2.429564595222473\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:41 INFO 139780359198336] Epoch[312] Batch [5]#011Speed: 63.12 samples/sec#011loss=2.429565\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:46 INFO 139780359198336] Epoch[312] Batch[10] avg_epoch_loss=2.452487\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:46 INFO 139780359198336] #quality_metric: host=algo-1, epoch=312, batch=10 train loss <loss>=2.4799946308135987\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:46 INFO 139780359198336] Epoch[312] Batch [10]#011Speed: 59.68 samples/sec#011loss=2.479995\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:46 INFO 139780359198336] processed a total of 683 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528752.178189, \"EndTime\": 1617528766.7763734, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14597.80740737915, \"count\": 1, \"min\": 14597.80740737915, \"max\": 14597.80740737915}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:46 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.787522872679894 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:46 INFO 139780359198336] #progress_metric: host=algo-1, completed 78.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:46 INFO 139780359198336] #quality_metric: host=algo-1, epoch=312, train loss <loss>=2.452487338672985\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:46 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:50 INFO 139780359198336] Epoch[313] Batch[0] avg_epoch_loss=2.505120\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:50 INFO 139780359198336] #quality_metric: host=algo-1, epoch=313, batch=0 train loss <loss>=2.505120277404785\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:55 INFO 139780359198336] Epoch[313] Batch[5] avg_epoch_loss=2.504832\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:55 INFO 139780359198336] #quality_metric: host=algo-1, epoch=313, batch=5 train loss <loss>=2.504832148551941\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:32:55 INFO 139780359198336] Epoch[313] Batch [5]#011Speed: 63.65 samples/sec#011loss=2.504832\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:00 INFO 139780359198336] processed a total of 591 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528766.7764425, \"EndTime\": 1617528780.1813152, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13404.418230056763, \"count\": 1, \"min\": 13404.418230056763, \"max\": 13404.418230056763}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:00 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.08957960281676 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:00 INFO 139780359198336] #progress_metric: host=algo-1, completed 78.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:00 INFO 139780359198336] #quality_metric: host=algo-1, epoch=313, train loss <loss>=2.585329055786133\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:00 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:04 INFO 139780359198336] Epoch[314] Batch[0] avg_epoch_loss=2.425019\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:04 INFO 139780359198336] #quality_metric: host=algo-1, epoch=314, batch=0 train loss <loss>=2.425018548965454\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:10 INFO 139780359198336] Epoch[314] Batch[5] avg_epoch_loss=2.465348\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:10 INFO 139780359198336] #quality_metric: host=algo-1, epoch=314, batch=5 train loss <loss>=2.4653484423955283\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:10 INFO 139780359198336] Epoch[314] Batch [5]#011Speed: 55.54 samples/sec#011loss=2.465348\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:14 INFO 139780359198336] processed a total of 599 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528780.1813867, \"EndTime\": 1617528794.3523302, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14170.54009437561, \"count\": 1, \"min\": 14170.54009437561, \"max\": 14170.54009437561}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:14 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=42.27048737779836 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:14 INFO 139780359198336] #progress_metric: host=algo-1, completed 78.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:14 INFO 139780359198336] #quality_metric: host=algo-1, epoch=314, train loss <loss>=2.3830944061279298\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:14 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:18 INFO 139780359198336] Epoch[315] Batch[0] avg_epoch_loss=2.531057\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:18 INFO 139780359198336] #quality_metric: host=algo-1, epoch=315, batch=0 train loss <loss>=2.5310566425323486\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:23 INFO 139780359198336] Epoch[315] Batch[5] avg_epoch_loss=2.457051\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:23 INFO 139780359198336] #quality_metric: host=algo-1, epoch=315, batch=5 train loss <loss>=2.457051396369934\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:23 INFO 139780359198336] Epoch[315] Batch [5]#011Speed: 63.17 samples/sec#011loss=2.457051\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:27 INFO 139780359198336] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528794.3524024, \"EndTime\": 1617528807.7665927, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13413.671255111694, \"count\": 1, \"min\": 13413.671255111694, \"max\": 13413.671255111694}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:27 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=47.04114119644914 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:27 INFO 139780359198336] #progress_metric: host=algo-1, completed 79.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:27 INFO 139780359198336] #quality_metric: host=algo-1, epoch=315, train loss <loss>=2.4400286436080934\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:27 INFO 139780359198336] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:33:32 INFO 139780359198336] Epoch[316] Batch[0] avg_epoch_loss=2.449495\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:32 INFO 139780359198336] #quality_metric: host=algo-1, epoch=316, batch=0 train loss <loss>=2.4494946002960205\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:37 INFO 139780359198336] Epoch[316] Batch[5] avg_epoch_loss=2.404952\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:37 INFO 139780359198336] #quality_metric: host=algo-1, epoch=316, batch=5 train loss <loss>=2.4049520095189414\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:37 INFO 139780359198336] Epoch[316] Batch [5]#011Speed: 62.45 samples/sec#011loss=2.404952\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:41 INFO 139780359198336] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528807.766673, \"EndTime\": 1617528821.279007, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13511.768341064453, \"count\": 1, \"min\": 13511.768341064453, \"max\": 13511.768341064453}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:41 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.55158554120929 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:41 INFO 139780359198336] #progress_metric: host=algo-1, completed 79.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:41 INFO 139780359198336] #quality_metric: host=algo-1, epoch=316, train loss <loss>=2.4634280443191527\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:41 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:45 INFO 139780359198336] Epoch[317] Batch[0] avg_epoch_loss=2.557009\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:45 INFO 139780359198336] #quality_metric: host=algo-1, epoch=317, batch=0 train loss <loss>=2.5570085048675537\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:50 INFO 139780359198336] Epoch[317] Batch[5] avg_epoch_loss=2.475911\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:50 INFO 139780359198336] #quality_metric: host=algo-1, epoch=317, batch=5 train loss <loss>=2.4759109814961753\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:50 INFO 139780359198336] Epoch[317] Batch [5]#011Speed: 62.29 samples/sec#011loss=2.475911\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:54 INFO 139780359198336] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528821.2790983, \"EndTime\": 1617528834.7706373, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13490.968465805054, \"count\": 1, \"min\": 13490.968465805054, \"max\": 13490.968465805054}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:54 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.32688329011071 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:54 INFO 139780359198336] #progress_metric: host=algo-1, completed 79.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:54 INFO 139780359198336] #quality_metric: host=algo-1, epoch=317, train loss <loss>=2.4321454048156737\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:54 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:58 INFO 139780359198336] Epoch[318] Batch[0] avg_epoch_loss=2.397359\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:33:58 INFO 139780359198336] #quality_metric: host=algo-1, epoch=318, batch=0 train loss <loss>=2.3973586559295654\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:04 INFO 139780359198336] Epoch[318] Batch[5] avg_epoch_loss=2.435814\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:04 INFO 139780359198336] #quality_metric: host=algo-1, epoch=318, batch=5 train loss <loss>=2.435813864072164\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:04 INFO 139780359198336] Epoch[318] Batch [5]#011Speed: 59.29 samples/sec#011loss=2.435814\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:09 INFO 139780359198336] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528834.7707226, \"EndTime\": 1617528849.2794394, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14508.185625076294, \"count\": 1, \"min\": 14508.185625076294, \"max\": 14508.185625076294}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:09 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.21668321332609 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:09 INFO 139780359198336] #progress_metric: host=algo-1, completed 79.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:09 INFO 139780359198336] #quality_metric: host=algo-1, epoch=318, train loss <loss>=2.462640953063965\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:09 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:13 INFO 139780359198336] Epoch[319] Batch[0] avg_epoch_loss=2.372875\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:13 INFO 139780359198336] #quality_metric: host=algo-1, epoch=319, batch=0 train loss <loss>=2.372875452041626\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:18 INFO 139780359198336] Epoch[319] Batch[5] avg_epoch_loss=2.480821\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:18 INFO 139780359198336] #quality_metric: host=algo-1, epoch=319, batch=5 train loss <loss>=2.4808209339777627\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:18 INFO 139780359198336] Epoch[319] Batch [5]#011Speed: 62.25 samples/sec#011loss=2.480821\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:22 INFO 139780359198336] processed a total of 616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528849.279511, \"EndTime\": 1617528862.8658037, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13585.712194442749, \"count\": 1, \"min\": 13585.712194442749, \"max\": 13585.712194442749}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:22 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.341407174109925 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:22 INFO 139780359198336] #progress_metric: host=algo-1, completed 80.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:22 INFO 139780359198336] #quality_metric: host=algo-1, epoch=319, train loss <loss>=2.467597007751465\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:22 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:27 INFO 139780359198336] Epoch[320] Batch[0] avg_epoch_loss=2.522829\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:27 INFO 139780359198336] #quality_metric: host=algo-1, epoch=320, batch=0 train loss <loss>=2.5228285789489746\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:32 INFO 139780359198336] Epoch[320] Batch[5] avg_epoch_loss=2.431993\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:32 INFO 139780359198336] #quality_metric: host=algo-1, epoch=320, batch=5 train loss <loss>=2.4319925705591836\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:32 INFO 139780359198336] Epoch[320] Batch [5]#011Speed: 60.96 samples/sec#011loss=2.431993\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:37 INFO 139780359198336] Epoch[320] Batch[10] avg_epoch_loss=2.523250\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:37 INFO 139780359198336] #quality_metric: host=algo-1, epoch=320, batch=10 train loss <loss>=2.6327585697174074\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:37 INFO 139780359198336] Epoch[320] Batch [10]#011Speed: 61.26 samples/sec#011loss=2.632759\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:37 INFO 139780359198336] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528862.8658736, \"EndTime\": 1617528877.541787, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14675.272464752197, \"count\": 1, \"min\": 14675.272464752197, \"max\": 14675.272464752197}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:37 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.22373573288304 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:37 INFO 139780359198336] #progress_metric: host=algo-1, completed 80.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:37 INFO 139780359198336] #quality_metric: host=algo-1, epoch=320, train loss <loss>=2.5232498429038306\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:37 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:41 INFO 139780359198336] Epoch[321] Batch[0] avg_epoch_loss=2.356120\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:41 INFO 139780359198336] #quality_metric: host=algo-1, epoch=321, batch=0 train loss <loss>=2.3561203479766846\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:46 INFO 139780359198336] Epoch[321] Batch[5] avg_epoch_loss=2.473125\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:46 INFO 139780359198336] #quality_metric: host=algo-1, epoch=321, batch=5 train loss <loss>=2.473124941190084\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:46 INFO 139780359198336] Epoch[321] Batch [5]#011Speed: 62.40 samples/sec#011loss=2.473125\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:51 INFO 139780359198336] processed a total of 597 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528877.541857, \"EndTime\": 1617528891.0874226, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13545.10474205017, \"count\": 1, \"min\": 13545.10474205017, \"max\": 13545.10474205017}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:51 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.074566507451955 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:51 INFO 139780359198336] #progress_metric: host=algo-1, completed 80.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:51 INFO 139780359198336] #quality_metric: host=algo-1, epoch=321, train loss <loss>=2.496601676940918\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:51 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:55 INFO 139780359198336] Epoch[322] Batch[0] avg_epoch_loss=2.489780\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:34:55 INFO 139780359198336] #quality_metric: host=algo-1, epoch=322, batch=0 train loss <loss>=2.4897799491882324\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:35:00 INFO 139780359198336] Epoch[322] Batch[5] avg_epoch_loss=2.431871\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:00 INFO 139780359198336] #quality_metric: host=algo-1, epoch=322, batch=5 train loss <loss>=2.431870619455973\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:00 INFO 139780359198336] Epoch[322] Batch [5]#011Speed: 62.51 samples/sec#011loss=2.431871\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:04 INFO 139780359198336] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528891.0875068, \"EndTime\": 1617528904.9733846, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13885.37049293518, \"count\": 1, \"min\": 13885.37049293518, \"max\": 13885.37049293518}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:04 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.51509255018349 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:04 INFO 139780359198336] #progress_metric: host=algo-1, completed 80.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:04 INFO 139780359198336] #quality_metric: host=algo-1, epoch=322, train loss <loss>=2.4741801738739015\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:04 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:09 INFO 139780359198336] Epoch[323] Batch[0] avg_epoch_loss=2.372376\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:09 INFO 139780359198336] #quality_metric: host=algo-1, epoch=323, batch=0 train loss <loss>=2.3723762035369873\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:14 INFO 139780359198336] Epoch[323] Batch[5] avg_epoch_loss=2.514113\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:14 INFO 139780359198336] #quality_metric: host=algo-1, epoch=323, batch=5 train loss <loss>=2.5141133069992065\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:14 INFO 139780359198336] Epoch[323] Batch [5]#011Speed: 62.26 samples/sec#011loss=2.514113\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:20 INFO 139780359198336] Epoch[323] Batch[10] avg_epoch_loss=2.512568\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:20 INFO 139780359198336] #quality_metric: host=algo-1, epoch=323, batch=10 train loss <loss>=2.5107131004333496\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:20 INFO 139780359198336] Epoch[323] Batch [10]#011Speed: 59.60 samples/sec#011loss=2.510713\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:20 INFO 139780359198336] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528904.973462, \"EndTime\": 1617528920.0677667, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 15093.591690063477, \"count\": 1, \"min\": 15093.591690063477, \"max\": 15093.591690063477}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:20 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.991895623270416 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:20 INFO 139780359198336] #progress_metric: host=algo-1, completed 81.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:20 INFO 139780359198336] #quality_metric: host=algo-1, epoch=323, train loss <loss>=2.5125677585601807\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:20 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:24 INFO 139780359198336] Epoch[324] Batch[0] avg_epoch_loss=2.393555\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:24 INFO 139780359198336] #quality_metric: host=algo-1, epoch=324, batch=0 train loss <loss>=2.3935554027557373\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:29 INFO 139780359198336] Epoch[324] Batch[5] avg_epoch_loss=2.403859\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:29 INFO 139780359198336] #quality_metric: host=algo-1, epoch=324, batch=5 train loss <loss>=2.4038585424423218\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:29 INFO 139780359198336] Epoch[324] Batch [5]#011Speed: 62.82 samples/sec#011loss=2.403859\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:34 INFO 139780359198336] Epoch[324] Batch[10] avg_epoch_loss=2.427535\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:34 INFO 139780359198336] #quality_metric: host=algo-1, epoch=324, batch=10 train loss <loss>=2.4559473991394043\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:34 INFO 139780359198336] Epoch[324] Batch [10]#011Speed: 59.08 samples/sec#011loss=2.455947\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:34 INFO 139780359198336] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528920.0678332, \"EndTime\": 1617528934.7258017, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14657.590389251709, \"count\": 1, \"min\": 14657.590389251709, \"max\": 14657.590389251709}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:34 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.73128240789418 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:34 INFO 139780359198336] #progress_metric: host=algo-1, completed 81.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:34 INFO 139780359198336] #quality_metric: host=algo-1, epoch=324, train loss <loss>=2.42753529548645\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:34 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:38 INFO 139780359198336] Epoch[325] Batch[0] avg_epoch_loss=2.540200\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:38 INFO 139780359198336] #quality_metric: host=algo-1, epoch=325, batch=0 train loss <loss>=2.5401997566223145\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:44 INFO 139780359198336] Epoch[325] Batch[5] avg_epoch_loss=2.496958\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:44 INFO 139780359198336] #quality_metric: host=algo-1, epoch=325, batch=5 train loss <loss>=2.496958335240682\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:44 INFO 139780359198336] Epoch[325] Batch [5]#011Speed: 60.88 samples/sec#011loss=2.496958\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:49 INFO 139780359198336] Epoch[325] Batch[10] avg_epoch_loss=2.449288\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:49 INFO 139780359198336] #quality_metric: host=algo-1, epoch=325, batch=10 train loss <loss>=2.3920838832855225\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:49 INFO 139780359198336] Epoch[325] Batch [10]#011Speed: 59.97 samples/sec#011loss=2.392084\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:49 INFO 139780359198336] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528934.7258766, \"EndTime\": 1617528949.4896452, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14763.345718383789, \"count\": 1, \"min\": 14763.345718383789, \"max\": 14763.345718383789}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:49 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.688961301365225 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:49 INFO 139780359198336] #progress_metric: host=algo-1, completed 81.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:49 INFO 139780359198336] #quality_metric: host=algo-1, epoch=325, train loss <loss>=2.4492881298065186\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:49 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:53 INFO 139780359198336] Epoch[326] Batch[0] avg_epoch_loss=2.465212\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:53 INFO 139780359198336] #quality_metric: host=algo-1, epoch=326, batch=0 train loss <loss>=2.4652116298675537\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:58 INFO 139780359198336] Epoch[326] Batch[5] avg_epoch_loss=2.393779\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:58 INFO 139780359198336] #quality_metric: host=algo-1, epoch=326, batch=5 train loss <loss>=2.3937785228093467\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:35:58 INFO 139780359198336] Epoch[326] Batch [5]#011Speed: 62.15 samples/sec#011loss=2.393779\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:04 INFO 139780359198336] Epoch[326] Batch[10] avg_epoch_loss=2.388687\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:04 INFO 139780359198336] #quality_metric: host=algo-1, epoch=326, batch=10 train loss <loss>=2.382576513290405\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:04 INFO 139780359198336] Epoch[326] Batch [10]#011Speed: 52.97 samples/sec#011loss=2.382577\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:04 INFO 139780359198336] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528949.4897196, \"EndTime\": 1617528964.8027315, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 15312.573194503784, \"count\": 1, \"min\": 15312.573194503784, \"max\": 15312.573194503784}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:04 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=42.90558667427354 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:04 INFO 139780359198336] #progress_metric: host=algo-1, completed 81.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:04 INFO 139780359198336] #quality_metric: host=algo-1, epoch=326, train loss <loss>=2.388686700300737\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:04 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:08 INFO 139780359198336] Epoch[327] Batch[0] avg_epoch_loss=2.414137\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:08 INFO 139780359198336] #quality_metric: host=algo-1, epoch=327, batch=0 train loss <loss>=2.4141366481781006\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:36:14 INFO 139780359198336] Epoch[327] Batch[5] avg_epoch_loss=2.450133\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:14 INFO 139780359198336] #quality_metric: host=algo-1, epoch=327, batch=5 train loss <loss>=2.4501331647237143\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:14 INFO 139780359198336] Epoch[327] Batch [5]#011Speed: 62.44 samples/sec#011loss=2.450133\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:19 INFO 139780359198336] Epoch[327] Batch[10] avg_epoch_loss=2.430625\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:19 INFO 139780359198336] #quality_metric: host=algo-1, epoch=327, batch=10 train loss <loss>=2.4072142124176024\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:19 INFO 139780359198336] Epoch[327] Batch [10]#011Speed: 58.04 samples/sec#011loss=2.407214\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:19 INFO 139780359198336] processed a total of 688 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528964.8028116, \"EndTime\": 1617528979.546167, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14742.811918258667, \"count\": 1, \"min\": 14742.811918258667, \"max\": 14742.811918258667}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:19 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.66650492763637 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:19 INFO 139780359198336] #progress_metric: host=algo-1, completed 82.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:19 INFO 139780359198336] #quality_metric: host=algo-1, epoch=327, train loss <loss>=2.430624550039118\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:19 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:23 INFO 139780359198336] Epoch[328] Batch[0] avg_epoch_loss=2.545823\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:23 INFO 139780359198336] #quality_metric: host=algo-1, epoch=328, batch=0 train loss <loss>=2.545823097229004\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:28 INFO 139780359198336] Epoch[328] Batch[5] avg_epoch_loss=2.503447\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:28 INFO 139780359198336] #quality_metric: host=algo-1, epoch=328, batch=5 train loss <loss>=2.5034471352895102\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:28 INFO 139780359198336] Epoch[328] Batch [5]#011Speed: 62.67 samples/sec#011loss=2.503447\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:33 INFO 139780359198336] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528979.5462325, \"EndTime\": 1617528993.265541, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13718.985557556152, \"count\": 1, \"min\": 13718.985557556152, \"max\": 13718.985557556152}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:33 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.77559275661941 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:33 INFO 139780359198336] #progress_metric: host=algo-1, completed 82.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:33 INFO 139780359198336] #quality_metric: host=algo-1, epoch=328, train loss <loss>=2.4779122352600096\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:33 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:37 INFO 139780359198336] Epoch[329] Batch[0] avg_epoch_loss=2.503925\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:37 INFO 139780359198336] #quality_metric: host=algo-1, epoch=329, batch=0 train loss <loss>=2.503924608230591\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:42 INFO 139780359198336] Epoch[329] Batch[5] avg_epoch_loss=2.447410\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:42 INFO 139780359198336] #quality_metric: host=algo-1, epoch=329, batch=5 train loss <loss>=2.447410066922506\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:42 INFO 139780359198336] Epoch[329] Batch [5]#011Speed: 62.48 samples/sec#011loss=2.447410\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:47 INFO 139780359198336] Epoch[329] Batch[10] avg_epoch_loss=2.469173\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:47 INFO 139780359198336] #quality_metric: host=algo-1, epoch=329, batch=10 train loss <loss>=2.4952880859375\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:47 INFO 139780359198336] Epoch[329] Batch [10]#011Speed: 60.42 samples/sec#011loss=2.495288\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:47 INFO 139780359198336] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617528993.2656212, \"EndTime\": 1617529007.8664098, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14600.155591964722, \"count\": 1, \"min\": 14600.155591964722, \"max\": 14600.155591964722}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:47 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.519787056656185 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:47 INFO 139780359198336] #progress_metric: host=algo-1, completed 82.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:47 INFO 139780359198336] #quality_metric: host=algo-1, epoch=329, train loss <loss>=2.469172802838412\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:47 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:52 INFO 139780359198336] Epoch[330] Batch[0] avg_epoch_loss=2.447452\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:52 INFO 139780359198336] #quality_metric: host=algo-1, epoch=330, batch=0 train loss <loss>=2.447451591491699\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:57 INFO 139780359198336] Epoch[330] Batch[5] avg_epoch_loss=2.455221\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:57 INFO 139780359198336] #quality_metric: host=algo-1, epoch=330, batch=5 train loss <loss>=2.4552213748296103\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:36:57 INFO 139780359198336] Epoch[330] Batch [5]#011Speed: 62.43 samples/sec#011loss=2.455221\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:02 INFO 139780359198336] Epoch[330] Batch[10] avg_epoch_loss=2.528950\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:02 INFO 139780359198336] #quality_metric: host=algo-1, epoch=330, batch=10 train loss <loss>=2.6174243450164796\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:02 INFO 139780359198336] Epoch[330] Batch [10]#011Speed: 57.85 samples/sec#011loss=2.617424\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:02 INFO 139780359198336] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529007.8664732, \"EndTime\": 1617529022.7636428, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14896.866083145142, \"count\": 1, \"min\": 14896.866083145142, \"max\": 14896.866083145142}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:02 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.43164381680348 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:02 INFO 139780359198336] #progress_metric: host=algo-1, completed 82.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:02 INFO 139780359198336] #quality_metric: host=algo-1, epoch=330, train loss <loss>=2.5289499976418237\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:02 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:07 INFO 139780359198336] Epoch[331] Batch[0] avg_epoch_loss=2.414155\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:07 INFO 139780359198336] #quality_metric: host=algo-1, epoch=331, batch=0 train loss <loss>=2.4141552448272705\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:12 INFO 139780359198336] Epoch[331] Batch[5] avg_epoch_loss=2.452109\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:12 INFO 139780359198336] #quality_metric: host=algo-1, epoch=331, batch=5 train loss <loss>=2.452109456062317\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:12 INFO 139780359198336] Epoch[331] Batch [5]#011Speed: 62.43 samples/sec#011loss=2.452109\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:16 INFO 139780359198336] processed a total of 615 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529022.7637167, \"EndTime\": 1617529036.5593674, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13795.21369934082, \"count\": 1, \"min\": 13795.21369934082, \"max\": 13795.21369934082}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:16 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.579221768746606 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:16 INFO 139780359198336] #progress_metric: host=algo-1, completed 83.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:16 INFO 139780359198336] #quality_metric: host=algo-1, epoch=331, train loss <loss>=2.4168533086776733\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:16 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:20 INFO 139780359198336] Epoch[332] Batch[0] avg_epoch_loss=2.416940\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:20 INFO 139780359198336] #quality_metric: host=algo-1, epoch=332, batch=0 train loss <loss>=2.416940212249756\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:25 INFO 139780359198336] Epoch[332] Batch[5] avg_epoch_loss=2.395374\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:25 INFO 139780359198336] #quality_metric: host=algo-1, epoch=332, batch=5 train loss <loss>=2.3953738609949746\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:25 INFO 139780359198336] Epoch[332] Batch [5]#011Speed: 62.57 samples/sec#011loss=2.395374\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:37:31 INFO 139780359198336] Epoch[332] Batch[10] avg_epoch_loss=2.391490\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:31 INFO 139780359198336] #quality_metric: host=algo-1, epoch=332, batch=10 train loss <loss>=2.386829948425293\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:31 INFO 139780359198336] Epoch[332] Batch [10]#011Speed: 61.36 samples/sec#011loss=2.386830\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:31 INFO 139780359198336] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529036.5597794, \"EndTime\": 1617529051.0837474, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14522.571086883545, \"count\": 1, \"min\": 14522.571086883545, \"max\": 14522.571086883545}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:31 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.757617987065444 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:31 INFO 139780359198336] #progress_metric: host=algo-1, completed 83.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:31 INFO 139780359198336] #quality_metric: host=algo-1, epoch=332, train loss <loss>=2.391490264372392\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:31 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:35 INFO 139780359198336] Epoch[333] Batch[0] avg_epoch_loss=2.501053\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:35 INFO 139780359198336] #quality_metric: host=algo-1, epoch=333, batch=0 train loss <loss>=2.5010528564453125\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:40 INFO 139780359198336] Epoch[333] Batch[5] avg_epoch_loss=2.450209\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:40 INFO 139780359198336] #quality_metric: host=algo-1, epoch=333, batch=5 train loss <loss>=2.450209140777588\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:40 INFO 139780359198336] Epoch[333] Batch [5]#011Speed: 63.11 samples/sec#011loss=2.450209\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:44 INFO 139780359198336] processed a total of 610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529051.0838118, \"EndTime\": 1617529064.5805857, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13496.398448944092, \"count\": 1, \"min\": 13496.398448944092, \"max\": 13496.398448944092}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:44 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.19681821803181 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:44 INFO 139780359198336] #progress_metric: host=algo-1, completed 83.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:44 INFO 139780359198336] #quality_metric: host=algo-1, epoch=333, train loss <loss>=2.4135317325592043\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:44 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:48 INFO 139780359198336] Epoch[334] Batch[0] avg_epoch_loss=2.386073\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:48 INFO 139780359198336] #quality_metric: host=algo-1, epoch=334, batch=0 train loss <loss>=2.386072874069214\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:53 INFO 139780359198336] Epoch[334] Batch[5] avg_epoch_loss=2.444816\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:53 INFO 139780359198336] #quality_metric: host=algo-1, epoch=334, batch=5 train loss <loss>=2.4448161125183105\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:53 INFO 139780359198336] Epoch[334] Batch [5]#011Speed: 62.71 samples/sec#011loss=2.444816\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:58 INFO 139780359198336] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529064.5806725, \"EndTime\": 1617529078.002235, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13421.10300064087, \"count\": 1, \"min\": 13421.10300064087, \"max\": 13421.10300064087}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:58 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.71711984930171 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:58 INFO 139780359198336] #progress_metric: host=algo-1, completed 83.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:58 INFO 139780359198336] #quality_metric: host=algo-1, epoch=334, train loss <loss>=2.4536212921142577\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:37:58 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:02 INFO 139780359198336] Epoch[335] Batch[0] avg_epoch_loss=2.437621\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:02 INFO 139780359198336] #quality_metric: host=algo-1, epoch=335, batch=0 train loss <loss>=2.4376206398010254\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:08 INFO 139780359198336] Epoch[335] Batch[5] avg_epoch_loss=2.476146\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:08 INFO 139780359198336] #quality_metric: host=algo-1, epoch=335, batch=5 train loss <loss>=2.476145625114441\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:08 INFO 139780359198336] Epoch[335] Batch [5]#011Speed: 53.38 samples/sec#011loss=2.476146\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:13 INFO 139780359198336] Epoch[335] Batch[10] avg_epoch_loss=2.536786\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:13 INFO 139780359198336] #quality_metric: host=algo-1, epoch=335, batch=10 train loss <loss>=2.609554719924927\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:13 INFO 139780359198336] Epoch[335] Batch [10]#011Speed: 60.73 samples/sec#011loss=2.609555\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:13 INFO 139780359198336] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529078.002303, \"EndTime\": 1617529093.5150096, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 15512.31050491333, \"count\": 1, \"min\": 15512.31050491333, \"max\": 15512.31050491333}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:13 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=41.450648838345145 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:13 INFO 139780359198336] #progress_metric: host=algo-1, completed 84.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:13 INFO 139780359198336] #quality_metric: host=algo-1, epoch=335, train loss <loss>=2.536786122755571\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:13 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:17 INFO 139780359198336] Epoch[336] Batch[0] avg_epoch_loss=2.490767\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:17 INFO 139780359198336] #quality_metric: host=algo-1, epoch=336, batch=0 train loss <loss>=2.490766763687134\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:22 INFO 139780359198336] Epoch[336] Batch[5] avg_epoch_loss=2.437497\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:22 INFO 139780359198336] #quality_metric: host=algo-1, epoch=336, batch=5 train loss <loss>=2.437497059504191\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:22 INFO 139780359198336] Epoch[336] Batch [5]#011Speed: 62.91 samples/sec#011loss=2.437497\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:28 INFO 139780359198336] Epoch[336] Batch[10] avg_epoch_loss=2.383603\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:28 INFO 139780359198336] #quality_metric: host=algo-1, epoch=336, batch=10 train loss <loss>=2.318930459022522\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:28 INFO 139780359198336] Epoch[336] Batch [10]#011Speed: 60.34 samples/sec#011loss=2.318930\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:28 INFO 139780359198336] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529093.5150754, \"EndTime\": 1617529108.0480468, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14532.639741897583, \"count\": 1, \"min\": 14532.639741897583, \"max\": 14532.639741897583}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:28 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.55232926607892 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:28 INFO 139780359198336] #progress_metric: host=algo-1, completed 84.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:28 INFO 139780359198336] #quality_metric: host=algo-1, epoch=336, train loss <loss>=2.3836031501943413\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:28 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:32 INFO 139780359198336] Epoch[337] Batch[0] avg_epoch_loss=2.415171\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:32 INFO 139780359198336] #quality_metric: host=algo-1, epoch=337, batch=0 train loss <loss>=2.415170669555664\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:37 INFO 139780359198336] Epoch[337] Batch[5] avg_epoch_loss=2.448985\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:37 INFO 139780359198336] #quality_metric: host=algo-1, epoch=337, batch=5 train loss <loss>=2.4489848216374717\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:37 INFO 139780359198336] Epoch[337] Batch [5]#011Speed: 60.38 samples/sec#011loss=2.448985\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:42 INFO 139780359198336] Epoch[337] Batch[10] avg_epoch_loss=2.473046\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:42 INFO 139780359198336] #quality_metric: host=algo-1, epoch=337, batch=10 train loss <loss>=2.5019204139709474\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:42 INFO 139780359198336] Epoch[337] Batch [10]#011Speed: 60.18 samples/sec#011loss=2.501920\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:42 INFO 139780359198336] processed a total of 669 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529108.048115, \"EndTime\": 1617529122.747023, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14698.606252670288, \"count\": 1, \"min\": 14698.606252670288, \"max\": 14698.606252670288}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:42 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.51417097837752 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:42 INFO 139780359198336] #progress_metric: host=algo-1, completed 84.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:42 INFO 139780359198336] #quality_metric: host=algo-1, epoch=337, train loss <loss>=2.473046454516324\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:42 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:46 INFO 139780359198336] Epoch[338] Batch[0] avg_epoch_loss=2.474941\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:46 INFO 139780359198336] #quality_metric: host=algo-1, epoch=338, batch=0 train loss <loss>=2.4749414920806885\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:38:52 INFO 139780359198336] Epoch[338] Batch[5] avg_epoch_loss=2.414915\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:52 INFO 139780359198336] #quality_metric: host=algo-1, epoch=338, batch=5 train loss <loss>=2.4149147272109985\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:52 INFO 139780359198336] Epoch[338] Batch [5]#011Speed: 62.23 samples/sec#011loss=2.414915\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:57 INFO 139780359198336] Epoch[338] Batch[10] avg_epoch_loss=2.400089\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:57 INFO 139780359198336] #quality_metric: host=algo-1, epoch=338, batch=10 train loss <loss>=2.382297468185425\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:57 INFO 139780359198336] Epoch[338] Batch [10]#011Speed: 60.78 samples/sec#011loss=2.382297\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:57 INFO 139780359198336] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529122.7471066, \"EndTime\": 1617529137.3692136, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14621.755599975586, \"count\": 1, \"min\": 14621.755599975586, \"max\": 14621.755599975586}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:57 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.72747728842067 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:57 INFO 139780359198336] #progress_metric: host=algo-1, completed 84.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:57 INFO 139780359198336] #quality_metric: host=algo-1, epoch=338, train loss <loss>=2.4000887003811924\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:38:57 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:01 INFO 139780359198336] Epoch[339] Batch[0] avg_epoch_loss=2.472003\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:01 INFO 139780359198336] #quality_metric: host=algo-1, epoch=339, batch=0 train loss <loss>=2.4720029830932617\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:07 INFO 139780359198336] Epoch[339] Batch[5] avg_epoch_loss=2.512229\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:07 INFO 139780359198336] #quality_metric: host=algo-1, epoch=339, batch=5 train loss <loss>=2.512228846549988\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:07 INFO 139780359198336] Epoch[339] Batch [5]#011Speed: 53.61 samples/sec#011loss=2.512229\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:11 INFO 139780359198336] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529137.3692799, \"EndTime\": 1617529151.9987502, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14629.138708114624, \"count\": 1, \"min\": 14629.138708114624, \"max\": 14629.138708114624}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:11 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=42.85932381017493 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:11 INFO 139780359198336] #progress_metric: host=algo-1, completed 85.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:11 INFO 139780359198336] #quality_metric: host=algo-1, epoch=339, train loss <loss>=2.485477161407471\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:11 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:16 INFO 139780359198336] Epoch[340] Batch[0] avg_epoch_loss=2.456701\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:16 INFO 139780359198336] #quality_metric: host=algo-1, epoch=340, batch=0 train loss <loss>=2.4567012786865234\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:21 INFO 139780359198336] Epoch[340] Batch[5] avg_epoch_loss=2.425393\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:21 INFO 139780359198336] #quality_metric: host=algo-1, epoch=340, batch=5 train loss <loss>=2.4253934224446616\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:21 INFO 139780359198336] Epoch[340] Batch [5]#011Speed: 62.14 samples/sec#011loss=2.425393\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:25 INFO 139780359198336] processed a total of 596 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529151.9988332, \"EndTime\": 1617529165.65061, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13651.39627456665, \"count\": 1, \"min\": 13651.39627456665, \"max\": 13651.39627456665}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:25 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.658105454172855 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:25 INFO 139780359198336] #progress_metric: host=algo-1, completed 85.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:25 INFO 139780359198336] #quality_metric: host=algo-1, epoch=340, train loss <loss>=2.410672402381897\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:25 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:29 INFO 139780359198336] Epoch[341] Batch[0] avg_epoch_loss=2.600961\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:29 INFO 139780359198336] #quality_metric: host=algo-1, epoch=341, batch=0 train loss <loss>=2.600961208343506\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:34 INFO 139780359198336] Epoch[341] Batch[5] avg_epoch_loss=2.454063\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:34 INFO 139780359198336] #quality_metric: host=algo-1, epoch=341, batch=5 train loss <loss>=2.454063375790914\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:34 INFO 139780359198336] Epoch[341] Batch [5]#011Speed: 62.71 samples/sec#011loss=2.454063\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:40 INFO 139780359198336] Epoch[341] Batch[10] avg_epoch_loss=2.427136\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:40 INFO 139780359198336] #quality_metric: host=algo-1, epoch=341, batch=10 train loss <loss>=2.394823169708252\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:40 INFO 139780359198336] Epoch[341] Batch [10]#011Speed: 58.74 samples/sec#011loss=2.394823\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:40 INFO 139780359198336] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529165.6507127, \"EndTime\": 1617529180.3746562, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14722.992181777954, \"count\": 1, \"min\": 14722.992181777954, \"max\": 14722.992181777954}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:40 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.48792379685031 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:40 INFO 139780359198336] #progress_metric: host=algo-1, completed 85.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:40 INFO 139780359198336] #quality_metric: host=algo-1, epoch=341, train loss <loss>=2.427136009389704\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:40 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:44 INFO 139780359198336] Epoch[342] Batch[0] avg_epoch_loss=2.466586\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:44 INFO 139780359198336] #quality_metric: host=algo-1, epoch=342, batch=0 train loss <loss>=2.4665863513946533\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:49 INFO 139780359198336] Epoch[342] Batch[5] avg_epoch_loss=2.468903\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:49 INFO 139780359198336] #quality_metric: host=algo-1, epoch=342, batch=5 train loss <loss>=2.4689027468363443\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:49 INFO 139780359198336] Epoch[342] Batch [5]#011Speed: 62.48 samples/sec#011loss=2.468903\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:54 INFO 139780359198336] Epoch[342] Batch[10] avg_epoch_loss=2.398008\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:54 INFO 139780359198336] #quality_metric: host=algo-1, epoch=342, batch=10 train loss <loss>=2.3129340171813966\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:54 INFO 139780359198336] Epoch[342] Batch [10]#011Speed: 60.15 samples/sec#011loss=2.312934\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:54 INFO 139780359198336] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529180.374726, \"EndTime\": 1617529194.9386172, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14563.390016555786, \"count\": 1, \"min\": 14563.390016555786, \"max\": 14563.390016555786}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:54 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.975465070248084 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:54 INFO 139780359198336] #progress_metric: host=algo-1, completed 85.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:54 INFO 139780359198336] #quality_metric: host=algo-1, epoch=342, train loss <loss>=2.398007869720459\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:54 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:59 INFO 139780359198336] Epoch[343] Batch[0] avg_epoch_loss=2.479509\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:39:59 INFO 139780359198336] #quality_metric: host=algo-1, epoch=343, batch=0 train loss <loss>=2.4795093536376953\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:04 INFO 139780359198336] Epoch[343] Batch[5] avg_epoch_loss=2.511861\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:04 INFO 139780359198336] #quality_metric: host=algo-1, epoch=343, batch=5 train loss <loss>=2.511861205101013\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:04 INFO 139780359198336] Epoch[343] Batch [5]#011Speed: 55.39 samples/sec#011loss=2.511861\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:40:10 INFO 139780359198336] Epoch[343] Batch[10] avg_epoch_loss=2.447091\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:10 INFO 139780359198336] #quality_metric: host=algo-1, epoch=343, batch=10 train loss <loss>=2.3693657398223875\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:10 INFO 139780359198336] Epoch[343] Batch [10]#011Speed: 56.36 samples/sec#011loss=2.369366\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:10 INFO 139780359198336] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529194.9386883, \"EndTime\": 1617529210.5376854, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 15598.52385520935, \"count\": 1, \"min\": 15598.52385520935, \"max\": 15598.52385520935}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:10 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=42.18319250498985 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:10 INFO 139780359198336] #progress_metric: host=algo-1, completed 86.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:10 INFO 139780359198336] #quality_metric: host=algo-1, epoch=343, train loss <loss>=2.4470905390652744\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:10 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:14 INFO 139780359198336] Epoch[344] Batch[0] avg_epoch_loss=2.307996\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:14 INFO 139780359198336] #quality_metric: host=algo-1, epoch=344, batch=0 train loss <loss>=2.3079960346221924\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:19 INFO 139780359198336] Epoch[344] Batch[5] avg_epoch_loss=2.458960\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:19 INFO 139780359198336] #quality_metric: host=algo-1, epoch=344, batch=5 train loss <loss>=2.4589601357777915\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:19 INFO 139780359198336] Epoch[344] Batch [5]#011Speed: 62.32 samples/sec#011loss=2.458960\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:25 INFO 139780359198336] Epoch[344] Batch[10] avg_epoch_loss=2.507286\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:25 INFO 139780359198336] #quality_metric: host=algo-1, epoch=344, batch=10 train loss <loss>=2.565278100967407\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:25 INFO 139780359198336] Epoch[344] Batch [10]#011Speed: 59.71 samples/sec#011loss=2.565278\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:25 INFO 139780359198336] processed a total of 670 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529210.5377588, \"EndTime\": 1617529225.059656, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14521.48461341858, \"count\": 1, \"min\": 14521.48461341858, \"max\": 14521.48461341858}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:25 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.138219593227056 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:25 INFO 139780359198336] #progress_metric: host=algo-1, completed 86.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:25 INFO 139780359198336] #quality_metric: host=algo-1, epoch=344, train loss <loss>=2.507286483591253\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:25 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:29 INFO 139780359198336] Epoch[345] Batch[0] avg_epoch_loss=2.515884\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:29 INFO 139780359198336] #quality_metric: host=algo-1, epoch=345, batch=0 train loss <loss>=2.5158841609954834\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:34 INFO 139780359198336] Epoch[345] Batch[5] avg_epoch_loss=2.420626\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:34 INFO 139780359198336] #quality_metric: host=algo-1, epoch=345, batch=5 train loss <loss>=2.420625607172648\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:34 INFO 139780359198336] Epoch[345] Batch [5]#011Speed: 61.89 samples/sec#011loss=2.420626\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:39 INFO 139780359198336] Epoch[345] Batch[10] avg_epoch_loss=2.415793\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:39 INFO 139780359198336] #quality_metric: host=algo-1, epoch=345, batch=10 train loss <loss>=2.409992980957031\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:39 INFO 139780359198336] Epoch[345] Batch [10]#011Speed: 57.26 samples/sec#011loss=2.409993\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:39 INFO 139780359198336] processed a total of 680 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529225.0597215, \"EndTime\": 1617529239.8852687, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14825.162410736084, \"count\": 1, \"min\": 14825.162410736084, \"max\": 14825.162410736084}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:39 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.86767820666762 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:39 INFO 139780359198336] #progress_metric: host=algo-1, completed 86.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:39 INFO 139780359198336] #quality_metric: host=algo-1, epoch=345, train loss <loss>=2.4157925952564585\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:39 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:44 INFO 139780359198336] Epoch[346] Batch[0] avg_epoch_loss=2.435743\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:44 INFO 139780359198336] #quality_metric: host=algo-1, epoch=346, batch=0 train loss <loss>=2.4357426166534424\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:49 INFO 139780359198336] Epoch[346] Batch[5] avg_epoch_loss=2.445262\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:49 INFO 139780359198336] #quality_metric: host=algo-1, epoch=346, batch=5 train loss <loss>=2.44526207447052\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:49 INFO 139780359198336] Epoch[346] Batch [5]#011Speed: 62.36 samples/sec#011loss=2.445262\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:53 INFO 139780359198336] processed a total of 593 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529239.885332, \"EndTime\": 1617529253.3952775, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13509.578704833984, \"count\": 1, \"min\": 13509.578704833984, \"max\": 13509.578704833984}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:53 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.89439532252862 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:53 INFO 139780359198336] #progress_metric: host=algo-1, completed 86.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:53 INFO 139780359198336] #quality_metric: host=algo-1, epoch=346, train loss <loss>=2.4457431554794313\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:53 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:57 INFO 139780359198336] Epoch[347] Batch[0] avg_epoch_loss=2.488602\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:40:57 INFO 139780359198336] #quality_metric: host=algo-1, epoch=347, batch=0 train loss <loss>=2.48860239982605\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:03 INFO 139780359198336] Epoch[347] Batch[5] avg_epoch_loss=2.469755\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:03 INFO 139780359198336] #quality_metric: host=algo-1, epoch=347, batch=5 train loss <loss>=2.4697550932566323\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:03 INFO 139780359198336] Epoch[347] Batch [5]#011Speed: 58.74 samples/sec#011loss=2.469755\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:07 INFO 139780359198336] processed a total of 607 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529253.3953567, \"EndTime\": 1617529267.6878757, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14292.014837265015, \"count\": 1, \"min\": 14292.014837265015, \"max\": 14292.014837265015}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:07 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=42.47095891714426 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:07 INFO 139780359198336] #progress_metric: host=algo-1, completed 87.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:07 INFO 139780359198336] #quality_metric: host=algo-1, epoch=347, train loss <loss>=2.436837887763977\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:07 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:11 INFO 139780359198336] Epoch[348] Batch[0] avg_epoch_loss=2.514278\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:11 INFO 139780359198336] #quality_metric: host=algo-1, epoch=348, batch=0 train loss <loss>=2.514277935028076\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:17 INFO 139780359198336] Epoch[348] Batch[5] avg_epoch_loss=2.462823\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:17 INFO 139780359198336] #quality_metric: host=algo-1, epoch=348, batch=5 train loss <loss>=2.4628233909606934\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:17 INFO 139780359198336] Epoch[348] Batch [5]#011Speed: 62.94 samples/sec#011loss=2.462823\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:22 INFO 139780359198336] Epoch[348] Batch[10] avg_epoch_loss=2.469092\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:22 INFO 139780359198336] #quality_metric: host=algo-1, epoch=348, batch=10 train loss <loss>=2.4766150951385497\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:22 INFO 139780359198336] Epoch[348] Batch [10]#011Speed: 60.91 samples/sec#011loss=2.476615\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:22 INFO 139780359198336] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529267.6879487, \"EndTime\": 1617529282.3357623, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14647.335767745972, \"count\": 1, \"min\": 14647.335767745972, \"max\": 14647.335767745972}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:22 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.89846396576068 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:22 INFO 139780359198336] #progress_metric: host=algo-1, completed 87.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:22 INFO 139780359198336] #quality_metric: host=algo-1, epoch=348, train loss <loss>=2.4690923474051734\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:22 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:26 INFO 139780359198336] Epoch[349] Batch[0] avg_epoch_loss=2.626236\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:26 INFO 139780359198336] #quality_metric: host=algo-1, epoch=349, batch=0 train loss <loss>=2.6262357234954834\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:41:31 INFO 139780359198336] Epoch[349] Batch[5] avg_epoch_loss=2.510879\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:31 INFO 139780359198336] #quality_metric: host=algo-1, epoch=349, batch=5 train loss <loss>=2.5108791987101235\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:31 INFO 139780359198336] Epoch[349] Batch [5]#011Speed: 61.92 samples/sec#011loss=2.510879\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:35 INFO 139780359198336] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529282.3358307, \"EndTime\": 1617529295.8265886, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13490.369319915771, \"count\": 1, \"min\": 13490.369319915771, \"max\": 13490.369319915771}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:35 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.77373415833964 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:35 INFO 139780359198336] #progress_metric: host=algo-1, completed 87.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:35 INFO 139780359198336] #quality_metric: host=algo-1, epoch=349, train loss <loss>=2.495434856414795\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:35 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:40 INFO 139780359198336] Epoch[350] Batch[0] avg_epoch_loss=2.486665\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:40 INFO 139780359198336] #quality_metric: host=algo-1, epoch=350, batch=0 train loss <loss>=2.4866645336151123\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:45 INFO 139780359198336] Epoch[350] Batch[5] avg_epoch_loss=2.455699\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:45 INFO 139780359198336] #quality_metric: host=algo-1, epoch=350, batch=5 train loss <loss>=2.4556991259256997\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:45 INFO 139780359198336] Epoch[350] Batch [5]#011Speed: 62.60 samples/sec#011loss=2.455699\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:50 INFO 139780359198336] Epoch[350] Batch[10] avg_epoch_loss=2.413822\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:50 INFO 139780359198336] #quality_metric: host=algo-1, epoch=350, batch=10 train loss <loss>=2.3635698795318603\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:50 INFO 139780359198336] Epoch[350] Batch [10]#011Speed: 60.48 samples/sec#011loss=2.363570\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:50 INFO 139780359198336] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529295.8266597, \"EndTime\": 1617529310.5323045, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14704.98013496399, \"count\": 1, \"min\": 14704.98013496399, \"max\": 14704.98013496399}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:50 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.06636844290991 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:50 INFO 139780359198336] #progress_metric: host=algo-1, completed 87.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:50 INFO 139780359198336] #quality_metric: host=algo-1, epoch=350, train loss <loss>=2.413822195746682\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:50 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:54 INFO 139780359198336] Epoch[351] Batch[0] avg_epoch_loss=2.461630\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:54 INFO 139780359198336] #quality_metric: host=algo-1, epoch=351, batch=0 train loss <loss>=2.46163010597229\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:59 INFO 139780359198336] Epoch[351] Batch[5] avg_epoch_loss=2.403133\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:59 INFO 139780359198336] #quality_metric: host=algo-1, epoch=351, batch=5 train loss <loss>=2.4031328360239663\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:41:59 INFO 139780359198336] Epoch[351] Batch [5]#011Speed: 62.40 samples/sec#011loss=2.403133\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:05 INFO 139780359198336] Epoch[351] Batch[10] avg_epoch_loss=2.427804\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:05 INFO 139780359198336] #quality_metric: host=algo-1, epoch=351, batch=10 train loss <loss>=2.4574093341827394\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:05 INFO 139780359198336] Epoch[351] Batch [10]#011Speed: 52.13 samples/sec#011loss=2.457409\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:05 INFO 139780359198336] processed a total of 670 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529310.532373, \"EndTime\": 1617529325.8559844, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 15323.184251785278, \"count\": 1, \"min\": 15323.184251785278, \"max\": 15323.184251785278}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:05 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.72422392085866 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:05 INFO 139780359198336] #progress_metric: host=algo-1, completed 88.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:05 INFO 139780359198336] #quality_metric: host=algo-1, epoch=351, train loss <loss>=2.427803971550681\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:05 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:10 INFO 139780359198336] Epoch[352] Batch[0] avg_epoch_loss=2.503261\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:10 INFO 139780359198336] #quality_metric: host=algo-1, epoch=352, batch=0 train loss <loss>=2.503260850906372\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:15 INFO 139780359198336] Epoch[352] Batch[5] avg_epoch_loss=2.439019\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:15 INFO 139780359198336] #quality_metric: host=algo-1, epoch=352, batch=5 train loss <loss>=2.4390187660853067\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:15 INFO 139780359198336] Epoch[352] Batch [5]#011Speed: 61.73 samples/sec#011loss=2.439019\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:20 INFO 139780359198336] Epoch[352] Batch[10] avg_epoch_loss=2.527085\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:20 INFO 139780359198336] #quality_metric: host=algo-1, epoch=352, batch=10 train loss <loss>=2.632763481140137\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:20 INFO 139780359198336] Epoch[352] Batch [10]#011Speed: 59.14 samples/sec#011loss=2.632763\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:20 INFO 139780359198336] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529325.856075, \"EndTime\": 1617529340.7253013, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14868.587970733643, \"count\": 1, \"min\": 14868.587970733643, \"max\": 14868.587970733643}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:20 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.6487518429954 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:20 INFO 139780359198336] #progress_metric: host=algo-1, completed 88.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:20 INFO 139780359198336] #quality_metric: host=algo-1, epoch=352, train loss <loss>=2.527084545655684\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:20 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:24 INFO 139780359198336] Epoch[353] Batch[0] avg_epoch_loss=2.559493\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:24 INFO 139780359198336] #quality_metric: host=algo-1, epoch=353, batch=0 train loss <loss>=2.559492588043213\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:30 INFO 139780359198336] Epoch[353] Batch[5] avg_epoch_loss=2.518385\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:30 INFO 139780359198336] #quality_metric: host=algo-1, epoch=353, batch=5 train loss <loss>=2.5183847745259604\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:30 INFO 139780359198336] Epoch[353] Batch [5]#011Speed: 62.77 samples/sec#011loss=2.518385\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:34 INFO 139780359198336] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529340.7253668, \"EndTime\": 1617529354.1839173, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13458.212614059448, \"count\": 1, \"min\": 13458.212614059448, \"max\": 13458.212614059448}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:34 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.58820668286365 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:34 INFO 139780359198336] #progress_metric: host=algo-1, completed 88.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:34 INFO 139780359198336] #quality_metric: host=algo-1, epoch=353, train loss <loss>=2.4927468061447144\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:34 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:38 INFO 139780359198336] Epoch[354] Batch[0] avg_epoch_loss=2.372049\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:38 INFO 139780359198336] #quality_metric: host=algo-1, epoch=354, batch=0 train loss <loss>=2.372049331665039\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:43 INFO 139780359198336] Epoch[354] Batch[5] avg_epoch_loss=2.431637\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:43 INFO 139780359198336] #quality_metric: host=algo-1, epoch=354, batch=5 train loss <loss>=2.4316368897755942\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:43 INFO 139780359198336] Epoch[354] Batch [5]#011Speed: 61.35 samples/sec#011loss=2.431637\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:48 INFO 139780359198336] Epoch[354] Batch[10] avg_epoch_loss=2.431292\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:48 INFO 139780359198336] #quality_metric: host=algo-1, epoch=354, batch=10 train loss <loss>=2.430878257751465\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:48 INFO 139780359198336] Epoch[354] Batch [10]#011Speed: 59.93 samples/sec#011loss=2.430878\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:48 INFO 139780359198336] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529354.1839988, \"EndTime\": 1617529368.826977, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14642.483949661255, \"count\": 1, \"min\": 14642.483949661255, \"max\": 14642.483949661255}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:48 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.07399071409964 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:48 INFO 139780359198336] #progress_metric: host=algo-1, completed 88.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:48 INFO 139780359198336] #quality_metric: host=algo-1, epoch=354, train loss <loss>=2.4312920570373535\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:48 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:53 INFO 139780359198336] Epoch[355] Batch[0] avg_epoch_loss=2.482777\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:53 INFO 139780359198336] #quality_metric: host=algo-1, epoch=355, batch=0 train loss <loss>=2.482776641845703\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:42:58 INFO 139780359198336] Epoch[355] Batch[5] avg_epoch_loss=2.513665\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:58 INFO 139780359198336] #quality_metric: host=algo-1, epoch=355, batch=5 train loss <loss>=2.513665278752645\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:42:58 INFO 139780359198336] Epoch[355] Batch [5]#011Speed: 63.01 samples/sec#011loss=2.513665\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:03 INFO 139780359198336] Epoch[355] Batch[10] avg_epoch_loss=2.504208\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:03 INFO 139780359198336] #quality_metric: host=algo-1, epoch=355, batch=10 train loss <loss>=2.492859935760498\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:03 INFO 139780359198336] Epoch[355] Batch [10]#011Speed: 57.60 samples/sec#011loss=2.492860\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:03 INFO 139780359198336] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529368.8270512, \"EndTime\": 1617529383.653027, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14825.496673583984, \"count\": 1, \"min\": 14825.496673583984, \"max\": 14825.496673583984}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:03 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.50573147469017 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:03 INFO 139780359198336] #progress_metric: host=algo-1, completed 89.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:03 INFO 139780359198336] #quality_metric: host=algo-1, epoch=355, train loss <loss>=2.504208304665305\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:03 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:08 INFO 139780359198336] Epoch[356] Batch[0] avg_epoch_loss=2.607101\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:08 INFO 139780359198336] #quality_metric: host=algo-1, epoch=356, batch=0 train loss <loss>=2.6071014404296875\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:13 INFO 139780359198336] Epoch[356] Batch[5] avg_epoch_loss=2.472439\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:13 INFO 139780359198336] #quality_metric: host=algo-1, epoch=356, batch=5 train loss <loss>=2.4724390109380088\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:13 INFO 139780359198336] Epoch[356] Batch [5]#011Speed: 61.29 samples/sec#011loss=2.472439\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:17 INFO 139780359198336] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529383.653096, \"EndTime\": 1617529397.4389524, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13785.413265228271, \"count\": 1, \"min\": 13785.413265228271, \"max\": 13785.413265228271}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:17 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.337392548222994 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:17 INFO 139780359198336] #progress_metric: host=algo-1, completed 89.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:17 INFO 139780359198336] #quality_metric: host=algo-1, epoch=356, train loss <loss>=2.458102488517761\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:17 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:21 INFO 139780359198336] Epoch[357] Batch[0] avg_epoch_loss=2.449932\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:21 INFO 139780359198336] #quality_metric: host=algo-1, epoch=357, batch=0 train loss <loss>=2.4499318599700928\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:26 INFO 139780359198336] Epoch[357] Batch[5] avg_epoch_loss=2.429517\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:26 INFO 139780359198336] #quality_metric: host=algo-1, epoch=357, batch=5 train loss <loss>=2.4295166730880737\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:26 INFO 139780359198336] Epoch[357] Batch [5]#011Speed: 63.08 samples/sec#011loss=2.429517\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:30 INFO 139780359198336] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529397.4390352, \"EndTime\": 1617529410.9073937, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13467.969417572021, \"count\": 1, \"min\": 13467.969417572021, \"max\": 13467.969417572021}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:30 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.851559041234324 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:30 INFO 139780359198336] #progress_metric: host=algo-1, completed 89.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:30 INFO 139780359198336] #quality_metric: host=algo-1, epoch=357, train loss <loss>=2.440900135040283\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:30 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:34 INFO 139780359198336] Epoch[358] Batch[0] avg_epoch_loss=2.507211\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:34 INFO 139780359198336] #quality_metric: host=algo-1, epoch=358, batch=0 train loss <loss>=2.5072107315063477\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:40 INFO 139780359198336] Epoch[358] Batch[5] avg_epoch_loss=2.436706\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:40 INFO 139780359198336] #quality_metric: host=algo-1, epoch=358, batch=5 train loss <loss>=2.4367059071858725\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:40 INFO 139780359198336] Epoch[358] Batch [5]#011Speed: 60.97 samples/sec#011loss=2.436706\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:45 INFO 139780359198336] Epoch[358] Batch[10] avg_epoch_loss=2.497358\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:45 INFO 139780359198336] #quality_metric: host=algo-1, epoch=358, batch=10 train loss <loss>=2.570139932632446\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:45 INFO 139780359198336] Epoch[358] Batch [10]#011Speed: 57.65 samples/sec#011loss=2.570140\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:45 INFO 139780359198336] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529410.9074621, \"EndTime\": 1617529425.7718358, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14863.855600357056, \"count\": 1, \"min\": 14863.855600357056, \"max\": 14863.855600357056}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:45 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.739104883679 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:45 INFO 139780359198336] #progress_metric: host=algo-1, completed 89.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:45 INFO 139780359198336] #quality_metric: host=algo-1, epoch=358, train loss <loss>=2.497357736934315\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:45 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:50 INFO 139780359198336] Epoch[359] Batch[0] avg_epoch_loss=2.504508\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:50 INFO 139780359198336] #quality_metric: host=algo-1, epoch=359, batch=0 train loss <loss>=2.5045077800750732\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:55 INFO 139780359198336] Epoch[359] Batch[5] avg_epoch_loss=2.429975\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:55 INFO 139780359198336] #quality_metric: host=algo-1, epoch=359, batch=5 train loss <loss>=2.429974675178528\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:43:55 INFO 139780359198336] Epoch[359] Batch [5]#011Speed: 62.30 samples/sec#011loss=2.429975\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:00 INFO 139780359198336] Epoch[359] Batch[10] avg_epoch_loss=2.511018\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:00 INFO 139780359198336] #quality_metric: host=algo-1, epoch=359, batch=10 train loss <loss>=2.6082704067230225\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:00 INFO 139780359198336] Epoch[359] Batch [10]#011Speed: 60.07 samples/sec#011loss=2.608270\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:00 INFO 139780359198336] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529425.7719028, \"EndTime\": 1617529440.5713978, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14799.183368682861, \"count\": 1, \"min\": 14799.183368682861, \"max\": 14799.183368682861}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:00 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.12375702392171 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:00 INFO 139780359198336] #progress_metric: host=algo-1, completed 90.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:00 INFO 139780359198336] #quality_metric: host=algo-1, epoch=359, train loss <loss>=2.5110181895169346\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:00 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:05 INFO 139780359198336] Epoch[360] Batch[0] avg_epoch_loss=2.555928\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:05 INFO 139780359198336] #quality_metric: host=algo-1, epoch=360, batch=0 train loss <loss>=2.5559284687042236\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:10 INFO 139780359198336] Epoch[360] Batch[5] avg_epoch_loss=2.486263\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:10 INFO 139780359198336] #quality_metric: host=algo-1, epoch=360, batch=5 train loss <loss>=2.486263116200765\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:10 INFO 139780359198336] Epoch[360] Batch [5]#011Speed: 59.81 samples/sec#011loss=2.486263\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:44:16 INFO 139780359198336] Epoch[360] Batch[10] avg_epoch_loss=2.547121\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:16 INFO 139780359198336] #quality_metric: host=algo-1, epoch=360, batch=10 train loss <loss>=2.62015061378479\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:16 INFO 139780359198336] Epoch[360] Batch [10]#011Speed: 59.08 samples/sec#011loss=2.620151\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:16 INFO 139780359198336] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529440.5714684, \"EndTime\": 1617529456.0262544, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 15454.411506652832, \"count\": 1, \"min\": 15454.411506652832, \"max\": 15454.411506652832}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:16 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=42.382456782498075 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:16 INFO 139780359198336] #progress_metric: host=algo-1, completed 90.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:16 INFO 139780359198336] #quality_metric: host=algo-1, epoch=360, train loss <loss>=2.5471210696480493\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:16 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:20 INFO 139780359198336] Epoch[361] Batch[0] avg_epoch_loss=2.435535\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:20 INFO 139780359198336] #quality_metric: host=algo-1, epoch=361, batch=0 train loss <loss>=2.435535192489624\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:25 INFO 139780359198336] Epoch[361] Batch[5] avg_epoch_loss=2.435314\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:25 INFO 139780359198336] #quality_metric: host=algo-1, epoch=361, batch=5 train loss <loss>=2.4353139797846475\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:25 INFO 139780359198336] Epoch[361] Batch [5]#011Speed: 61.93 samples/sec#011loss=2.435314\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:29 INFO 139780359198336] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529456.0263214, \"EndTime\": 1617529469.6991138, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13672.412157058716, \"count\": 1, \"min\": 13672.412157058716, \"max\": 13672.412157058716}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:29 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.00438219309665 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:29 INFO 139780359198336] #progress_metric: host=algo-1, completed 90.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:29 INFO 139780359198336] #quality_metric: host=algo-1, epoch=361, train loss <loss>=2.45257511138916\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:29 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:33 INFO 139780359198336] Epoch[362] Batch[0] avg_epoch_loss=2.607388\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:33 INFO 139780359198336] #quality_metric: host=algo-1, epoch=362, batch=0 train loss <loss>=2.6073882579803467\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:39 INFO 139780359198336] Epoch[362] Batch[5] avg_epoch_loss=2.457693\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:39 INFO 139780359198336] #quality_metric: host=algo-1, epoch=362, batch=5 train loss <loss>=2.457693258921305\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:39 INFO 139780359198336] Epoch[362] Batch [5]#011Speed: 61.41 samples/sec#011loss=2.457693\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:44 INFO 139780359198336] Epoch[362] Batch[10] avg_epoch_loss=2.469554\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:44 INFO 139780359198336] #quality_metric: host=algo-1, epoch=362, batch=10 train loss <loss>=2.483786916732788\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:44 INFO 139780359198336] Epoch[362] Batch [10]#011Speed: 58.51 samples/sec#011loss=2.483787\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:44 INFO 139780359198336] processed a total of 676 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529469.6992538, \"EndTime\": 1617529484.5550282, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14855.13710975647, \"count\": 1, \"min\": 14855.13710975647, \"max\": 14855.13710975647}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:44 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.50573443613653 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:44 INFO 139780359198336] #progress_metric: host=algo-1, completed 90.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:44 INFO 139780359198336] #quality_metric: host=algo-1, epoch=362, train loss <loss>=2.4695540124719795\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:44 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:48 INFO 139780359198336] Epoch[363] Batch[0] avg_epoch_loss=2.295738\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:48 INFO 139780359198336] #quality_metric: host=algo-1, epoch=363, batch=0 train loss <loss>=2.295738458633423\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:53 INFO 139780359198336] Epoch[363] Batch[5] avg_epoch_loss=2.447798\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:53 INFO 139780359198336] #quality_metric: host=algo-1, epoch=363, batch=5 train loss <loss>=2.4477978150049844\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:53 INFO 139780359198336] Epoch[363] Batch [5]#011Speed: 61.53 samples/sec#011loss=2.447798\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:59 INFO 139780359198336] Epoch[363] Batch[10] avg_epoch_loss=2.430699\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:59 INFO 139780359198336] #quality_metric: host=algo-1, epoch=363, batch=10 train loss <loss>=2.4101799964904784\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:59 INFO 139780359198336] Epoch[363] Batch [10]#011Speed: 59.60 samples/sec#011loss=2.410180\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:59 INFO 139780359198336] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529484.55513, \"EndTime\": 1617529499.3299582, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14774.504661560059, \"count\": 1, \"min\": 14774.504661560059, \"max\": 14774.504661560059}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:59 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.400469252149314 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:59 INFO 139780359198336] #progress_metric: host=algo-1, completed 91.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:59 INFO 139780359198336] #quality_metric: host=algo-1, epoch=363, train loss <loss>=2.4306988065893\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:44:59 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:03 INFO 139780359198336] Epoch[364] Batch[0] avg_epoch_loss=2.453436\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:03 INFO 139780359198336] #quality_metric: host=algo-1, epoch=364, batch=0 train loss <loss>=2.4534361362457275\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:09 INFO 139780359198336] Epoch[364] Batch[5] avg_epoch_loss=2.443927\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:09 INFO 139780359198336] #quality_metric: host=algo-1, epoch=364, batch=5 train loss <loss>=2.4439271291097007\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:09 INFO 139780359198336] Epoch[364] Batch [5]#011Speed: 55.49 samples/sec#011loss=2.443927\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:14 INFO 139780359198336] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529499.3300364, \"EndTime\": 1617529514.0527253, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14722.199201583862, \"count\": 1, \"min\": 14722.199201583862, \"max\": 14722.199201583862}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:14 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=42.52024072075401 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:14 INFO 139780359198336] #progress_metric: host=algo-1, completed 91.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:14 INFO 139780359198336] #quality_metric: host=algo-1, epoch=364, train loss <loss>=2.419314169883728\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:14 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:18 INFO 139780359198336] Epoch[365] Batch[0] avg_epoch_loss=2.351127\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:18 INFO 139780359198336] #quality_metric: host=algo-1, epoch=365, batch=0 train loss <loss>=2.3511269092559814\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:23 INFO 139780359198336] Epoch[365] Batch[5] avg_epoch_loss=2.407494\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:23 INFO 139780359198336] #quality_metric: host=algo-1, epoch=365, batch=5 train loss <loss>=2.4074943463007608\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:23 INFO 139780359198336] Epoch[365] Batch [5]#011Speed: 61.49 samples/sec#011loss=2.407494\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:27 INFO 139780359198336] processed a total of 615 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529514.0528908, \"EndTime\": 1617529527.713872, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13660.602331161499, \"count\": 1, \"min\": 13660.602331161499, \"max\": 13660.602331161499}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:27 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.019594149145775 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:27 INFO 139780359198336] #progress_metric: host=algo-1, completed 91.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:27 INFO 139780359198336] #quality_metric: host=algo-1, epoch=365, train loss <loss>=2.4312971353530886\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:27 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:32 INFO 139780359198336] Epoch[366] Batch[0] avg_epoch_loss=2.509395\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:32 INFO 139780359198336] #quality_metric: host=algo-1, epoch=366, batch=0 train loss <loss>=2.509394884109497\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:45:37 INFO 139780359198336] Epoch[366] Batch[5] avg_epoch_loss=2.476960\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:37 INFO 139780359198336] #quality_metric: host=algo-1, epoch=366, batch=5 train loss <loss>=2.4769599437713623\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:37 INFO 139780359198336] Epoch[366] Batch [5]#011Speed: 61.26 samples/sec#011loss=2.476960\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:41 INFO 139780359198336] processed a total of 607 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529527.713955, \"EndTime\": 1617529541.5280752, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13813.64631652832, \"count\": 1, \"min\": 13813.64631652832, \"max\": 13813.64631652832}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:41 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.941366671902585 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:41 INFO 139780359198336] #progress_metric: host=algo-1, completed 91.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:41 INFO 139780359198336] #quality_metric: host=algo-1, epoch=366, train loss <loss>=2.4497730016708372\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:41 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:45 INFO 139780359198336] Epoch[367] Batch[0] avg_epoch_loss=2.512982\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:45 INFO 139780359198336] #quality_metric: host=algo-1, epoch=367, batch=0 train loss <loss>=2.512981653213501\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:51 INFO 139780359198336] Epoch[367] Batch[5] avg_epoch_loss=2.448337\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:51 INFO 139780359198336] #quality_metric: host=algo-1, epoch=367, batch=5 train loss <loss>=2.448336879412333\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:51 INFO 139780359198336] Epoch[367] Batch [5]#011Speed: 61.18 samples/sec#011loss=2.448337\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:55 INFO 139780359198336] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529541.5282195, \"EndTime\": 1617529555.366432, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13837.634325027466, \"count\": 1, \"min\": 13837.634325027466, \"max\": 13837.634325027466}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:55 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.03351847040012 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:55 INFO 139780359198336] #progress_metric: host=algo-1, completed 92.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:55 INFO 139780359198336] #quality_metric: host=algo-1, epoch=367, train loss <loss>=2.4272010564804076\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:55 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:59 INFO 139780359198336] Epoch[368] Batch[0] avg_epoch_loss=2.515912\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:45:59 INFO 139780359198336] #quality_metric: host=algo-1, epoch=368, batch=0 train loss <loss>=2.5159120559692383\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:05 INFO 139780359198336] Epoch[368] Batch[5] avg_epoch_loss=2.434850\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:05 INFO 139780359198336] #quality_metric: host=algo-1, epoch=368, batch=5 train loss <loss>=2.434849500656128\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:05 INFO 139780359198336] Epoch[368] Batch [5]#011Speed: 55.42 samples/sec#011loss=2.434850\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:10 INFO 139780359198336] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529555.3665066, \"EndTime\": 1617529570.0239186, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14656.69059753418, \"count\": 1, \"min\": 14656.69059753418, \"max\": 14656.69059753418}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:10 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.11993938743564 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:10 INFO 139780359198336] #progress_metric: host=algo-1, completed 92.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:10 INFO 139780359198336] #quality_metric: host=algo-1, epoch=368, train loss <loss>=2.4356011152267456\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:10 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:14 INFO 139780359198336] Epoch[369] Batch[0] avg_epoch_loss=2.509348\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:14 INFO 139780359198336] #quality_metric: host=algo-1, epoch=369, batch=0 train loss <loss>=2.5093483924865723\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:19 INFO 139780359198336] Epoch[369] Batch[5] avg_epoch_loss=2.450654\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:19 INFO 139780359198336] #quality_metric: host=algo-1, epoch=369, batch=5 train loss <loss>=2.4506544272104898\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:19 INFO 139780359198336] Epoch[369] Batch [5]#011Speed: 61.68 samples/sec#011loss=2.450654\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:25 INFO 139780359198336] Epoch[369] Batch[10] avg_epoch_loss=2.395055\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:25 INFO 139780359198336] #quality_metric: host=algo-1, epoch=369, batch=10 train loss <loss>=2.328335237503052\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:25 INFO 139780359198336] Epoch[369] Batch [10]#011Speed: 58.59 samples/sec#011loss=2.328335\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:25 INFO 139780359198336] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529570.0239878, \"EndTime\": 1617529585.0029266, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14978.49440574646, \"count\": 1, \"min\": 14978.49440574646, \"max\": 14978.49440574646}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:25 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.662317871978 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:25 INFO 139780359198336] #progress_metric: host=algo-1, completed 92.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:25 INFO 139780359198336] #quality_metric: host=algo-1, epoch=369, train loss <loss>=2.3950547955252905\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:25 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:29 INFO 139780359198336] Epoch[370] Batch[0] avg_epoch_loss=2.525884\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:29 INFO 139780359198336] #quality_metric: host=algo-1, epoch=370, batch=0 train loss <loss>=2.525883674621582\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:34 INFO 139780359198336] Epoch[370] Batch[5] avg_epoch_loss=2.455160\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:34 INFO 139780359198336] #quality_metric: host=algo-1, epoch=370, batch=5 train loss <loss>=2.455160140991211\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:34 INFO 139780359198336] Epoch[370] Batch [5]#011Speed: 62.06 samples/sec#011loss=2.455160\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:39 INFO 139780359198336] Epoch[370] Batch[10] avg_epoch_loss=2.463506\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:39 INFO 139780359198336] #quality_metric: host=algo-1, epoch=370, batch=10 train loss <loss>=2.4735207557678223\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:39 INFO 139780359198336] Epoch[370] Batch [10]#011Speed: 60.22 samples/sec#011loss=2.473521\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:39 INFO 139780359198336] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529585.0029938, \"EndTime\": 1617529599.7610378, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14757.696628570557, \"count\": 1, \"min\": 14757.696628570557, \"max\": 14757.696628570557}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:39 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.84123397518435 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:39 INFO 139780359198336] #progress_metric: host=algo-1, completed 92.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:39 INFO 139780359198336] #quality_metric: host=algo-1, epoch=370, train loss <loss>=2.4635058749805796\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:39 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:43 INFO 139780359198336] Epoch[371] Batch[0] avg_epoch_loss=2.467249\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:43 INFO 139780359198336] #quality_metric: host=algo-1, epoch=371, batch=0 train loss <loss>=2.4672486782073975\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:49 INFO 139780359198336] Epoch[371] Batch[5] avg_epoch_loss=2.421968\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:49 INFO 139780359198336] #quality_metric: host=algo-1, epoch=371, batch=5 train loss <loss>=2.421968460083008\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:49 INFO 139780359198336] Epoch[371] Batch [5]#011Speed: 60.29 samples/sec#011loss=2.421968\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:54 INFO 139780359198336] Epoch[371] Batch[10] avg_epoch_loss=2.413909\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:54 INFO 139780359198336] #quality_metric: host=algo-1, epoch=371, batch=10 train loss <loss>=2.404238224029541\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:54 INFO 139780359198336] Epoch[371] Batch [10]#011Speed: 58.82 samples/sec#011loss=2.404238\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:54 INFO 139780359198336] processed a total of 676 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529599.7611024, \"EndTime\": 1617529614.6416776, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14880.195617675781, \"count\": 1, \"min\": 14880.195617675781, \"max\": 14880.195617675781}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:54 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.42921768224957 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:54 INFO 139780359198336] #progress_metric: host=algo-1, completed 93.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:54 INFO 139780359198336] #quality_metric: host=algo-1, epoch=371, train loss <loss>=2.4139092618768867\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:54 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:58 INFO 139780359198336] Epoch[372] Batch[0] avg_epoch_loss=2.443595\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:46:58 INFO 139780359198336] #quality_metric: host=algo-1, epoch=372, batch=0 train loss <loss>=2.4435954093933105\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:04 INFO 139780359198336] Epoch[372] Batch[5] avg_epoch_loss=2.463108\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:04 INFO 139780359198336] #quality_metric: host=algo-1, epoch=372, batch=5 train loss <loss>=2.4631083011627197\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:04 INFO 139780359198336] Epoch[372] Batch [5]#011Speed: 56.87 samples/sec#011loss=2.463108\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:47:09 INFO 139780359198336] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529614.6417446, \"EndTime\": 1617529629.0919857, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14449.883222579956, \"count\": 1, \"min\": 14449.883222579956, \"max\": 14449.883222579956}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:09 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=42.8373997863735 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:09 INFO 139780359198336] #progress_metric: host=algo-1, completed 93.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:09 INFO 139780359198336] #quality_metric: host=algo-1, epoch=372, train loss <loss>=2.501129388809204\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:09 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:13 INFO 139780359198336] Epoch[373] Batch[0] avg_epoch_loss=2.541819\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:13 INFO 139780359198336] #quality_metric: host=algo-1, epoch=373, batch=0 train loss <loss>=2.5418190956115723\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:18 INFO 139780359198336] Epoch[373] Batch[5] avg_epoch_loss=2.492155\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:18 INFO 139780359198336] #quality_metric: host=algo-1, epoch=373, batch=5 train loss <loss>=2.4921553134918213\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:18 INFO 139780359198336] Epoch[373] Batch [5]#011Speed: 60.35 samples/sec#011loss=2.492155\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:22 INFO 139780359198336] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529629.0920594, \"EndTime\": 1617529642.783684, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13691.092252731323, \"count\": 1, \"min\": 13691.092252731323, \"max\": 13691.092252731323}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:22 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.30713627303049 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:22 INFO 139780359198336] #progress_metric: host=algo-1, completed 93.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:22 INFO 139780359198336] #quality_metric: host=algo-1, epoch=373, train loss <loss>=2.449399471282959\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:22 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:26 INFO 139780359198336] Epoch[374] Batch[0] avg_epoch_loss=2.499351\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:26 INFO 139780359198336] #quality_metric: host=algo-1, epoch=374, batch=0 train loss <loss>=2.4993510246276855\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:32 INFO 139780359198336] Epoch[374] Batch[5] avg_epoch_loss=2.411954\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:32 INFO 139780359198336] #quality_metric: host=algo-1, epoch=374, batch=5 train loss <loss>=2.411953568458557\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:32 INFO 139780359198336] Epoch[374] Batch [5]#011Speed: 62.81 samples/sec#011loss=2.411954\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:37 INFO 139780359198336] Epoch[374] Batch[10] avg_epoch_loss=2.387466\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:37 INFO 139780359198336] #quality_metric: host=algo-1, epoch=374, batch=10 train loss <loss>=2.358081817626953\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:37 INFO 139780359198336] Epoch[374] Batch [10]#011Speed: 61.83 samples/sec#011loss=2.358082\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:37 INFO 139780359198336] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529642.7837539, \"EndTime\": 1617529657.2422998, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14458.008289337158, \"count\": 1, \"min\": 14458.008289337158, \"max\": 14458.008289337158}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:37 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.47330475399649 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:37 INFO 139780359198336] #progress_metric: host=algo-1, completed 93.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:37 INFO 139780359198336] #quality_metric: host=algo-1, epoch=374, train loss <loss>=2.387466408989646\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:37 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:41 INFO 139780359198336] Epoch[375] Batch[0] avg_epoch_loss=2.412877\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:41 INFO 139780359198336] #quality_metric: host=algo-1, epoch=375, batch=0 train loss <loss>=2.412876844406128\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:46 INFO 139780359198336] Epoch[375] Batch[5] avg_epoch_loss=2.466002\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:46 INFO 139780359198336] #quality_metric: host=algo-1, epoch=375, batch=5 train loss <loss>=2.466002345085144\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:46 INFO 139780359198336] Epoch[375] Batch [5]#011Speed: 61.63 samples/sec#011loss=2.466002\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:51 INFO 139780359198336] Epoch[375] Batch[10] avg_epoch_loss=2.492526\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:51 INFO 139780359198336] #quality_metric: host=algo-1, epoch=375, batch=10 train loss <loss>=2.5243538856506347\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:51 INFO 139780359198336] Epoch[375] Batch [10]#011Speed: 60.51 samples/sec#011loss=2.524354\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:51 INFO 139780359198336] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529657.24236, \"EndTime\": 1617529671.7537625, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14510.94913482666, \"count\": 1, \"min\": 14510.94913482666, \"max\": 14510.94913482666}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:51 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.9649844049999 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:51 INFO 139780359198336] #progress_metric: host=algo-1, completed 94.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:51 INFO 139780359198336] #quality_metric: host=algo-1, epoch=375, train loss <loss>=2.4925257726149126\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:51 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:55 INFO 139780359198336] Epoch[376] Batch[0] avg_epoch_loss=2.411368\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:47:55 INFO 139780359198336] #quality_metric: host=algo-1, epoch=376, batch=0 train loss <loss>=2.4113683700561523\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:01 INFO 139780359198336] Epoch[376] Batch[5] avg_epoch_loss=2.436758\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:01 INFO 139780359198336] #quality_metric: host=algo-1, epoch=376, batch=5 train loss <loss>=2.436758120854696\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:01 INFO 139780359198336] Epoch[376] Batch [5]#011Speed: 63.08 samples/sec#011loss=2.436758\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:05 INFO 139780359198336] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529671.7538276, \"EndTime\": 1617529685.8075335, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14053.3607006073, \"count\": 1, \"min\": 14053.3607006073, \"max\": 14053.3607006073}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:05 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.974909219294844 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:05 INFO 139780359198336] #progress_metric: host=algo-1, completed 94.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:05 INFO 139780359198336] #quality_metric: host=algo-1, epoch=376, train loss <loss>=2.4173548460006713\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:05 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:10 INFO 139780359198336] Epoch[377] Batch[0] avg_epoch_loss=2.444530\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:10 INFO 139780359198336] #quality_metric: host=algo-1, epoch=377, batch=0 train loss <loss>=2.4445297718048096\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:15 INFO 139780359198336] Epoch[377] Batch[5] avg_epoch_loss=2.459238\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:15 INFO 139780359198336] #quality_metric: host=algo-1, epoch=377, batch=5 train loss <loss>=2.459237575531006\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:15 INFO 139780359198336] Epoch[377] Batch [5]#011Speed: 63.50 samples/sec#011loss=2.459238\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:20 INFO 139780359198336] Epoch[377] Batch[10] avg_epoch_loss=2.503838\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:20 INFO 139780359198336] #quality_metric: host=algo-1, epoch=377, batch=10 train loss <loss>=2.557357931137085\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:20 INFO 139780359198336] Epoch[377] Batch [10]#011Speed: 59.72 samples/sec#011loss=2.557358\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:20 INFO 139780359198336] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529685.8076096, \"EndTime\": 1617529700.4238567, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14615.604639053345, \"count\": 1, \"min\": 14615.604639053345, \"max\": 14615.604639053345}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:20 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.335852818570864 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:20 INFO 139780359198336] #progress_metric: host=algo-1, completed 94.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:20 INFO 139780359198336] #quality_metric: host=algo-1, epoch=377, train loss <loss>=2.503837737170133\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:20 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:24 INFO 139780359198336] Epoch[378] Batch[0] avg_epoch_loss=2.442056\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:24 INFO 139780359198336] #quality_metric: host=algo-1, epoch=378, batch=0 train loss <loss>=2.4420557022094727\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:48:29 INFO 139780359198336] Epoch[378] Batch[5] avg_epoch_loss=2.427793\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:29 INFO 139780359198336] #quality_metric: host=algo-1, epoch=378, batch=5 train loss <loss>=2.427792946497599\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:29 INFO 139780359198336] Epoch[378] Batch [5]#011Speed: 63.04 samples/sec#011loss=2.427793\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:33 INFO 139780359198336] processed a total of 614 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529700.4239316, \"EndTime\": 1617529713.901887, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13477.628946304321, \"count\": 1, \"min\": 13477.628946304321, \"max\": 13477.628946304321}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:33 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.556554761193716 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:33 INFO 139780359198336] #progress_metric: host=algo-1, completed 94.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:33 INFO 139780359198336] #quality_metric: host=algo-1, epoch=378, train loss <loss>=2.4712262392044066\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:33 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:38 INFO 139780359198336] Epoch[379] Batch[0] avg_epoch_loss=2.440594\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:38 INFO 139780359198336] #quality_metric: host=algo-1, epoch=379, batch=0 train loss <loss>=2.440594434738159\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:43 INFO 139780359198336] Epoch[379] Batch[5] avg_epoch_loss=2.453212\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:43 INFO 139780359198336] #quality_metric: host=algo-1, epoch=379, batch=5 train loss <loss>=2.453211784362793\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:43 INFO 139780359198336] Epoch[379] Batch [5]#011Speed: 62.40 samples/sec#011loss=2.453212\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:47 INFO 139780359198336] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529713.9019723, \"EndTime\": 1617529727.5933287, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13690.810203552246, \"count\": 1, \"min\": 13690.810203552246, \"max\": 13690.810203552246}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:47 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.45415071692741 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:47 INFO 139780359198336] #progress_metric: host=algo-1, completed 95.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:47 INFO 139780359198336] #quality_metric: host=algo-1, epoch=379, train loss <loss>=2.467928957939148\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:47 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:51 INFO 139780359198336] Epoch[380] Batch[0] avg_epoch_loss=2.495789\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:51 INFO 139780359198336] #quality_metric: host=algo-1, epoch=380, batch=0 train loss <loss>=2.495788812637329\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:56 INFO 139780359198336] Epoch[380] Batch[5] avg_epoch_loss=2.453490\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:56 INFO 139780359198336] #quality_metric: host=algo-1, epoch=380, batch=5 train loss <loss>=2.4534902969996133\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:48:56 INFO 139780359198336] Epoch[380] Batch [5]#011Speed: 62.39 samples/sec#011loss=2.453490\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:02 INFO 139780359198336] Epoch[380] Batch[10] avg_epoch_loss=2.453551\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:02 INFO 139780359198336] #quality_metric: host=algo-1, epoch=380, batch=10 train loss <loss>=2.453623580932617\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:02 INFO 139780359198336] Epoch[380] Batch [10]#011Speed: 59.15 samples/sec#011loss=2.453624\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:02 INFO 139780359198336] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529727.5934014, \"EndTime\": 1617529742.2305634, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14636.613607406616, \"count\": 1, \"min\": 14636.613607406616, \"max\": 14636.613607406616}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:02 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.16039424703183 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:02 INFO 139780359198336] #progress_metric: host=algo-1, completed 95.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:02 INFO 139780359198336] #quality_metric: host=algo-1, epoch=380, train loss <loss>=2.4535508806055244\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:02 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:06 INFO 139780359198336] Epoch[381] Batch[0] avg_epoch_loss=2.466815\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:06 INFO 139780359198336] #quality_metric: host=algo-1, epoch=381, batch=0 train loss <loss>=2.4668145179748535\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:11 INFO 139780359198336] Epoch[381] Batch[5] avg_epoch_loss=2.469263\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:11 INFO 139780359198336] #quality_metric: host=algo-1, epoch=381, batch=5 train loss <loss>=2.469263275464376\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:11 INFO 139780359198336] Epoch[381] Batch [5]#011Speed: 62.52 samples/sec#011loss=2.469263\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:16 INFO 139780359198336] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529742.2306342, \"EndTime\": 1617529756.0864706, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13855.449438095093, \"count\": 1, \"min\": 13855.449438095093, \"max\": 13855.449438095093}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:16 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.324776420363584 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:16 INFO 139780359198336] #progress_metric: host=algo-1, completed 95.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:16 INFO 139780359198336] #quality_metric: host=algo-1, epoch=381, train loss <loss>=2.437912368774414\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:16 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:20 INFO 139780359198336] Epoch[382] Batch[0] avg_epoch_loss=2.576655\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:20 INFO 139780359198336] #quality_metric: host=algo-1, epoch=382, batch=0 train loss <loss>=2.5766546726226807\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:25 INFO 139780359198336] Epoch[382] Batch[5] avg_epoch_loss=2.474901\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:25 INFO 139780359198336] #quality_metric: host=algo-1, epoch=382, batch=5 train loss <loss>=2.4749005238215127\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:25 INFO 139780359198336] Epoch[382] Batch [5]#011Speed: 62.13 samples/sec#011loss=2.474901\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:29 INFO 139780359198336] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529756.0865433, \"EndTime\": 1617529769.718385, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13631.459712982178, \"count\": 1, \"min\": 13631.459712982178, \"max\": 13631.459712982178}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:29 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.58301003928501 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:29 INFO 139780359198336] #progress_metric: host=algo-1, completed 95.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:29 INFO 139780359198336] #quality_metric: host=algo-1, epoch=382, train loss <loss>=2.4730343580245973\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:29 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:34 INFO 139780359198336] Epoch[383] Batch[0] avg_epoch_loss=2.400444\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:34 INFO 139780359198336] #quality_metric: host=algo-1, epoch=383, batch=0 train loss <loss>=2.4004440307617188\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:39 INFO 139780359198336] Epoch[383] Batch[5] avg_epoch_loss=2.464095\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:39 INFO 139780359198336] #quality_metric: host=algo-1, epoch=383, batch=5 train loss <loss>=2.464094956715902\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:39 INFO 139780359198336] Epoch[383] Batch [5]#011Speed: 62.75 samples/sec#011loss=2.464095\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:43 INFO 139780359198336] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529769.7184708, \"EndTime\": 1617529783.2918797, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13573.045253753662, \"count\": 1, \"min\": 13573.045253753662, \"max\": 13573.045253753662}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:43 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.120418248551516 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:43 INFO 139780359198336] #progress_metric: host=algo-1, completed 96.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:43 INFO 139780359198336] #quality_metric: host=algo-1, epoch=383, train loss <loss>=2.4514831066131593\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:43 INFO 139780359198336] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:49:47 INFO 139780359198336] Epoch[384] Batch[0] avg_epoch_loss=2.465906\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:47 INFO 139780359198336] #quality_metric: host=algo-1, epoch=384, batch=0 train loss <loss>=2.4659059047698975\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:52 INFO 139780359198336] Epoch[384] Batch[5] avg_epoch_loss=2.509413\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:52 INFO 139780359198336] #quality_metric: host=algo-1, epoch=384, batch=5 train loss <loss>=2.509412964185079\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:52 INFO 139780359198336] Epoch[384] Batch [5]#011Speed: 60.66 samples/sec#011loss=2.509413\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:58 INFO 139780359198336] Epoch[384] Batch[10] avg_epoch_loss=2.508626\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:58 INFO 139780359198336] #quality_metric: host=algo-1, epoch=384, batch=10 train loss <loss>=2.507682180404663\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:58 INFO 139780359198336] Epoch[384] Batch [10]#011Speed: 59.10 samples/sec#011loss=2.507682\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:58 INFO 139780359198336] processed a total of 688 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529783.291966, \"EndTime\": 1617529798.1000347, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14807.71279335022, \"count\": 1, \"min\": 14807.71279335022, \"max\": 14807.71279335022}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:58 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.46184174159641 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:58 INFO 139780359198336] #progress_metric: host=algo-1, completed 96.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:58 INFO 139780359198336] #quality_metric: host=algo-1, epoch=384, train loss <loss>=2.50862624428489\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:49:58 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:02 INFO 139780359198336] Epoch[385] Batch[0] avg_epoch_loss=2.392240\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:02 INFO 139780359198336] #quality_metric: host=algo-1, epoch=385, batch=0 train loss <loss>=2.392239809036255\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:08 INFO 139780359198336] Epoch[385] Batch[5] avg_epoch_loss=2.457821\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:08 INFO 139780359198336] #quality_metric: host=algo-1, epoch=385, batch=5 train loss <loss>=2.4578205347061157\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:08 INFO 139780359198336] Epoch[385] Batch [5]#011Speed: 54.41 samples/sec#011loss=2.457821\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:12 INFO 139780359198336] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529798.1001368, \"EndTime\": 1617529812.539843, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14439.25404548645, \"count\": 1, \"min\": 14439.25404548645, \"max\": 14439.25404548645}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:12 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.28446576194696 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:12 INFO 139780359198336] #progress_metric: host=algo-1, completed 96.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:12 INFO 139780359198336] #quality_metric: host=algo-1, epoch=385, train loss <loss>=2.4618195056915284\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:12 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:16 INFO 139780359198336] Epoch[386] Batch[0] avg_epoch_loss=2.488082\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:16 INFO 139780359198336] #quality_metric: host=algo-1, epoch=386, batch=0 train loss <loss>=2.4880824089050293\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:21 INFO 139780359198336] Epoch[386] Batch[5] avg_epoch_loss=2.443474\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:21 INFO 139780359198336] #quality_metric: host=algo-1, epoch=386, batch=5 train loss <loss>=2.443474372227987\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:21 INFO 139780359198336] Epoch[386] Batch [5]#011Speed: 60.97 samples/sec#011loss=2.443474\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:27 INFO 139780359198336] Epoch[386] Batch[10] avg_epoch_loss=2.423886\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:27 INFO 139780359198336] #quality_metric: host=algo-1, epoch=386, batch=10 train loss <loss>=2.4003788948059084\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:27 INFO 139780359198336] Epoch[386] Batch [10]#011Speed: 59.92 samples/sec#011loss=2.400379\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:27 INFO 139780359198336] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529812.5399148, \"EndTime\": 1617529827.2645679, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14724.157333374023, \"count\": 1, \"min\": 14724.157333374023, \"max\": 14724.157333374023}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:27 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.68817119544304 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:27 INFO 139780359198336] #progress_metric: host=algo-1, completed 96.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:27 INFO 139780359198336] #quality_metric: host=algo-1, epoch=386, train loss <loss>=2.4238855188543145\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:27 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:31 INFO 139780359198336] Epoch[387] Batch[0] avg_epoch_loss=2.349394\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:31 INFO 139780359198336] #quality_metric: host=algo-1, epoch=387, batch=0 train loss <loss>=2.3493940830230713\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:36 INFO 139780359198336] Epoch[387] Batch[5] avg_epoch_loss=2.434153\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:36 INFO 139780359198336] #quality_metric: host=algo-1, epoch=387, batch=5 train loss <loss>=2.4341530402501426\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:36 INFO 139780359198336] Epoch[387] Batch [5]#011Speed: 62.74 samples/sec#011loss=2.434153\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:40 INFO 139780359198336] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529827.264634, \"EndTime\": 1617529840.8062177, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13541.20922088623, \"count\": 1, \"min\": 13541.20922088623, \"max\": 13541.20922088623}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:40 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.00711749386324 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:40 INFO 139780359198336] #progress_metric: host=algo-1, completed 97.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:40 INFO 139780359198336] #quality_metric: host=algo-1, epoch=387, train loss <loss>=2.417184352874756\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:40 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:44 INFO 139780359198336] Epoch[388] Batch[0] avg_epoch_loss=2.391722\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:44 INFO 139780359198336] #quality_metric: host=algo-1, epoch=388, batch=0 train loss <loss>=2.3917219638824463\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:50 INFO 139780359198336] Epoch[388] Batch[5] avg_epoch_loss=2.439198\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:50 INFO 139780359198336] #quality_metric: host=algo-1, epoch=388, batch=5 train loss <loss>=2.4391981760660806\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:50 INFO 139780359198336] Epoch[388] Batch [5]#011Speed: 60.77 samples/sec#011loss=2.439198\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:55 INFO 139780359198336] Epoch[388] Batch[10] avg_epoch_loss=2.431447\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:55 INFO 139780359198336] #quality_metric: host=algo-1, epoch=388, batch=10 train loss <loss>=2.4221449375152586\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:55 INFO 139780359198336] Epoch[388] Batch [10]#011Speed: 59.91 samples/sec#011loss=2.422145\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:55 INFO 139780359198336] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529840.8063357, \"EndTime\": 1617529855.5451534, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14737.64944076538, \"count\": 1, \"min\": 14737.64944076538, \"max\": 14737.64944076538}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:55 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.579366718032595 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:55 INFO 139780359198336] #progress_metric: host=algo-1, completed 97.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:55 INFO 139780359198336] #quality_metric: host=algo-1, epoch=388, train loss <loss>=2.4314467039975254\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:55 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:59 INFO 139780359198336] Epoch[389] Batch[0] avg_epoch_loss=2.596408\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:50:59 INFO 139780359198336] #quality_metric: host=algo-1, epoch=389, batch=0 train loss <loss>=2.596407890319824\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:05 INFO 139780359198336] Epoch[389] Batch[5] avg_epoch_loss=2.445140\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:05 INFO 139780359198336] #quality_metric: host=algo-1, epoch=389, batch=5 train loss <loss>=2.44514008363088\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:05 INFO 139780359198336] Epoch[389] Batch [5]#011Speed: 55.62 samples/sec#011loss=2.445140\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:51:10 INFO 139780359198336] processed a total of 616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529855.5452306, \"EndTime\": 1617529870.0864136, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14540.778160095215, \"count\": 1, \"min\": 14540.778160095215, \"max\": 14540.778160095215}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:10 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=42.363340732828426 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:10 INFO 139780359198336] #progress_metric: host=algo-1, completed 97.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:10 INFO 139780359198336] #quality_metric: host=algo-1, epoch=389, train loss <loss>=2.450956630706787\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:10 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:14 INFO 139780359198336] Epoch[390] Batch[0] avg_epoch_loss=2.554639\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:14 INFO 139780359198336] #quality_metric: host=algo-1, epoch=390, batch=0 train loss <loss>=2.554638624191284\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:19 INFO 139780359198336] Epoch[390] Batch[5] avg_epoch_loss=2.511081\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:19 INFO 139780359198336] #quality_metric: host=algo-1, epoch=390, batch=5 train loss <loss>=2.5110809008280435\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:19 INFO 139780359198336] Epoch[390] Batch [5]#011Speed: 62.58 samples/sec#011loss=2.511081\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:24 INFO 139780359198336] Epoch[390] Batch[10] avg_epoch_loss=2.492203\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:24 INFO 139780359198336] #quality_metric: host=algo-1, epoch=390, batch=10 train loss <loss>=2.4695489406585693\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:24 INFO 139780359198336] Epoch[390] Batch [10]#011Speed: 58.16 samples/sec#011loss=2.469549\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:24 INFO 139780359198336] processed a total of 670 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529870.0864823, \"EndTime\": 1617529884.809932, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14722.982168197632, \"count\": 1, \"min\": 14722.982168197632, \"max\": 14722.982168197632}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:24 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.50673121204535 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:24 INFO 139780359198336] #progress_metric: host=algo-1, completed 97.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:24 INFO 139780359198336] #quality_metric: host=algo-1, epoch=390, train loss <loss>=2.492202737114646\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:24 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:28 INFO 139780359198336] Epoch[391] Batch[0] avg_epoch_loss=2.298598\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:28 INFO 139780359198336] #quality_metric: host=algo-1, epoch=391, batch=0 train loss <loss>=2.298598289489746\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:34 INFO 139780359198336] Epoch[391] Batch[5] avg_epoch_loss=2.385135\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:34 INFO 139780359198336] #quality_metric: host=algo-1, epoch=391, batch=5 train loss <loss>=2.3851354519526162\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:34 INFO 139780359198336] Epoch[391] Batch [5]#011Speed: 62.75 samples/sec#011loss=2.385135\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:39 INFO 139780359198336] Epoch[391] Batch[10] avg_epoch_loss=2.357301\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:39 INFO 139780359198336] #quality_metric: host=algo-1, epoch=391, batch=10 train loss <loss>=2.323900556564331\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:39 INFO 139780359198336] Epoch[391] Batch [10]#011Speed: 60.13 samples/sec#011loss=2.323901\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:39 INFO 139780359198336] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529884.8100092, \"EndTime\": 1617529899.3510327, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14540.632724761963, \"count\": 1, \"min\": 14540.632724761963, \"max\": 14540.632724761963}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:39 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.252094603854225 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:39 INFO 139780359198336] #progress_metric: host=algo-1, completed 98.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:39 INFO 139780359198336] #quality_metric: host=algo-1, epoch=391, train loss <loss>=2.3573014085943047\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:39 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:43 INFO 139780359198336] Epoch[392] Batch[0] avg_epoch_loss=2.444759\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:43 INFO 139780359198336] #quality_metric: host=algo-1, epoch=392, batch=0 train loss <loss>=2.4447591304779053\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:48 INFO 139780359198336] Epoch[392] Batch[5] avg_epoch_loss=2.464270\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:48 INFO 139780359198336] #quality_metric: host=algo-1, epoch=392, batch=5 train loss <loss>=2.4642697970072427\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:48 INFO 139780359198336] Epoch[392] Batch [5]#011Speed: 62.31 samples/sec#011loss=2.464270\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:53 INFO 139780359198336] processed a total of 613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529899.3511333, \"EndTime\": 1617529913.0543063, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13702.853202819824, \"count\": 1, \"min\": 13702.853202819824, \"max\": 13702.853202819824}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:53 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=44.73479866944028 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:53 INFO 139780359198336] #progress_metric: host=algo-1, completed 98.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:53 INFO 139780359198336] #quality_metric: host=algo-1, epoch=392, train loss <loss>=2.45294029712677\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:53 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:57 INFO 139780359198336] Epoch[393] Batch[0] avg_epoch_loss=2.286797\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:51:57 INFO 139780359198336] #quality_metric: host=algo-1, epoch=393, batch=0 train loss <loss>=2.286797285079956\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:02 INFO 139780359198336] Epoch[393] Batch[5] avg_epoch_loss=2.418228\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:02 INFO 139780359198336] #quality_metric: host=algo-1, epoch=393, batch=5 train loss <loss>=2.4182276725769043\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:02 INFO 139780359198336] Epoch[393] Batch [5]#011Speed: 59.93 samples/sec#011loss=2.418228\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:07 INFO 139780359198336] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529913.0543985, \"EndTime\": 1617529927.4752204, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14420.342206954956, \"count\": 1, \"min\": 14420.342206954956, \"max\": 14420.342206954956}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:07 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=43.61850514330277 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:07 INFO 139780359198336] #progress_metric: host=algo-1, completed 98.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:07 INFO 139780359198336] #quality_metric: host=algo-1, epoch=393, train loss <loss>=2.474024438858032\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:07 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:11 INFO 139780359198336] Epoch[394] Batch[0] avg_epoch_loss=2.524941\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:11 INFO 139780359198336] #quality_metric: host=algo-1, epoch=394, batch=0 train loss <loss>=2.5249407291412354\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:16 INFO 139780359198336] Epoch[394] Batch[5] avg_epoch_loss=2.459776\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:16 INFO 139780359198336] #quality_metric: host=algo-1, epoch=394, batch=5 train loss <loss>=2.459776441256205\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:16 INFO 139780359198336] Epoch[394] Batch [5]#011Speed: 62.52 samples/sec#011loss=2.459776\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:22 INFO 139780359198336] Epoch[394] Batch[10] avg_epoch_loss=2.490717\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:22 INFO 139780359198336] #quality_metric: host=algo-1, epoch=394, batch=10 train loss <loss>=2.527844858169556\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:22 INFO 139780359198336] Epoch[394] Batch [10]#011Speed: 58.56 samples/sec#011loss=2.527845\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:22 INFO 139780359198336] processed a total of 673 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529927.4753118, \"EndTime\": 1617529942.129147, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14653.436660766602, \"count\": 1, \"min\": 14653.436660766602, \"max\": 14653.436660766602}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:22 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.927447376346436 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:22 INFO 139780359198336] #progress_metric: host=algo-1, completed 98.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:22 INFO 139780359198336] #quality_metric: host=algo-1, epoch=394, train loss <loss>=2.4907166307622735\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:22 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:26 INFO 139780359198336] Epoch[395] Batch[0] avg_epoch_loss=2.381899\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:26 INFO 139780359198336] #quality_metric: host=algo-1, epoch=395, batch=0 train loss <loss>=2.3818986415863037\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/04/2021 09:52:31 INFO 139780359198336] Epoch[395] Batch[5] avg_epoch_loss=2.432020\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:31 INFO 139780359198336] #quality_metric: host=algo-1, epoch=395, batch=5 train loss <loss>=2.4320202668507895\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:31 INFO 139780359198336] Epoch[395] Batch [5]#011Speed: 63.19 samples/sec#011loss=2.432020\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:36 INFO 139780359198336] Epoch[395] Batch[10] avg_epoch_loss=2.409468\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:36 INFO 139780359198336] #quality_metric: host=algo-1, epoch=395, batch=10 train loss <loss>=2.382405424118042\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:36 INFO 139780359198336] Epoch[395] Batch [10]#011Speed: 59.52 samples/sec#011loss=2.382405\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:36 INFO 139780359198336] processed a total of 685 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529942.1292264, \"EndTime\": 1617529956.5949373, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 14465.210676193237, \"count\": 1, \"min\": 14465.210676193237, \"max\": 14465.210676193237}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:36 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=47.35466549885561 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:36 INFO 139780359198336] #progress_metric: host=algo-1, completed 99.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:36 INFO 139780359198336] #quality_metric: host=algo-1, epoch=395, train loss <loss>=2.4094680656086314\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:36 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:40 INFO 139780359198336] Epoch[396] Batch[0] avg_epoch_loss=2.452051\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:40 INFO 139780359198336] #quality_metric: host=algo-1, epoch=396, batch=0 train loss <loss>=2.4520514011383057\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:45 INFO 139780359198336] Epoch[396] Batch[5] avg_epoch_loss=2.490360\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:45 INFO 139780359198336] #quality_metric: host=algo-1, epoch=396, batch=5 train loss <loss>=2.4903601805369058\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:45 INFO 139780359198336] Epoch[396] Batch [5]#011Speed: 63.46 samples/sec#011loss=2.490360\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:49 INFO 139780359198336] processed a total of 617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529956.595005, \"EndTime\": 1617529969.9838176, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13388.291358947754, \"count\": 1, \"min\": 13388.291358947754, \"max\": 13388.291358947754}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:49 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.084176827106944 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:49 INFO 139780359198336] #progress_metric: host=algo-1, completed 99.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:49 INFO 139780359198336] #quality_metric: host=algo-1, epoch=396, train loss <loss>=2.4349367380142213\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:49 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:54 INFO 139780359198336] Epoch[397] Batch[0] avg_epoch_loss=2.463759\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:54 INFO 139780359198336] #quality_metric: host=algo-1, epoch=397, batch=0 train loss <loss>=2.463758945465088\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:59 INFO 139780359198336] Epoch[397] Batch[5] avg_epoch_loss=2.465652\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:59 INFO 139780359198336] #quality_metric: host=algo-1, epoch=397, batch=5 train loss <loss>=2.465651830037435\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:52:59 INFO 139780359198336] Epoch[397] Batch [5]#011Speed: 63.43 samples/sec#011loss=2.465652\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:53:03 INFO 139780359198336] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529969.9840171, \"EndTime\": 1617529983.6616716, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13677.26755142212, \"count\": 1, \"min\": 13677.26755142212, \"max\": 13677.26755142212}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:53:03 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=46.792645906747325 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:53:03 INFO 139780359198336] #progress_metric: host=algo-1, completed 99.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:53:03 INFO 139780359198336] #quality_metric: host=algo-1, epoch=397, train loss <loss>=2.4492817640304567\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:53:03 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:53:08 INFO 139780359198336] Epoch[398] Batch[0] avg_epoch_loss=2.377837\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:53:08 INFO 139780359198336] #quality_metric: host=algo-1, epoch=398, batch=0 train loss <loss>=2.3778374195098877\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:53:13 INFO 139780359198336] Epoch[398] Batch[5] avg_epoch_loss=2.434678\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:53:13 INFO 139780359198336] #quality_metric: host=algo-1, epoch=398, batch=5 train loss <loss>=2.434677561124166\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:53:13 INFO 139780359198336] Epoch[398] Batch [5]#011Speed: 63.33 samples/sec#011loss=2.434678\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:53:17 INFO 139780359198336] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529983.6617386, \"EndTime\": 1617529997.324314, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13662.179946899414, \"count\": 1, \"min\": 13662.179946899414, \"max\": 13662.179946899414}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:53:17 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.8195239718 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:53:17 INFO 139780359198336] #progress_metric: host=algo-1, completed 99.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:53:17 INFO 139780359198336] #quality_metric: host=algo-1, epoch=398, train loss <loss>=2.4618380308151244\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:53:17 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:53:21 INFO 139780359198336] Epoch[399] Batch[0] avg_epoch_loss=2.485166\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:53:21 INFO 139780359198336] #quality_metric: host=algo-1, epoch=399, batch=0 train loss <loss>=2.485166311264038\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:53:26 INFO 139780359198336] Epoch[399] Batch[5] avg_epoch_loss=2.412548\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:53:26 INFO 139780359198336] #quality_metric: host=algo-1, epoch=399, batch=5 train loss <loss>=2.4125475883483887\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:53:26 INFO 139780359198336] Epoch[399] Batch [5]#011Speed: 61.61 samples/sec#011loss=2.412548\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:53:30 INFO 139780359198336] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617529997.3243985, \"EndTime\": 1617530010.8707745, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13545.954942703247, \"count\": 1, \"min\": 13545.954942703247, \"max\": 13545.954942703247}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:53:30 INFO 139780359198336] #throughput_metric: host=algo-1, train throughput=45.769769198235224 records/second\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:53:30 INFO 139780359198336] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:53:30 INFO 139780359198336] #quality_metric: host=algo-1, epoch=399, train loss <loss>=2.415531063079834\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:53:30 INFO 139780359198336] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:53:30 INFO 139780359198336] Final loss: 2.3492721102454444 (occurred at epoch 215)\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:53:30 INFO 139780359198336] #quality_metric: host=algo-1, train final_loss <loss>=2.3492721102454444\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.6/site-packages/algorithm/run_worker.py:356: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\n",
      "  \"You are using large values for `context_length` and/or `prediction_length`. \"\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:53:30 WARNING 139780359198336] You are using large values for `context_length` and/or `prediction_length`. The following step may take some time. If the step crashes, use an instance with more memory or reduce these two parameters.\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:53:30 INFO 139780359198336] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:53:30 WARNING 139780359198336] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:53:30 INFO 139780359198336] All workers finished. Serializing model for prediction.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"StartTime\": 1617530010.8708496, \"EndTime\": 1617530025.5226464, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 14650.559902191162, \"count\": 1, \"min\": 14650.559902191162, \"max\": 14650.559902191162}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:53:46 INFO 139780359198336] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617530025.5227408, \"EndTime\": 1617530026.6047297, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 15732.687711715698, \"count\": 1, \"min\": 15732.687711715698, \"max\": 15732.687711715698}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:53:46 INFO 139780359198336] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:53:46 INFO 139780359198336] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617530026.6048021, \"EndTime\": 1617530026.7355595, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.serialize.time\": {\"sum\": 130.71155548095703, \"count\": 1, \"min\": 130.71155548095703, \"max\": 130.71155548095703}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:53:46 INFO 139780359198336] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:53:46 INFO 139780359198336] #memory_usage::<batchbuffer> = 213.4899139404297 mb\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:53:46 INFO 139780359198336] Evaluating model accuracy on testset using 100 samples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617530026.7356105, \"EndTime\": 1617530026.7365656, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.bind.time\": {\"sum\": 0.0400543212890625, \"count\": 1, \"min\": 0.0400543212890625, \"max\": 0.0400543212890625}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617530026.7366273, \"EndTime\": 1617530044.253815, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.score.time\": {\"sum\": 17517.289638519287, \"count\": 1, \"min\": 17517.289638519287, \"max\": 17517.289638519287}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:54:04 INFO 139780359198336] #test_score (algo-1, RMSE): 40.203741484527846\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:54:04 INFO 139780359198336] #test_score (algo-1, mean_absolute_QuantileLoss): 16275.36949883501\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:54:04 INFO 139780359198336] #test_score (algo-1, mean_wQuantileLoss): 0.1352111780247155\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:54:04 INFO 139780359198336] #test_score (algo-1, wQuantileLoss[0.1]): 0.08137104744648552\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:54:04 INFO 139780359198336] #test_score (algo-1, wQuantileLoss[0.2]): 0.1251230146123185\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:54:04 INFO 139780359198336] #test_score (algo-1, wQuantileLoss[0.3]): 0.15162931301852858\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:54:04 INFO 139780359198336] #test_score (algo-1, wQuantileLoss[0.4]): 0.16546533188971804\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:54:04 INFO 139780359198336] #test_score (algo-1, wQuantileLoss[0.5]): 0.17155656928825272\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:54:04 INFO 139780359198336] #test_score (algo-1, wQuantileLoss[0.6]): 0.16808313628263905\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:54:04 INFO 139780359198336] #test_score (algo-1, wQuantileLoss[0.7]): 0.15208834362028048\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:54:04 INFO 139780359198336] #test_score (algo-1, wQuantileLoss[0.8]): 0.12261521188793083\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:54:04 INFO 139780359198336] #test_score (algo-1, wQuantileLoss[0.9]): 0.07896863417628594\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:54:04 INFO 139780359198336] #quality_metric: host=algo-1, test RMSE <loss>=40.203741484527846\u001b[0m\n",
      "\u001b[34m[04/04/2021 09:54:04 INFO 139780359198336] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=0.1352111780247155\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617530044.253915, \"EndTime\": 1617530044.497868, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 6.665706634521484, \"count\": 1, \"min\": 6.665706634521484, \"max\": 6.665706634521484}, \"totaltime\": {\"sum\": 5754058.852672577, \"count\": 1, \"min\": 5754058.852672577, \"max\": 5754058.852672577}}}\n",
      "\u001b[0m\n",
      "\n",
      "2021-04-04 09:54:20 Uploading - Uploading generated training model\n",
      "2021-04-04 09:54:20 Completed - Training job completed\n",
      "Training seconds: 5802\n",
      "Billable seconds: 5802\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(inputs=data_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job name: deepar-bikerental-no-categories-2021-04-04-08-15-24-671\n"
     ]
    }
   ],
   "source": [
    "job_name = estimator.latest_training_job.name\n",
    "print ('job name: {0}'.format(job_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "endpoint_name = sess.endpoint_from_job(\n",
    "    job_name=job_name,\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    image_uri=container,\n",
    "    role=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "endpoint name: deepar-bikerental-no-categories-2021-04-04-08-15-24-671\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print ('endpoint name: {0}'.format(endpoint_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "notice": "Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved. Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
